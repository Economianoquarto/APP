[
  {
    "objectID": "posts/modelo-classico-regressao/index.html",
    "href": "posts/modelo-classico-regressao/index.html",
    "title": "Modelo Clássico de Regressão MCRL",
    "section": "",
    "text": "Equação do Modelo: O modelo é definido como \\(y_i = f(x_{i1}, x_{i2}, ..., x_{ik}) + \\epsilon_i\\), que pode ser expresso de forma linear como \\(y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_k x_{ik} + \\epsilon_i\\), para \\(i = 1, ..., n\\).\nRepresentação Matricial: O modelo também pode ser representado em forma matricial como \\(y = X\\beta + \\epsilon\\), onde: \\(y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\\) é o vetor das variáveis dependentes (n x 1). \\(X = \\begin{pmatrix} 1 & x_{12} & \\cdots & x_{1k} \\\\ 1 & x_{22} & \\cdots & x_{2k} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n2} & \\cdots & x_{nk} \\end{pmatrix}\\) é a matriz das variáveis independentes (n x k+1), assumindo \\(x_{i1} = 1\\) para o intercepto. \\(\\beta = \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_k \\end{pmatrix}\\) é o vetor dos parâmetros (k+1 x 1). \\(\\epsilon = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}\\) é o vetor dos erros (n x 1).\nHipóteses: O modelo clássico de regressão linear múltipla se baseia nas seguintes hipóteses: H1) Linearidade: A relação entre a variável dependente e as variáveis independentes é linear nos parâmetros. H2) Identificação (posto completo): A matriz das variáveis independentes \\(X\\) tem posto completo, ou seja, \\(posto(X) = K\\) (onde \\(K = k+1\\)). Isso garante que as colunas de \\(X\\) são linearmente independentes, permitindo a identificação única dos parâmetros. H3) Valor esperado dos erros é nulo: O valor esperado do vetor de erros é zero, \\(E[\\epsilon] = \\begin{pmatrix} E[\\epsilon_1] \\\\ \\vdots \\\\ E[\\epsilon_n] \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}\\).\nImplicações da H3 (Valor Esperado dos Erros é Nulo): 1. Se a média condicional do erro dado \\(X\\) é zero (\\(E[\\epsilon|X] = 0\\)), então a média não condicional do erro também é zero (\\(E[\\epsilon] = E[E[\\epsilon|X]] = E = 0\\)). 2. A hipótese \\(E[\\epsilon|X] = 0\\) implica que \\(E[y|X] = E[X\\beta + \\epsilon|X] = E[X\\beta|X] + E[\\epsilon|X] = X\\beta + 0 = X\\beta\\). Portanto, \\(E[y|X] - X\\beta = 0\\), o que implica \\(E[y - X\\beta|X] = E[\\epsilon|X] = 0\\). 3. Além disso, se \\(\\epsilon\\) e \\(X\\) são independentes, então \\(E[X'\\epsilon] = E[X']E[\\epsilon] = E[X'] \\cdot 0 = 0\\). Consequentemente, a covariância entre \\(X\\) e \\(\\epsilon\\) é \\(Cov(X, \\epsilon) = E[X\\epsilon'] - E[X]E[\\epsilon'] = E[X\\epsilon'] - E[X] \\cdot 0 = E[X\\epsilon'] = (E[X'\\epsilon])' = 0' = 0\\)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Avaliação de Política Públicas",
    "section": "",
    "text": "Ensino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsino\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\nCaio Lopes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#definição-e-características-dos-dados-de-painel",
    "href": "index.html#definição-e-características-dos-dados-de-painel",
    "title": "Avaliação de Política Públicas",
    "section": "Definição e Características dos Dados de Painel",
    "text": "Definição e Características dos Dados de Painel\nOs dados de painel constituem uma estrutura de dados que combina as dimensões cross-section e temporal, fornecendo observações repetidas das mesmas unidades (indivíduos, empresas, países, etc.) ao longo de múltiplos períodos de tempo. Formalmente, podemos representar um conjunto de dados de painel como \\(\\{y_{it}, x_{it}: i = 1, ..., N; t = 1, ..., T\\}\\), onde \\(i\\) indexa as unidades cross-section e \\(t\\) indexa os períodos temporais.\nEsta estrutura bidimensional distingue os dados de painel tanto de dados puramente cross-section (observações de múltiplas unidades em um único ponto no tempo) quanto de séries temporais (observações de uma única unidade ao longo de múltiplos períodos). A natureza híbrida dos dados de painel permite explorar tanto a variação entre unidades quanto a variação temporal dentro de cada unidade, oferecendo uma riqueza informacional única para a análise empírica.\nUma distinção importante na literatura de dados de painel é entre painéis curtos e painéis longos. Painéis curtos caracterizam-se por um grande número de unidades cross-section (\\(N\\) grande) observadas por um número relativamente pequeno de períodos (\\(T\\) pequeno), tipicamente \\(T < 10\\). Este é o caso mais comum em aplicações microeconométricas, onde podemos ter milhares de indivíduos ou empresas observados por alguns anos. Por outro lado, painéis longos envolvem um número menor de unidades observadas por muitos períodos, como no caso de estudos macroeconômicos com poucos países observados por décadas.\nO foco deste post está nos painéis curtos, que apresentam desafios metodológicos específicos relacionados ao tratamento da heterogeneidade individual quando o número de períodos é limitado. Neste contexto, os efeitos individuais não podem ser estimados consistentemente, exigindo abordagens alternativas para lidar com a heterogeneidade não observada."
  },
  {
    "objectID": "index.html#as-três-principais-vantagens-dos-dados-de-painel",
    "href": "index.html#as-três-principais-vantagens-dos-dados-de-painel",
    "title": "Avaliação de Política Públicas",
    "section": "As Três Principais Vantagens dos Dados de Painel",
    "text": "As Três Principais Vantagens dos Dados de Painel\n\nMaior Precisão na Estimação\nA primeira e mais imediata vantagem dos dados de painel é o aumento substancial no tamanho da amostra. Ao combinar observações cross-section e temporais, obtemos \\(N \\times T\\) observações em vez de apenas \\(N\\) (no caso de dados cross-section) ou \\(T\\) (no caso de séries temporais). Este aumento no número de observações geralmente resulta em maior precisão na estimação dos parâmetros, refletida em erros padrão menores e intervalos de confiança mais estreitos.\nNo entanto, é crucial reconhecer que o ganho de precisão não é automático nem proporcional ao aumento no número de observações. A presença de correlação temporal nos erros para uma mesma unidade implica que as \\(T\\) observações de cada indivíduo não fornecem \\(T\\) vezes mais informação do que uma única observação. A correlação positiva entre os erros ao longo do tempo reduz o conteúdo informacional efetivo dos dados, e os erros padrão usuais do OLS podem subestimar drasticamente a verdadeira incerteza dos estimadores.\nEsta questão é particularmente relevante quando consideramos que características não observadas dos indivíduos tendem a persistir ao longo do tempo. Por exemplo, se um modelo subestima consistentemente a renda de um indivíduo em um ano devido a características não observadas (como habilidade ou motivação), é provável que continue subestimando a renda desse mesmo indivíduo em anos subsequentes. Esta persistência cria correlação positiva nos resíduos, violando o pressuposto de independência do OLS clássico.\n\n\nControle da Heterogeneidade Individual Não Observada\nA segunda vantagem fundamental dos dados de painel é a possibilidade de controlar heterogeneidade individual não observada que pode estar correlacionada com as variáveis explicativas. Esta é talvez a contribuição mais importante dos métodos de painel para a identificação causal em econometria.\nEm análises cross-section, a presença de variáveis omitidas correlacionadas tanto com a variável dependente quanto com as variáveis explicativas resulta em viés de variáveis omitidas. Por exemplo, ao estimar o retorno à educação usando dados cross-section, a habilidade individual não observada pode estar positivamente correlacionada tanto com educação quanto com renda, levando a uma superestimação do efeito causal da educação.\nOs dados de painel oferecem uma solução elegante para este problema quando a heterogeneidade não observada é aditiva e invariante no tempo. Se as características não observadas que afetam a variável dependente permanecem constantes ao longo do período de observação, podemos “diferenciá-las” usando transformações apropriadas dos dados. Esta capacidade de controlar heterogeneidade não observada representa uma alternativa poderosa aos métodos de variáveis instrumentais, que frequentemente enfrentam dificuldades na identificação de instrumentos válidos.\nO modelo de efeitos fixos explora precisamente esta ideia, permitindo que cada unidade tenha seu próprio intercepto específico que captura todas as características não observadas invariantes no tempo. Desta forma, a identificação dos parâmetros de interesse baseia-se exclusivamente na variação temporal dentro de cada unidade, eliminando o viés decorrente de características não observadas constantes.\n\n\nAnálise da Dinâmica Comportamental\nA terceira vantagem dos dados de painel é a capacidade de analisar a dinâmica comportamental de forma mais rica do que seria possível com dados cross-section ou séries temporais isoladamente. Esta dimensão temporal permite investigar questões fundamentais sobre persistência, mobilidade e heterogeneidade na dinâmica individual.\nConsidere, por exemplo, a análise da pobreza. Dados cross-section podem revelar que 20% da população está em situação de pobreza em um determinado ano, mas não conseguem distinguir entre diferentes cenários dinâmicos: os mesmos 20% permanecem pobres ano após ano, ou existe mobilidade significativa com diferentes indivíduos entrando e saindo da pobreza? Esta distinção é crucial para o desenho de políticas públicas efetivas.\nSimilarmente, na análise do desemprego, dados de painel permitem distinguir entre desemprego friccional (períodos curtos de desemprego durante transições entre empregos) e desemprego estrutural (períodos longos de desemprego concentrados em indivíduos específicos). Esta distinção tem implicações importantes tanto para a compreensão teórica dos mercados de trabalho quanto para o desenho de políticas de emprego.\nA dimensão temporal dos dados de painel também permite investigar questões sobre dependência de estado (state dependence) versus heterogeneidade não observada. Por exemplo, a alta correlação serial nos rendimentos individuais pode decorrer de características individuais persistentes (como habilidade) ou de verdadeira dependência temporal (onde rendimentos passados influenciam rendimentos futuros). Modelos de painel dinâmicos, embora mais complexos, podem ajudar a distinguir entre essas duas fontes de persistência."
  },
  {
    "objectID": "index.html#o-modelo-geral-e-a-necessidade-de-restrições",
    "href": "index.html#o-modelo-geral-e-a-necessidade-de-restrições",
    "title": "Avaliação de Política Públicas",
    "section": "O Modelo Geral e a Necessidade de Restrições",
    "text": "O Modelo Geral e a Necessidade de Restrições\nA análise de dados de painel inicia-se com um modelo muito geral que permite que tanto o intercepto quanto os coeficientes angulares variem entre indivíduos e ao longo do tempo:\n\\[y_{it} = \\alpha_{it} + x_{it}'\\beta_{it} + u_{it}, \\quad i = 1, ..., N, \\quad t = 1, ..., T\\]\nonde \\(y_{it}\\) é a variável dependente escalar, \\(x_{it}\\) é um vetor \\(K \\times 1\\) de variáveis independentes, \\(u_{it}\\) é o termo de erro, \\(i\\) indexa indivíduos e \\(t\\) indexa tempo.\nEste modelo, embora teoricamente atrativo por sua flexibilidade, é impraticável na prática. Com \\(N\\) indivíduos, \\(T\\) períodos e \\(K\\) variáveis explicativas, teríamos \\(NT(K+1)\\) parâmetros para estimar com apenas \\(NT\\) observações. Claramente, este modelo é não identificado e requer restrições adicionais para tornar-se estimável.\nA questão central torna-se então: quais restrições devemos impor? A resposta a esta pergunta define os diferentes modelos de painel e suas propriedades estatísticas. As restrições mais comumente impostas referem-se à forma como os parâmetros variam (ou não variam) entre indivíduos e ao longo do tempo, e à natureza da correlação entre os efeitos individuais e as variáveis explicativas."
  },
  {
    "objectID": "index.html#a-questão-fundamental-como-tratar-a-heterogeneidade-individual",
    "href": "index.html#a-questão-fundamental-como-tratar-a-heterogeneidade-individual",
    "title": "Avaliação de Política Públicas",
    "section": "A Questão Fundamental: Como Tratar a Heterogeneidade Individual?",
    "text": "A Questão Fundamental: Como Tratar a Heterogeneidade Individual?\nO cerne do debate sobre modelos de painel reside no tratamento da heterogeneidade individual não observada. Esta heterogeneidade manifesta-se através de características específicas de cada unidade de observação que afetam a variável dependente mas não são diretamente observáveis ou mensuráveis.\nEm termos práticos, consideremos um modelo de determinação de salários. Características como habilidade, motivação, conexões sociais, ou preferências por trabalho podem afetar significativamente os salários, mas são difíceis de medir diretamente. Se essas características não observadas estão correlacionadas com variáveis explicativas observáveis (como educação ou experiência), sua omissão do modelo resultará em estimadores viesados.\nA literatura de dados de painel oferece três abordagens principais para lidar com esta heterogeneidade, cada uma baseada em pressupostos diferentes sobre a natureza e comportamento dos efeitos individuais não observados."
  },
  {
    "objectID": "index.html#os-três-modelos-principais-uma-visão-geral",
    "href": "index.html#os-três-modelos-principais-uma-visão-geral",
    "title": "Avaliação de Política Públicas",
    "section": "Os Três Modelos Principais: Uma Visão Geral",
    "text": "Os Três Modelos Principais: Uma Visão Geral\n\nModelo Pooled (Agrupado): A Abordagem da Homogeneidade\nO modelo pooled representa a abordagem mais restritiva, assumindo homogeneidade completa entre as unidades de observação. Este modelo trata os dados de painel como se fossem uma grande amostra cross-section, ignorando a estrutura temporal e a identidade específica de cada unidade.\nFormalmente, o modelo pooled especifica:\n\\[y_{it} = \\alpha + x_{it}'\\beta + u_{it}\\]\nonde \\(\\alpha\\) e \\(\\beta\\) são constantes para todos os indivíduos e períodos. Este modelo assume implicitamente que não existe heterogeneidade individual relevante, ou que qualquer heterogeneidade existente é não correlacionada com as variáveis explicativas e pode ser tratada como parte do termo de erro aleatório.\n\n\nModelo de Efeitos Aleatórios: Heterogeneidade Não Correlacionada\nO modelo de efeitos aleatórios reconhece a existência de heterogeneidade individual, mas assume que esta heterogeneidade é distribuída independentemente das variáveis explicativas. Este modelo pode ser visto como uma extensão do modelo pooled que permite interceptos específicos para cada indivíduo.\nA especificação do modelo de efeitos aleatórios é:\n\\[y_{it} = \\alpha + x_{it}'\\beta + (\\alpha_i + \\varepsilon_{it})\\]\nonde \\(\\alpha_i\\) representa o efeito aleatório individual e \\(\\varepsilon_{it}\\) é o erro idiossincrático. O pressuposto fundamental é que \\(\\alpha_i\\) é independente de \\(x_{it}\\) para todos os períodos, o que permite a estimação consistente de todos os parâmetros, incluindo coeficientes de variáveis invariantes no tempo.\n\n\nModelo de Efeitos Fixos: Heterogeneidade Correlacionada\nO modelo de efeitos fixos adota a abordagem mais flexível, permitindo que a heterogeneidade individual seja correlacionada com as variáveis explicativas. Este modelo não faz pressupostos sobre a distribuição dos efeitos individuais ou sua correlação com os regressores.\nA especificação é:\n\\[y_{it} = \\alpha_i + x_{it}'\\beta + \\varepsilon_{it}\\]\nonde \\(\\alpha_i\\) são parâmetros fixos específicos para cada indivíduo, que podem ser correlacionados com \\(x_{it}\\). Esta flexibilidade tem um custo: apenas os coeficientes de variáveis que variam no tempo podem ser identificados, pois os efeitos fixos absorvem toda a variação cross-section."
  },
  {
    "objectID": "index.html#por-que-a-escolha-importa-implicações-para-consistência-e-interpretação",
    "href": "index.html#por-que-a-escolha-importa-implicações-para-consistência-e-interpretação",
    "title": "Avaliação de Política Públicas",
    "section": "Por Que a Escolha Importa: Implicações para Consistência e Interpretação",
    "text": "Por Que a Escolha Importa: Implicações para Consistência e Interpretação\nA escolha entre estes três modelos não é meramente uma questão de preferência metodológica - ela tem implicações fundamentais para a consistência dos estimadores e a interpretação dos resultados. Um estimador é consistente sob um modelo específico se converge em probabilidade para o verdadeiro valor do parâmetro quando o tamanho da amostra aumenta, assumindo que o modelo está corretamente especificado.\nA Tabela 1 resume as propriedades de consistência dos principais estimadores sob cada especificação de modelo. Esta tabela revela uma hierarquia clara: estimadores que são consistentes sob pressupostos mais restritivos (como o modelo pooled) podem tornar-se inconsistentes quando esses pressupostos são violados, enquanto estimadores robustos a pressupostos mais fracos (como o estimador within para efeitos fixos) mantêm consistência mesmo sob especificações mais gerais.\n\n\nTable 1: Consistência dos Estimadores por Modelo Assumido\n\n\n\n\n\n\n\n\nEstimador\nModelo Pooled\nEfeitos Aleatórios\nEfeitos Fixos\n\n\n\n\nPooled OLS\nConsistente\nConsistente\nInconsistente\n\n\nBetween\nConsistente\nConsistente\nInconsistente\n\n\nWithin (Efeitos Fixos)\nConsistente\nConsistente\nConsistente\n\n\nPrimeiras Diferenças\nConsistente\nConsistente\nConsistente\n\n\nEfeitos Aleatórios (GLS)\nConsistente\nConsistente\nInconsistente\n\n\n\n\nEsta tabela ilustra um princípio fundamental da econometria: a robustez tem um preço. Estimadores mais robustos (como within e primeiras diferenças) mantêm consistência sob pressupostos mais fracos, mas podem ser menos eficientes quando os pressupostos mais restritivos são válidos. Por outro lado, estimadores mais eficientes sob pressupostos específicos (como pooled OLS ou efeitos aleatórios) podem produzir resultados severamente viesados quando esses pressupostos são violados.\nA implicação prática é clara: a escolha do modelo deve ser baseada em uma avaliação cuidadosa da plausibilidade dos pressupostos subjacentes no contexto específico da aplicação. Em muitas aplicações microeconométricas, a presença de heterogeneidade individual correlacionada com os regressores é altamente plausível, favorecendo o uso de modelos de efeitos fixos. Em outras situações, particularmente quando o interesse recai sobre efeitos de variáveis invariantes no tempo, o modelo de efeitos aleatórios pode ser mais apropriado, desde que seus pressupostos sejam defensáveis."
  },
  {
    "objectID": "index.html#formulação-matemática-e-pressupostos-fundamentais",
    "href": "index.html#formulação-matemática-e-pressupostos-fundamentais",
    "title": "Avaliação de Política Públicas",
    "section": "Formulação Matemática e Pressupostos Fundamentais",
    "text": "Formulação Matemática e Pressupostos Fundamentais\nO modelo Pooled OLS representa a extensão mais direta dos métodos de regressão linear clássica para dados de painel. Sua formulação matemática é deceptivamente simples:\n\\[y_{it} = \\alpha + x_{it}'\\beta + u_{it}, \\quad i = 1, ..., N, \\quad t = 1, ..., T\\]\nonde \\(y_{it}\\) é a variável dependente para o indivíduo \\(i\\) no período \\(t\\), \\(x_{it}\\) é um vetor \\(K \\times 1\\) de variáveis explicativas, \\(\\alpha\\) é o intercepto comum a todas as observações, \\(\\beta\\) é um vetor \\(K \\times 1\\) de coeficientes angulares constantes, e \\(u_{it}\\) é o termo de erro.\nA implementação prática do modelo pooled consiste em “empilhar” todas as observações de painel em uma única regressão com \\(NT\\) observações, tratando cada observação \\((i,t)\\) como independente das demais. Esta abordagem ignora completamente a estrutura de painel dos dados, tratando-os como se fossem uma grande amostra cross-section.\nOs pressupostos fundamentais do modelo pooled incluem:\nHomogeneidade dos Parâmetros: Todos os indivíduos possuem o mesmo intercepto \\(\\alpha\\) e os mesmos coeficientes angulares \\(\\beta\\). Este pressuposto implica que a relação entre as variáveis explicativas e a variável dependente é idêntica para todos os indivíduos em todos os períodos.\nExogeneidade Estrita: \\(E[u_{it}|x_{i1}, ..., x_{iT}] = 0\\) para todos \\(i\\) e \\(t\\). Este pressuposto, conhecido como exogeneidade estrita ou forte, requer que o termo de erro seja não correlacionado com os valores passados, presentes e futuros de todas as variáveis explicativas.\nHomocedasticidade: \\(Var[u_{it}|x_{i1}, ..., x_{iT}] = \\sigma^2\\) para todos \\(i\\) e \\(t\\). A variância do erro é constante across indivíduos e tempo.\nNão Autocorrelação: \\(Cov[u_{it}, u_{is}|x_{i1}, ..., x_{iT}] = 0\\) para \\(t \\neq s\\). Os erros para o mesmo indivíduo em períodos diferentes são não correlacionados."
  },
  {
    "objectID": "index.html#quando-o-modelo-pooled-é-apropriado",
    "href": "index.html#quando-o-modelo-pooled-é-apropriado",
    "title": "Avaliação de Política Públicas",
    "section": "Quando o Modelo Pooled é Apropriado",
    "text": "Quando o Modelo Pooled é Apropriado\nO modelo pooled é apropriado quando os pressupostos de homogeneidade e independência são plausíveis. Em termos práticos, isto ocorre quando:\nAusência de Heterogeneidade Individual Relevante: Não existem características não observadas específicas dos indivíduos que afetem significativamente a variável dependente. Alternativamente, qualquer heterogeneidade existente é não correlacionada com as variáveis explicativas e pode ser tratada como ruído aleatório.\nEstabilidade Temporal da Relação: A relação entre as variáveis explicativas e a variável dependente permanece estável ao longo do tempo, sem mudanças estruturais ou efeitos de aprendizado que possam afetar os coeficientes.\nIndependência Temporal dos Choques: Os choques que afetam a variável dependente em um período não persistem ou influenciam períodos subsequentes. Esta condição é particularmente restritiva em aplicações microeconométricas, onde choques individuais frequentemente exibem persistência.\nExemplos de situações onde o modelo pooled pode ser apropriado incluem análises de mercados com produtos homogêneos e participantes com características similares, estudos de fenômenos com pouca persistência temporal, ou análises exploratórias iniciais onde a simplicidade metodológica é valorizada sobre a sofisticação."
  },
  {
    "objectID": "index.html#vantagens-do-modelo-pooled",
    "href": "index.html#vantagens-do-modelo-pooled",
    "title": "Avaliação de Política Públicas",
    "section": "Vantagens do Modelo Pooled",
    "text": "Vantagens do Modelo Pooled\n\nSimplicidade Conceitual e Computacional\nA principal vantagem do modelo pooled é sua simplicidade. A estimação reduz-se a uma regressão OLS padrão com \\(NT\\) observações, utilizando procedimentos computacionais bem estabelecidos e amplamente disponíveis. Esta simplicidade facilita a interpretação dos resultados e a comunicação dos achados para audiências não especializadas.\n\n\nEficiência sob Pressupostos Corretos\nQuando os pressupostos do modelo pooled são válidos, o estimador OLS é o melhor estimador linear não viesado (BLUE - Best Linear Unbiased Estimator) pelo teorema de Gauss-Markov. Neste caso, o modelo pooled oferece a maior eficiência possível entre todos os estimadores lineares não viesados.\n\n\nIdentificação de Todos os Parâmetros\nDiferentemente do modelo de efeitos fixos, o modelo pooled permite a identificação e estimação de coeficientes para todas as variáveis explicativas, incluindo aquelas que são invariantes no tempo. Esta capacidade é particularmente valiosa quando o interesse da pesquisa recai sobre efeitos de características demográficas, geográficas, ou outras variáveis que não mudam ao longo do período de observação."
  },
  {
    "objectID": "index.html#limitações-e-problemas-do-modelo-pooled",
    "href": "index.html#limitações-e-problemas-do-modelo-pooled",
    "title": "Avaliação de Política Públicas",
    "section": "Limitações e Problemas do Modelo Pooled",
    "text": "Limitações e Problemas do Modelo Pooled\n\nO Problema da Correlação Temporal dos Erros\nA limitação mais séria do modelo pooled em aplicações práticas é a violação quase inevitável do pressuposto de não autocorrelação dos erros. Em dados de painel, é altamente plausível que características não observadas dos indivíduos criem correlação positiva entre os erros ao longo do tempo.\nPara compreender este problema, considere um modelo de determinação de salários onde a habilidade individual não observada afeta positivamente os salários. Se a habilidade é relativamente estável ao longo do tempo, indivíduos com alta habilidade tenderão a ter salários sistematicamente acima do previsto pelo modelo em todos os períodos, enquanto indivíduos com baixa habilidade terão salários sistematicamente abaixo do previsto.\nEsta correlação temporal dos erros tem consequências graves para a inferência estatística. Os erros padrão usuais do OLS, que assumem independência das observações, subestimarão sistematicamente a verdadeira incerteza dos estimadores. Como resultado, as estatísticas t serão inflacionadas, levando a rejeições espúrias da hipótese nula e conclusões errôneas sobre a significância estatística dos coeficientes.\n\n\nViés de Variáveis Omitidas\nQuando existem características individuais não observadas correlacionadas com as variáveis explicativas, o modelo pooled sofre de viés de variáveis omitidas. Este viés surge porque o termo de erro \\(u_{it}\\) inclui implicitamente os efeitos individuais não observados, violando o pressuposto de exogeneidade estrita.\nFormalmente, se o verdadeiro modelo é \\(y_{it} = \\alpha_i + x_{it}'\\beta + \\varepsilon_{it}\\) (um modelo de efeitos fixos), mas estimamos o modelo pooled \\(y_{it} = \\alpha + x_{it}'\\beta + u_{it}\\), então \\(u_{it} = (\\alpha_i - \\alpha) + \\varepsilon_{it}\\). Se \\(\\alpha_i\\) está correlacionado com \\(x_{it}\\), então \\(E[u_{it}|x_{it}] \\neq 0\\), violando o pressuposto de exogeneidade e resultando em estimadores inconsistentes.\n\n\nSuperestimação da Precisão\nMesmo quando os coeficientes estimados são não viesados, a presença de correlação temporal nos erros leva à superestimação da precisão dos estimadores. O modelo pooled trata cada uma das \\(NT\\) observações como fornecendo informação independente, mas na realidade, as \\(T\\) observações de cada indivíduo fornecem menos informação do que \\(T\\) observações verdadeiramente independentes devido à correlação temporal.\nEsta superestimação da precisão é particularmente problemática em painéis com muitos períodos ou alta correlação temporal dos erros. Em casos extremos, os erros padrão reportados podem ser uma fração pequena dos erros padrão corretos, levando a conclusões completamente errôneas sobre a significância estatística dos resultados."
  },
  {
    "objectID": "index.html#correções-e-extensões-do-modelo-pooled",
    "href": "index.html#correções-e-extensões-do-modelo-pooled",
    "title": "Avaliação de Política Públicas",
    "section": "Correções e Extensões do Modelo Pooled",
    "text": "Correções e Extensões do Modelo Pooled\n\nErros Padrão Robustos à Correlação Temporal\nUma abordagem para lidar com a correlação temporal dos erros mantendo a estrutura do modelo pooled é o uso de erros padrão robustos que permitem correlação arbitrária dentro de cada cluster (indivíduo). Estes erros padrão “clustered” fornecem inferência válida mesmo na presença de correlação temporal, desde que o número de clusters seja suficientemente grande.\nA matriz de variância-covariância robusta a clusters tem a forma:\n\\[\\hat{V}_{cluster} = (X'X)^{-1}\\left(\\sum_{i=1}^N X_i'\\hat{u}_i\\hat{u}_i'X_i\\right)(X'X)^{-1}\\]\nonde \\(X_i\\) e \\(\\hat{u}_i\\) são, respectivamente, a matriz de regressores e o vetor de resíduos para o indivíduo \\(i\\).\n\n\nModelo Pooled com Dummies Temporais\nUma extensão comum do modelo pooled básico é a inclusão de dummies temporais para controlar efeitos de tempo comuns a todos os indivíduos:\n\\[y_{it} = \\alpha + \\sum_{s=2}^T \\gamma_s d_{s,it} + x_{it}'\\beta + u_{it}\\]\nonde \\(d_{s,it}\\) são dummies temporais que assumem valor 1 se \\(t = s\\) e 0 caso contrário. Esta especificação permite controlar choques macroeconômicos, mudanças de política, ou outros fatores que afetam todos os indivíduos simultaneamente em períodos específicos.\nA inclusão de dummies temporais é particularmente importante em aplicações onde o período de observação inclui eventos significativos (como crises econômicas, mudanças regulatórias, ou choques externos) que podem afetar a relação entre as variáveis de interesse."
  },
  {
    "objectID": "index.html#formulação-matemática-e-estrutura-do-erro-composto",
    "href": "index.html#formulação-matemática-e-estrutura-do-erro-composto",
    "title": "Avaliação de Política Públicas",
    "section": "Formulação Matemática e Estrutura do Erro Composto",
    "text": "Formulação Matemática e Estrutura do Erro Composto\nO modelo de efeitos aleatórios representa um meio-termo entre a rigidez do modelo pooled e a flexibilidade do modelo de efeitos fixos. Sua formulação reconhece a existência de heterogeneidade individual, mas impõe restrições específicas sobre a natureza desta heterogeneidade.\nA especificação fundamental do modelo de efeitos aleatórios é:\n\\[y_{it} = \\alpha + x_{it}'\\beta + (\\alpha_i + \\varepsilon_{it})\\]\nonde \\(\\alpha\\) é o intercepto médio comum, \\(x_{it}'\\beta\\) representa os efeitos das variáveis observáveis, \\(\\alpha_i\\) é o efeito aleatório individual específico, e \\(\\varepsilon_{it}\\) é o erro idiossincrático. O termo entre parênteses, \\(u_{it} = \\alpha_i + \\varepsilon_{it}\\), constitui o erro composto que caracteriza este modelo.\nEsta decomposição do erro em dois componentes tem implicações profundas para a estrutura de correlação dos dados. O componente \\(\\alpha_i\\) é específico do indivíduo mas constante ao longo do tempo, criando correlação entre as observações do mesmo indivíduo em diferentes períodos. O componente \\(\\varepsilon_{it}\\) varia tanto entre indivíduos quanto ao longo do tempo, representando choques idiossincráticos não correlacionados.\nOs pressupostos distribucional padrão do modelo de efeitos aleatórios especificam:\n\\[\\alpha_i \\sim iid(0, \\sigma_\\alpha^2)\\] \\[\\varepsilon_{it} \\sim iid(0, \\sigma_\\varepsilon^2)\\] \\[Cov[\\alpha_i, \\varepsilon_{it}] = 0 \\text{ para todos } i, t\\]\nEstes pressupostos implicam que tanto os efeitos individuais quanto os erros idiossincráticos são independente e identicamente distribuídos, com médias zero e variâncias constantes."
  },
  {
    "objectID": "index.html#o-pressuposto-fundamental-independência-dos-efeitos-aleatórios",
    "href": "index.html#o-pressuposto-fundamental-independência-dos-efeitos-aleatórios",
    "title": "Avaliação de Política Públicas",
    "section": "O Pressuposto Fundamental: Independência dos Efeitos Aleatórios",
    "text": "O Pressuposto Fundamental: Independência dos Efeitos Aleatórios\nO pressuposto mais crítico do modelo de efeitos aleatórios é a independência entre os efeitos individuais e as variáveis explicativas:\n\\[E[\\alpha_i | x_{i1}, ..., x_{iT}] = 0\\]\nEste pressuposto, conhecido como exogeneidade dos efeitos aleatórios, requer que as características não observadas específicas dos indivíduos sejam não correlacionadas com todas as variáveis explicativas em todos os períodos. Em outras palavras, a heterogeneidade individual deve ser “puramente aleatória” em relação aos regressores observados.\nA plausibilidade deste pressuposto varia significativamente entre aplicações. Em estudos microeconométricos, é frequentemente questionável assumir que características como habilidade, motivação, ou preferências individuais são não correlacionadas com variáveis como educação, experiência, ou escolhas ocupacionais. Esta limitação levou muitos economistas a favorecer modelos de efeitos fixos em aplicações empíricas."
  },
  {
    "objectID": "index.html#estrutura-de-correlação-o-modelo-equicorrelacionado",
    "href": "index.html#estrutura-de-correlação-o-modelo-equicorrelacionado",
    "title": "Avaliação de Política Públicas",
    "section": "Estrutura de Correlação: O Modelo Equicorrelacionado",
    "text": "Estrutura de Correlação: O Modelo Equicorrelacionado\nUma característica distintiva do modelo de efeitos aleatórios é a estrutura de correlação específica que impõe aos dados. A presença do componente \\(\\alpha_i\\) no erro composto cria correlação entre observações do mesmo indivíduo:\n\\[Cov[u_{it}, u_{is}] = Cov[(\\alpha_i + \\varepsilon_{it}), (\\alpha_i + \\varepsilon_{is})] = \\sigma_\\alpha^2\\]\npara \\(t \\neq s\\), enquanto:\n\\[Var[u_{it}] = \\sigma_\\alpha^2 + \\sigma_\\varepsilon^2\\]\nIsto resulta em uma correlação intraclasse constante:\n\\[\\rho = \\frac{\\sigma_\\alpha^2}{\\sigma_\\alpha^2 + \\sigma_\\varepsilon^2}\\]\nEsta correlação é independente da distância temporal entre as observações, caracterizando o que é conhecido como estrutura equicorrelacionada ou exchangeable. Sob esta estrutura, a correlação entre observações do mesmo indivíduo nos períodos 1 e 2 é idêntica à correlação entre os períodos 1 e 5, ou qualquer outro par de períodos.\nA estrutura equicorrelacionada é uma restrição forte que pode não ser realística em muitas aplicações. Em dados econômicos, é comum observar que a correlação entre observações decresce com a distância temporal, refletindo a dissipação gradual de choques ao longo do tempo. O modelo de efeitos aleatórios não acomoda esta possibilidade, assumindo correlação constante independentemente do intervalo temporal."
  },
  {
    "objectID": "index.html#estimação-o-método-de-mínimos-quadrados-generalizados-gls",
    "href": "index.html#estimação-o-método-de-mínimos-quadrados-generalizados-gls",
    "title": "Avaliação de Política Públicas",
    "section": "Estimação: O Método de Mínimos Quadrados Generalizados (GLS)",
    "text": "Estimação: O Método de Mínimos Quadrados Generalizados (GLS)\nDevido à estrutura de correlação não esférica dos erros, o estimador OLS, embora consistente sob os pressupostos do modelo de efeitos aleatórios, não é eficiente. O estimador eficiente é obtido através do método de Mínimos Quadrados Generalizados (GLS), que leva em conta a estrutura de correlação conhecida dos erros.\nO estimador GLS para o modelo de efeitos aleatórios pode ser implementado através de uma transformação dos dados que remove a correlação serial. A transformação específica é:\n\\[y_{it}^* = y_{it} - \\theta \\bar{y}_i\\] \\[x_{it}^* = x_{it} - \\theta \\bar{x}_i\\]\nonde \\(\\bar{y}_i = T^{-1}\\sum_{t=1}^T y_{it}\\) e \\(\\bar{x}_i = T^{-1}\\sum_{t=1}^T x_{it}\\) são as médias temporais para o indivíduo \\(i\\), e:\n\\[\\theta = 1 - \\sqrt{\\frac{\\sigma_\\varepsilon^2}{\\sigma_\\varepsilon^2 + T\\sigma_\\alpha^2}}\\]\nO parâmetro \\(\\theta\\) determina o grau de “demeaning” aplicado aos dados. Quando \\(\\sigma_\\alpha^2 = 0\\) (ausência de efeitos aleatórios), \\(\\theta = 0\\) e a transformação se reduz ao modelo pooled original. Quando \\(\\sigma_\\alpha^2 \\to \\infty\\) (efeitos aleatórios dominantes), \\(\\theta \\to 1\\) e a transformação aproxima-se da transformação within do modelo de efeitos fixos.\nNa prática, os parâmetros de variância \\(\\sigma_\\alpha^2\\) e \\(\\sigma_\\varepsilon^2\\) são desconhecidos e devem ser estimados. O procedimento padrão envolve estimação em dois estágios: primeiro, obtêm-se estimativas consistentes dos parâmetros de variância usando resíduos de regressões auxiliares; segundo, aplica-se a transformação GLS usando estas estimativas. Este procedimento é conhecido como GLS factível (FGLS)."
  },
  {
    "objectID": "index.html#vantagens-do-modelo-de-efeitos-aleatórios",
    "href": "index.html#vantagens-do-modelo-de-efeitos-aleatórios",
    "title": "Avaliação de Política Públicas",
    "section": "Vantagens do Modelo de Efeitos Aleatórios",
    "text": "Vantagens do Modelo de Efeitos Aleatórios\n\nEficiência sob Pressupostos Corretos\nQuando os pressupostos do modelo de efeitos aleatórios são válidos, o estimador GLS é mais eficiente que tanto o estimador pooled OLS quanto o estimador within de efeitos fixos. Esta maior eficiência reflete-se em erros padrão menores e intervalos de confiança mais estreitos, proporcionando maior precisão na estimação dos parâmetros.\nA vantagem de eficiência é particularmente pronunciada quando a correlação intraclasse \\(\\rho\\) é alta, indicando que uma proporção substancial da variação total é devida a diferenças entre indivíduos. Nestes casos, o modelo de efeitos aleatórios explora eficientemente tanto a variação within quanto a variação between, enquanto o modelo de efeitos fixos descarta completamente a informação between.\n\n\nIdentificação de Variáveis Invariantes no Tempo\nUma vantagem crucial do modelo de efeitos aleatórios sobre o modelo de efeitos fixos é a capacidade de identificar e estimar coeficientes de variáveis que são invariantes no tempo. Características como gênero, raça, local de nascimento, ou outras variáveis demográficas fixas podem ter coeficientes estimados no modelo de efeitos aleatórios, mas são perfeitamente colineares com os efeitos fixos individuais.\nEsta capacidade é particularmente valiosa em aplicações onde o interesse principal recai sobre efeitos de características demográficas ou geográficas. Por exemplo, em estudos de discriminação salarial, a capacidade de estimar diretamente o efeito do gênero ou raça é fundamental para os objetivos da pesquisa.\n\n\nParcimônia Paramétrica\nO modelo de efeitos aleatórios é mais parcimonioso que o modelo de efeitos fixos, estimando apenas \\(K + 3\\) parâmetros (\\(K\\) coeficientes angulares, um intercepto, e dois parâmetros de variância) em vez de \\(K + N\\) parâmetros no modelo de efeitos fixos. Esta parcimônia é particularmente vantajosa em painéis com muitos indivíduos, onde o modelo de efeitos fixos pode enfrentar problemas de dimensionalidade."
  },
  {
    "objectID": "index.html#limitações-e-críticas-do-modelo-de-efeitos-aleatórios",
    "href": "index.html#limitações-e-críticas-do-modelo-de-efeitos-aleatórios",
    "title": "Avaliação de Política Públicas",
    "section": "Limitações e Críticas do Modelo de Efeitos Aleatórios",
    "text": "Limitações e Críticas do Modelo de Efeitos Aleatórios\n\nA Implausibilidade do Pressuposto de Exogeneidade\nA crítica mais fundamental ao modelo de efeitos aleatórios em aplicações microeconométricas é a implausibilidade do pressuposto de exogeneidade dos efeitos aleatórios. Em muitos contextos econômicos, é altamente provável que características individuais não observadas estejam correlacionadas com as variáveis explicativas de interesse.\nConsidere, por exemplo, um modelo de determinação de salários onde a educação é uma variável explicativa principal. O pressuposto de efeitos aleatórios requer que características como habilidade, motivação, ou background familiar sejam não correlacionadas com o nível educacional. Esta assumção é questionável, dado que indivíduos com maior habilidade ou de famílias mais favorecidas tendem a investir mais em educação.\n\n\nRigidez da Estrutura de Correlação\nA estrutura equicorrelacionada imposta pelo modelo de efeitos aleatórios pode ser excessivamente restritiva em muitas aplicações. A assumção de correlação constante entre observações do mesmo indivíduo, independentemente da distância temporal, raramente é realística em dados econômicos.\nEm muitos contextos, esperaríamos que a correlação entre observações diminuísse com a distância temporal, refletindo a dissipação gradual de choques ou a evolução das características individuais ao longo do tempo. O modelo de efeitos aleatórios não acomoda esta possibilidade, potencialmente levando a ineficiência ou especificação incorreta.\n\n\nSensibilidade a Violações dos Pressupostos\nQuando o pressuposto de exogeneidade dos efeitos aleatórios é violado, o estimador GLS torna-se inconsistente. Diferentemente do estimador within de efeitos fixos, que mantém consistência mesmo quando os efeitos individuais são correlacionados com os regressores, o estimador de efeitos aleatórios não oferece robustez a violações de seus pressupostos fundamentais.\nEsta sensibilidade implica que a escolha entre modelos de efeitos aleatórios e efeitos fixos não é meramente uma questão de eficiência, mas uma questão fundamental de consistência. Se existe qualquer dúvida sobre a validade do pressuposto de exogeneidade, o modelo de efeitos fixos oferece uma alternativa mais robusta, mesmo ao custo de menor eficiência quando os pressupostos de efeitos aleatórios são válidos."
  },
  {
    "objectID": "index.html#formulação-matemática-e-filosofia-subjacente",
    "href": "index.html#formulação-matemática-e-filosofia-subjacente",
    "title": "Avaliação de Política Públicas",
    "section": "Formulação Matemática e Filosofia Subjacente",
    "text": "Formulação Matemática e Filosofia Subjacente\nO modelo de efeitos fixos representa a abordagem mais flexível e robusta para lidar com heterogeneidade individual não observada em dados de painel. Sua formulação matemática é:\n\\[y_{it} = \\alpha_i + x_{it}'\\beta + \\varepsilon_{it}\\]\nonde \\(\\alpha_i\\) são parâmetros fixos específicos para cada indivíduo, \\(x_{it}'\\beta\\) captura os efeitos das variáveis observáveis, e \\(\\varepsilon_{it}\\) é o erro idiossincrático que satisfaz os pressupostos clássicos de ruído branco.\nA diferença fundamental entre este modelo e o modelo de efeitos aleatórios não reside na formulação matemática - ambos incluem efeitos individuais específicos - mas na natureza dos pressupostos sobre estes efeitos. No modelo de efeitos fixos, os \\(\\alpha_i\\) são tratados como parâmetros fixos desconhecidos que podem ser correlacionados arbitrariamente com as variáveis explicativas \\(x_{it}\\).\nEsta flexibilidade tem um preço: com \\(N\\) indivíduos, o modelo inclui \\(N\\) parâmetros \\(\\alpha_i\\) adicionais aos \\(K\\) coeficientes angulares de interesse. Em painéis curtos, onde \\(N\\) é grande mas \\(T\\) é pequeno, estes parâmetros não podem ser estimados consistentemente. No entanto, como demonstraremos, é possível estimar consistentemente os coeficientes \\(\\beta\\) mesmo sem estimar os \\(\\alpha_i\\) individualmente."
  },
  {
    "objectID": "index.html#o-pressuposto-de-exogeneidade-estrita",
    "href": "index.html#o-pressuposto-de-exogeneidade-estrita",
    "title": "Avaliação de Política Públicas",
    "section": "O Pressuposto de Exogeneidade Estrita",
    "text": "O Pressuposto de Exogeneidade Estrita\nO modelo de efeitos fixos requer o pressuposto de exogeneidade estrita:\n\\[E[\\varepsilon_{it} | \\alpha_i, x_{i1}, ..., x_{iT}] = 0\\]\nEste pressuposto é substancialmente mais fraco que o requerido pelo modelo de efeitos aleatórios. Enquanto o modelo de efeitos aleatórios exige que \\(E[\\alpha_i | x_{i1}, ..., x_{iT}] = 0\\), o modelo de efeitos fixos permite correlação arbitrária entre \\(\\alpha_i\\) e as variáveis explicativas, requerendo apenas que o erro idiossincrático \\(\\varepsilon_{it}\\) seja não correlacionado com os regressores.\nEsta diferença é crucial para aplicações empíricas. O pressuposto de exogeneidade estrita permite que características individuais não observadas (capturadas por \\(\\alpha_i\\)) sejam correlacionadas com as variáveis explicativas, desde que esta correlação seja constante ao longo do tempo. Por exemplo, em um modelo de determinação de salários, a habilidade individual pode estar correlacionada com educação, mas o modelo requer apenas que choques idiossincráticos aos salários (como sorte ou erros de medida) sejam não correlacionados com educação."
  },
  {
    "objectID": "index.html#identificação-através-da-variação-within",
    "href": "index.html#identificação-através-da-variação-within",
    "title": "Avaliação de Política Públicas",
    "section": "Identificação através da Variação Within",
    "text": "Identificação através da Variação Within\nA estratégia de identificação do modelo de efeitos fixos baseia-se exclusivamente na variação temporal dentro de cada indivíduo (variação within). Esta abordagem elimina todos os efeitos de características invariantes no tempo, sejam elas observadas ou não observadas.\nPara compreender esta estratégia, considere a média temporal da equação do modelo para cada indivíduo:\n\\[\\bar{y}_i = \\alpha_i + \\bar{x}_i'\\beta + \\bar{\\varepsilon}_i\\]\nonde \\(\\bar{y}_i = T^{-1}\\sum_{t=1}^T y_{it}\\), \\(\\bar{x}_i = T^{-1}\\sum_{t=1}^T x_{it}\\), e \\(\\bar{\\varepsilon}_i = T^{-1}\\sum_{t=1}^T \\varepsilon_{it}\\).\nSubtraindo esta equação da equação original, obtemos a transformação within:\n\\[y_{it} - \\bar{y}_i = (x_{it} - \\bar{x}_i)'\\beta + (\\varepsilon_{it} - \\bar{\\varepsilon}_i)\\]\nou, em notação mais compacta:\n\\[\\ddot{y}_{it} = \\ddot{x}_{it}'\\beta + \\ddot{\\varepsilon}_{it}\\]\nonde \\(\\ddot{z}_{it} = z_{it} - \\bar{z}_i\\) denota desvios das médias individuais.\nEsta transformação elimina completamente os efeitos fixos \\(\\alpha_i\\), permitindo estimação consistente de \\(\\beta\\) através de OLS aplicado aos dados transformados. O estimador resultante é conhecido como estimador within ou estimador de efeitos fixos."
  },
  {
    "objectID": "index.html#propriedades-do-estimador-within",
    "href": "index.html#propriedades-do-estimador-within",
    "title": "Avaliação de Política Públicas",
    "section": "Propriedades do Estimador Within",
    "text": "Propriedades do Estimador Within\n\nConsistência e Não Viés\nO estimador within é consistente sob o pressuposto de exogeneidade estrita, mesmo quando os efeitos fixos são correlacionados com as variáveis explicativas. Esta robustez é uma vantagem crucial sobre os estimadores pooled OLS e efeitos aleatórios, que se tornam inconsistentes na presença de correlação entre efeitos individuais e regressores.\nA consistência do estimador within pode ser demonstrada notando que a transformação within preserva o pressuposto de exogeneidade:\n\\[E[\\ddot{\\varepsilon}_{it} | \\ddot{x}_{i1}, ..., \\ddot{x}_{iT}] = 0\\]\ndesde que \\(E[\\varepsilon_{it} | x_{i1}, ..., x_{iT}] = 0\\). Consequentemente, o estimador OLS aplicado aos dados transformados satisfaz as condições para consistência.\n\n\nEficiência Condicional\nSob os pressupostos do modelo de efeitos fixos, incluindo homocedasticidade e não autocorrelação de \\(\\varepsilon_{it}\\), o estimador within é eficiente entre todos os estimadores lineares não viesados que utilizam apenas a variação within. No entanto, quando os pressupostos do modelo de efeitos aleatórios são válidos, o estimador within é menos eficiente que o estimador GLS de efeitos aleatórios, pois descarta a informação contida na variação between.\nEsta perda de eficiência reflete o trade-off fundamental entre robustez e eficiência em econometria. O estimador within oferece robustez à correlação entre efeitos individuais e regressores, mas ao custo de menor eficiência quando esta correlação está ausente."
  },
  {
    "objectID": "index.html#limitações-do-modelo-de-efeitos-fixos",
    "href": "index.html#limitações-do-modelo-de-efeitos-fixos",
    "title": "Avaliação de Política Públicas",
    "section": "Limitações do Modelo de Efeitos Fixos",
    "text": "Limitações do Modelo de Efeitos Fixos\n\nImpossibilidade de Identificar Efeitos de Variáveis Invariantes no Tempo\nA limitação mais significativa do modelo de efeitos fixos é a impossibilidade de identificar coeficientes de variáveis que são invariantes no tempo. Variáveis como gênero, raça, local de nascimento, ou outras características demográficas fixas são perfeitamente colineares com os efeitos fixos individuais e, portanto, não podem ter seus efeitos estimados.\nEsta limitação é particularmente restritiva em aplicações onde o interesse principal recai sobre efeitos de características demográficas. Por exemplo, estudos de discriminação salarial que buscam estimar diretamente o efeito do gênero ou raça não podem utilizar modelos de efeitos fixos puros.\n\n\nProblema dos Parâmetros Incidentais\nEm painéis curtos, o modelo de efeitos fixos enfrenta o problema dos parâmetros incidentais identificado por Neyman e Scott (1948). Com \\(N\\) efeitos fixos para estimar e apenas \\(T\\) observações por indivíduo, os efeitos fixos individuais não podem ser estimados consistentemente quando \\(T\\) é fixo e \\(N \\to \\infty\\).\nEmbora este problema não afete a consistência do estimador within para os coeficientes \\(\\beta\\) em modelos lineares, ele pode causar viés em modelos não lineares. Em modelos logit ou probit com efeitos fixos, por exemplo, o viés dos parâmetros incidentais pode ser substancial quando \\(T\\) é pequeno.\n\n\nPerda de Graus de Liberdade\nO modelo de efeitos fixos consome \\(N\\) graus de liberdade para estimar os efeitos fixos individuais, reduzindo a eficiência da estimação, particularmente quando \\(N\\) é grande relativamente a \\(NT\\). Esta perda de graus de liberdade pode ser problemática em painéis com muitos indivíduos observados por poucos períodos."
  },
  {
    "objectID": "index.html#estimadores-alternativos-primeiras-diferenças",
    "href": "index.html#estimadores-alternativos-primeiras-diferenças",
    "title": "Avaliação de Política Públicas",
    "section": "Estimadores Alternativos: Primeiras Diferenças",
    "text": "Estimadores Alternativos: Primeiras Diferenças\nUma alternativa ao estimador within é o estimador de primeiras diferenças, que elimina os efeitos fixos através de diferenciação temporal em vez de demeaning:\n\\[y_{it} - y_{i,t-1} = (x_{it} - x_{i,t-1})'\\beta + (\\varepsilon_{it} - \\varepsilon_{i,t-1})\\]\nou:\n\\[\\Delta y_{it} = \\Delta x_{it}'\\beta + \\Delta \\varepsilon_{it}\\]\nO estimador de primeiras diferenças é obtido aplicando OLS a esta equação diferenciada.\n\nEquivalência e Diferenças com o Estimador Within\nQuando \\(T = 2\\), os estimadores within e primeiras diferenças são idênticos. Para \\(T > 2\\), ambos são consistentes sob os mesmos pressupostos, mas diferem em eficiência dependendo da estrutura de correlação serial dos erros.\nSe \\(\\varepsilon_{it}\\) segue um passeio aleatório, o estimador de primeiras diferenças é mais eficiente. Se \\(\\varepsilon_{it}\\) é não correlacionado serialmente, o estimador within é mais eficiente. Na prática, a escolha entre os dois estimadores pode ser baseada em testes de especificação ou considerações teóricas sobre a natureza dos choques idiossincráticos."
  },
  {
    "objectID": "index.html#extensões-e-variações-do-modelo-de-efeitos-fixos",
    "href": "index.html#extensões-e-variações-do-modelo-de-efeitos-fixos",
    "title": "Avaliação de Política Públicas",
    "section": "Extensões e Variações do Modelo de Efeitos Fixos",
    "text": "Extensões e Variações do Modelo de Efeitos Fixos\n\nEfeitos Fixos Bidirecionais\nUma extensão comum do modelo básico de efeitos fixos é a inclusão de efeitos fixos temporais além dos efeitos fixos individuais:\n\\[y_{it} = \\alpha_i + \\gamma_t + x_{it}'\\beta + \\varepsilon_{it}\\]\nonde \\(\\gamma_t\\) são efeitos fixos temporais que capturam choques comuns a todos os indivíduos em cada período. Esta especificação é particularmente útil quando existem fatores macroeconômicos, mudanças de política, ou outros choques agregados que afetam todos os indivíduos simultaneamente.\nA estimação de modelos com efeitos fixos bidirecionais requer a inclusão de dummies tanto para indivíduos quanto para períodos, ou o uso de transformações que eliminem ambos os tipos de efeitos fixos.\n\n\nModelos com Efeitos Fixos Interativos\nEm algumas aplicações, pode ser apropriado permitir que os efeitos de variáveis observáveis variem entre indivíduos. Isto pode ser modelado através de efeitos fixos interativos:\n\\[y_{it} = \\alpha_i + x_{it}'\\beta_i + \\varepsilon_{it}\\]\nonde \\(\\beta_i\\) são coeficientes específicos para cada indivíduo. Este modelo é mais flexível, mas requer \\(N \\times K\\) parâmetros adicionais e pode enfrentar problemas de identificação em painéis curtos.\n\n\nModelos de Efeitos Fixos com Heterogeneidade de Inclinação\nUma abordagem intermediária permite que alguns coeficientes variem entre indivíduos enquanto outros permanecem constantes:\n\\[y_{it} = \\alpha_i + x_{1it}'\\beta + x_{2it}'\\beta_i + \\varepsilon_{it}\\]\nonde \\(x_{1it}\\) inclui variáveis com efeitos homogêneos e \\(x_{2it}\\) inclui variáveis com efeitos heterogêneos. Esta especificação oferece flexibilidade adicional mantendo parcimônia paramétrica."
  },
  {
    "objectID": "index.html#tabela-comparativa-de-características-fundamentais",
    "href": "index.html#tabela-comparativa-de-características-fundamentais",
    "title": "Avaliação de Política Públicas",
    "section": "Tabela Comparativa de Características Fundamentais",
    "text": "Tabela Comparativa de Características Fundamentais\nA Table 2 apresenta uma síntese das características fundamentais dos três modelos de painel linear, facilitando a comparação direta de suas propriedades e limitações.\n\n\nTable 2: Comparativo das Características dos Modelos de Painel\n\n\n\n\n\n\n\n\nCaracterística\nPooled OLS\nEfeitos Aleatórios\nEfeitos Fixos\n\n\n\n\nPressuposto sobre \\(\\alpha_i\\)\nInexistente\n\\(E[\\alpha_i \\| x_{it}] = 0\\)\nCorrelação arbitrária\n\n\nEstrutura de correlação\nIndependência\nEquicorrelacionada\nArbitrária within\n\n\nVariáveis invariantes no tempo\nIdentificadas\nIdentificadas\nNão identificadas\n\n\nRobustez à correlação \\((\\alpha_i, x_{it})\\)\nNão\nNão\nSim\n\n\nEficiência (sob pressupostos corretos)\nAlta\nMáxima\nModerada\n\n\nGraus de liberdade consumidos\n\\(K+1\\)\n\\(K+3\\)\n\\(K+N\\)\n\n\nAdequado para \\(N\\) grande, \\(T\\) pequeno\nSim\nSim\nLimitado\n\n\n\n\nEsta tabela revela claramente os trade-offs envolvidos na escolha entre os diferentes modelos. O modelo pooled oferece simplicidade e eficiência sob pressupostos restritivos, mas carece de robustez. O modelo de efeitos aleatórios oferece eficiência máxima e permite identificação de todos os parâmetros, mas requer pressupostos fortes sobre a independência dos efeitos individuais. O modelo de efeitos fixos oferece máxima robustez, mas ao custo de menor eficiência e impossibilidade de identificar efeitos de variáveis invariantes no tempo."
  },
  {
    "objectID": "index.html#cenários-de-aplicação-recomendados",
    "href": "index.html#cenários-de-aplicação-recomendados",
    "title": "Avaliação de Política Públicas",
    "section": "Cenários de Aplicação Recomendados",
    "text": "Cenários de Aplicação Recomendados\n\nQuando Usar o Modelo Pooled\nO modelo pooled é apropriado em situações específicas e relativamente raras:\nHomogeneidade Genuína: Quando existe razão teórica ou empírica para acreditar que as unidades de observação são genuinamente homogêneas em relação aos fatores que afetam a variável dependente. Isto pode ocorrer em experimentos controlados ou em análises de mercados com produtos e participantes altamente padronizados.\nAnálises Exploratórias: Como ponto de partida em análises exploratórias, onde a simplicidade metodológica é valorizada sobre a sofisticação. Os resultados do modelo pooled podem servir como benchmark para comparação com modelos mais complexos.\nPainéis Muito Curtos: Em painéis com apenas dois períodos, onde a distinção entre modelos pode ser menos crítica e a simplicidade do modelo pooled pode ser vantajosa.\n\n\nQuando Usar o Modelo de Efeitos Aleatórios\nO modelo de efeitos aleatórios é apropriado quando:\nInteresse em Variáveis Invariantes no Tempo: Quando o objetivo principal da pesquisa é estimar efeitos de características demográficas, geográficas, ou outras variáveis que não mudam ao longo do período de observação.\nAmostragem Aleatória de uma População: Quando as unidades de observação representam uma amostra aleatória de uma população maior, e não há razão teórica para esperar correlação sistemática entre características não observadas e as variáveis explicativas.\nEficiência é Prioritária: Quando a eficiência na estimação é prioritária e existe confiança na validade dos pressupostos do modelo, particularmente a exogeneidade dos efeitos aleatórios.\n\n\nQuando Usar o Modelo de Efeitos Fixos\nO modelo de efeitos fixos é frequentemente a escolha preferida em aplicações microeconométricas:\nPresença Provável de Heterogeneidade Correlacionada: Quando existe razão teórica ou empírica para suspeitar que características não observadas estão correlacionadas com as variáveis explicativas. Esta situação é comum em estudos de retornos à educação, efeitos de políticas públicas, ou análises de produtividade.\nFoco na Identificação Causal: Quando o objetivo principal é identificação causal e a robustez é prioritária sobre a eficiência. O modelo de efeitos fixos oferece uma estratégia de identificação credível baseada na variação within.\nDisponibilidade de Variação Temporal Suficiente: Quando as variáveis explicativas de interesse apresentam variação temporal suficiente dentro das unidades de observação para permitir identificação precisa dos parâmetros."
  },
  {
    "objectID": "index.html#o-problema-dos-erros-padrão-em-dados-de-painel",
    "href": "index.html#o-problema-dos-erros-padrão-em-dados-de-painel",
    "title": "Avaliação de Política Públicas",
    "section": "O Problema dos Erros Padrão em Dados de Painel",
    "text": "O Problema dos Erros Padrão em Dados de Painel\nA inferência estatística em modelos de painel apresenta desafios únicos relacionados à estrutura de correlação dos dados. A presença de múltiplas observações para cada unidade cria dependência entre observações que deve ser adequadamente considerada no cálculo dos erros padrão.\n\nCorrelação Temporal e Spatial\nEm dados de painel, duas fontes principais de correlação podem afetar a inferência:\nCorrelação Temporal: Observações do mesmo indivíduo em diferentes períodos tendem a ser correlacionadas devido à persistência de características individuais e choques. Esta correlação viola o pressuposto de independência do OLS clássico.\nCorrelação Cross-Section: Em alguns contextos, observações de diferentes indivíduos no mesmo período podem ser correlacionadas devido a choques comuns, efeitos de pares, ou outras formas de interdependência.\n\n\nConsequências para a Inferência\nA presença de correlação não considerada tem consequências graves para a inferência estatística:\nSubestimação dos Erros Padrão: Os erros padrão usuais do OLS assumem independência das observações. Na presença de correlação positiva, estes erros padrão subestimam a verdadeira incerteza dos estimadores.\nInflação das Estatísticas t: Erros padrão subestimados resultam em estatísticas t inflacionadas, levando a rejeições espúrias da hipótese nula e conclusões errôneas sobre significância estatística.\nIntervalos de Confiança Incorretos: Intervalos de confiança baseados em erros padrão incorretos não mantêm a cobertura nominal, comprometendo a inferência estatística."
  },
  {
    "objectID": "index.html#soluções-para-inferência-robusta",
    "href": "index.html#soluções-para-inferência-robusta",
    "title": "Avaliação de Política Públicas",
    "section": "Soluções para Inferência Robusta",
    "text": "Soluções para Inferência Robusta\n\nErros Padrão Clustered\nA solução mais comum para o problema de correlação em dados de painel é o uso de erros padrão robustos a clusters, onde cada indivíduo constitui um cluster. Esta abordagem permite correlação arbitrária entre observações do mesmo indivíduo, mantendo o pressuposto de independência entre indivíduos.\nA matriz de variância-covariância robusta a clusters é:\n\\[\\hat{V}_{cluster} = (X'X)^{-1}\\left(\\sum_{i=1}^N X_i'\\hat{u}_i\\hat{u}_i'X_i\\right)(X'X)^{-1}\\]\nEsta correção é válida assintoticamente quando o número de clusters (\\(N\\)) é grande, tipicamente requerendo \\(N \\geq 50\\) para propriedades assintóticas adequadas.\n\n\nBootstrap para Painéis\nEm situações onde o número de clusters é pequeno ou a estrutura de correlação é complexa, métodos de bootstrap podem fornecer inferência mais confiável. O bootstrap para dados de painel deve preservar a estrutura de dependência dos dados, tipicamente reamostrando clusters inteiros em vez de observações individuais.\n\n\nCorreções de Pequenas Amostras\nQuando o número de clusters é pequeno, correções de pequenas amostras podem melhorar as propriedades dos erros padrão clustered. Estas correções incluem ajustes nos graus de liberdade e fatores de correção para viés de pequenas amostras."
  },
  {
    "objectID": "index.html#teste-de-hausman",
    "href": "index.html#teste-de-hausman",
    "title": "Avaliação de Política Públicas",
    "section": "Teste de Hausman",
    "text": "Teste de Hausman\nO teste de Hausman é o procedimento padrão para escolher entre modelos de efeitos aleatórios e efeitos fixos. Este teste baseia-se na ideia de que, sob a hipótese nula de que os efeitos aleatórios são não correlacionados com os regressores, ambos os estimadores são consistentes, mas o estimador de efeitos aleatórios é mais eficiente.\nA estatística de teste é:\n\\[H = (\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE})'[\\hat{V}_{FE} - \\hat{V}_{RE}]^{-1}(\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE})\\]\nonde \\(\\hat{\\beta}_{FE}\\) e \\(\\hat{\\beta}_{RE}\\) são os estimadores de efeitos fixos e aleatórios, respectivamente, e \\(\\hat{V}_{FE}\\) e \\(\\hat{V}_{RE}\\) são suas matrizes de variância-covariância estimadas.\nSob a hipótese nula, a estatística \\(H\\) segue uma distribuição qui-quadrado com graus de liberdade igual ao número de coeficientes testados. A rejeição da hipótese nula favorece o modelo de efeitos fixos."
  },
  {
    "objectID": "index.html#testes-de-poolabilidade",
    "href": "index.html#testes-de-poolabilidade",
    "title": "Avaliação de Política Públicas",
    "section": "Testes de Poolabilidade",
    "text": "Testes de Poolabilidade\nAntes de escolher entre efeitos fixos e aleatórios, é útil testar se a estrutura de painel é necessária ou se o modelo pooled é adequado.\n\nTeste F para Efeitos Fixos\nO teste F padrão compara o modelo de efeitos fixos com o modelo pooled:\n\\[F = \\frac{(SSR_{pooled} - SSR_{FE})/(N-1)}{SSR_{FE}/(NT-N-K)}\\]\nonde \\(SSR_{pooled}\\) e \\(SSR_{FE}\\) são as somas dos quadrados dos resíduos dos modelos pooled e efeitos fixos, respectivamente.\n\n\nTeste de Breusch-Pagan para Efeitos Aleatórios\nO teste de Breusch-Pagan testa a hipótese nula de que \\(\\sigma_\\alpha^2 = 0\\), ou seja, que não existem efeitos aleatórios e o modelo pooled é apropriado."
  },
  {
    "objectID": "index.html#princípios-orientadores-para-a-escolha",
    "href": "index.html#princípios-orientadores-para-a-escolha",
    "title": "Avaliação de Política Públicas",
    "section": "Princípios Orientadores para a Escolha",
    "text": "Princípios Orientadores para a Escolha\nA experiência acumulada na literatura econométrica sugere alguns princípios orientadores:\nPriorize a Robustez: Em caso de dúvida sobre a validade dos pressupostos, prefira modelos mais robustos. O modelo de efeitos fixos oferece robustez à correlação entre efeitos individuais e regressores, uma violação comum em aplicações microeconométricas.\nConsidere o Contexto Teórico: A plausibilidade dos pressupostos deve ser avaliada à luz da teoria econômica e do conhecimento institucional. Em estudos de retornos à educação, por exemplo, a correlação entre habilidade não observada e educação é teoricamente plausível, favorecendo modelos de efeitos fixos.\nUse Testes de Especificação: Testes formais como o teste de Hausman podem fornecer evidência estatística sobre a adequação dos pressupostos, mas devem ser interpretados em conjunto com considerações teóricas.\nReporte Múltiplas Especificações: A prática de reportar resultados de múltiplas especificações permite avaliar a robustez dos achados e fornece transparência sobre a sensibilidade dos resultados às escolhas metodológicas."
  },
  {
    "objectID": "index.html#desenvolvimentos-futuros",
    "href": "index.html#desenvolvimentos-futuros",
    "title": "Avaliação de Política Públicas",
    "section": "Desenvolvimentos Futuros",
    "text": "Desenvolvimentos Futuros\nA literatura de dados de painel continua evoluindo, com desenvolvimentos recentes incluindo:\nModelos com Efeitos Fixos Interativos: Permitindo heterogeneidade mais rica na forma como variáveis observáveis afetam diferentes unidades.\nMétodos para Painéis com Dependência Cross-Section: Lidando com correlação entre unidades devido a fatores comuns não observados.\nAbordagens Bayesianas: Oferecendo frameworks alternativos para incorporar incerteza sobre a especificação do modelo.\nMétodos de Machine Learning: Explorando abordagens não paramétricas para modelar heterogeneidade complexa."
  },
  {
    "objectID": "index.html#reflexão-final",
    "href": "index.html#reflexão-final",
    "title": "Avaliação de Política Públicas",
    "section": "Reflexão Final",
    "text": "Reflexão Final\nA análise de dados de painel exemplifica um tema central da econometria moderna: o trade-off entre robustez e eficiência. Não existe uma solução única que seja ótima em todas as situações. A escolha informada entre modelos requer compreensão profunda dos pressupostos subjacentes, avaliação cuidadosa de sua plausibilidade no contexto específico, e transparência sobre as implicações das escolhas metodológicas.\nO domínio destes conceitos e técnicas é essencial para qualquer pesquisador que trabalhe com dados longitudinais. A capacidade de navegar entre diferentes especificações, compreender suas implicações, e comunicar claramente as escolhas metodológicas distingue a análise empírica rigorosa da aplicação mecânica de técnicas estatísticas.\nÀ medida que a disponibilidade de dados de painel continua crescendo, impulsionada por avanços na coleta e armazenamento de dados, a importância destes métodos apenas aumentará. A base conceitual sólida fornecida por este comparativo dos modelos fundamentais de painel linear constitui o alicerce sobre o qual técnicas mais avançadas podem ser construídas e aplicadas com confiança e rigor."
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Avaliação de Política Públicas",
    "section": "Referências",
    "text": "Referências\n[1] Cameron, A. C., & Trivedi, P. K. (2005). Microeconometrics: Methods and Applications. Cambridge University Press.\n[2] Chamberlain, G. (1980). Analysis of covariance with qualitative data. The Review of Economic Studies, 47(1), 225-238.\n[3] Hausman, J. A. (1978). Specification tests in econometrics. Econometrica, 46(6), 1251-1271.\n[4] Hsiao, C. (2014). Analysis of Panel Data (3rd ed.). Cambridge University Press.\n[5] Wooldridge, J. M. (2010). Econometric Analysis of Cross Section and Panel Data (2nd ed.). MIT Press."
  },
  {
    "objectID": "index.html#especificação",
    "href": "index.html#especificação",
    "title": "Avaliação de Política Públicas",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + u_{it}\\]\nForma matricial: \\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{u}\\]\nonde \\(\\mathbf{X}\\) inclui coluna de 1’s para o intercepto."
  },
  {
    "objectID": "index.html#hipóteses-fundamentais",
    "href": "index.html#hipóteses-fundamentais",
    "title": "Avaliação de Política Públicas",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade Estrita: \\[E[u_{it}|\\mathbf{X}_i] = 0, \\quad \\forall i,t\\]\nH2. Homocedasticidade: \\[Var[u_{it}|\\mathbf{X}_i] = \\sigma^2, \\quad \\forall i,t\\]\nH3. Não Autocorrelação: \\[Cov[u_{it}, u_{is}|\\mathbf{X}_i] = 0, \\quad \\forall t \\neq s\\]\nMatriz de Variância-Covariância: \\[\\boldsymbol{\\Omega} = E[\\mathbf{u}\\mathbf{u}'|\\mathbf{X}] = \\sigma^2 \\mathbf{I}_{NT}\\]"
  },
  {
    "objectID": "index.html#estimador",
    "href": "index.html#estimador",
    "title": "Avaliação de Política Públicas",
    "section": "Estimador",
    "text": "Estimador\n\\[\\hat{\\boldsymbol{\\beta}}_{POLS} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}\\]\nPropriedades: Consistente e eficiente sob H1-H3."
  },
  {
    "objectID": "index.html#especificação-1",
    "href": "index.html#especificação-1",
    "title": "Avaliação de Política Públicas",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + (\\alpha_i + \\varepsilon_{it})\\]\nonde: - \\(\\alpha_i \\sim iid(0, \\sigma_\\alpha^2)\\): efeito aleatório individual - \\(\\varepsilon_{it} \\sim iid(0, \\sigma_\\varepsilon^2)\\): erro idiossincrático - \\(u_{it} = \\alpha_i + \\varepsilon_{it}\\): erro composto"
  },
  {
    "objectID": "index.html#hipóteses-fundamentais-1",
    "href": "index.html#hipóteses-fundamentais-1",
    "title": "Avaliação de Política Públicas",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade dos Efeitos Aleatórios: \\[E[\\alpha_i|\\mathbf{X}_i] = 0\\]\nH2. Exogeneidade Estrita: \\[E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\]\nH3. Independência: \\[Cov[\\alpha_i, \\varepsilon_{it}] = 0, \\quad \\forall i,t\\]"
  },
  {
    "objectID": "index.html#estrutura-de-correlação",
    "href": "index.html#estrutura-de-correlação",
    "title": "Avaliação de Política Públicas",
    "section": "Estrutura de Correlação",
    "text": "Estrutura de Correlação\nVariância: \\[Var[u_{it}] = \\sigma_\\alpha^2 + \\sigma_\\varepsilon^2\\]\nCovariância: \\[Cov[u_{it}, u_{is}] = \\sigma_\\alpha^2, \\quad t \\neq s\\]\nCorrelação Intraclasse: \\[\\rho = \\frac{\\sigma_\\alpha^2}{\\sigma_\\alpha^2 + \\sigma_\\varepsilon^2}\\]"
  },
  {
    "objectID": "index.html#matriz-de-variância-covariância",
    "href": "index.html#matriz-de-variância-covariância",
    "title": "Avaliação de Política Públicas",
    "section": "Matriz de Variância-Covariância",
    "text": "Matriz de Variância-Covariância\nPara cada indivíduo \\(i\\): \\[\\boldsymbol{\\Omega}_i = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma_\\varepsilon^2 \\mathbf{I}_T + \\sigma_\\alpha^2 \\mathbf{J}_T\\]\nonde \\(\\mathbf{J}_T = \\mathbf{e}_T\\mathbf{e}_T'\\) (matriz de 1’s).\nForma completa: \\[\\boldsymbol{\\Omega} = \\text{diag}(\\boldsymbol{\\Omega}_1, ..., \\boldsymbol{\\Omega}_N)\\]"
  },
  {
    "objectID": "index.html#transformação-gls",
    "href": "index.html#transformação-gls",
    "title": "Avaliação de Política Públicas",
    "section": "Transformação GLS",
    "text": "Transformação GLS\nParâmetro de transformação: \\[\\theta = 1 - \\sqrt{\\frac{\\sigma_\\varepsilon^2}{\\sigma_\\varepsilon^2 + T\\sigma_\\alpha^2}}\\]\nDados transformados: \\[y_{it}^* = y_{it} - \\theta\\bar{y}_i, \\quad \\mathbf{x}_{it}^* = \\mathbf{x}_{it} - \\theta\\bar{\\mathbf{x}}_i\\]\nEstimador GLS: \\[\\hat{\\boldsymbol{\\beta}}_{RE} = (\\mathbf{X}^{*'}\\mathbf{X}^*)^{-1}\\mathbf{X}^{*'}\\mathbf{y}^*\\]"
  },
  {
    "objectID": "index.html#especificação-2",
    "href": "index.html#especificação-2",
    "title": "Avaliação de Política Públicas",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha_i + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + \\varepsilon_{it}\\]\nonde \\(\\alpha_i\\) são parâmetros fixos específicos para cada indivíduo."
  },
  {
    "objectID": "index.html#hipóteses-fundamentais-2",
    "href": "index.html#hipóteses-fundamentais-2",
    "title": "Avaliação de Política Públicas",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade Estrita: \\[E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\]\nH2. Homocedasticidade: \\[Var[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = \\sigma^2\\]\nH3. Não Autocorrelação: \\[Cov[\\varepsilon_{it}, \\varepsilon_{is}|\\alpha_i, \\mathbf{X}_i] = 0, \\quad t \\neq s\\]\nObservação Crucial: Permite \\(Cov[\\alpha_i, \\mathbf{x}_{it}] \\neq 0\\)"
  },
  {
    "objectID": "index.html#representação-matricial-com-dummies",
    "href": "index.html#representação-matricial-com-dummies",
    "title": "Avaliação de Política Públicas",
    "section": "Representação Matricial com Dummies",
    "text": "Representação Matricial com Dummies\n\\[\\mathbf{y} = \\mathbf{D}\\boldsymbol{\\alpha} + \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\]\nonde \\(\\mathbf{D}\\) é matriz \\(NT \\times N\\) de dummies individuais: \\[\\mathbf{D} = \\begin{pmatrix} \\mathbf{e}_T & \\mathbf{0} & \\cdots & \\mathbf{0} \\\\ \\mathbf{0} & \\mathbf{e}_T & \\cdots & \\mathbf{0} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\mathbf{0} & \\mathbf{0} & \\cdots & \\mathbf{e}_T \\end{pmatrix}\\]"
  },
  {
    "objectID": "index.html#transformação-within",
    "href": "index.html#transformação-within",
    "title": "Avaliação de Política Públicas",
    "section": "Transformação Within",
    "text": "Transformação Within\nMatriz de transformação within: \\[\\mathbf{Q} = \\mathbf{I}_{NT} - \\mathbf{D}(\\mathbf{D}'\\mathbf{D})^{-1}\\mathbf{D}'\\]\nPropriedade: \\(\\mathbf{Q}\\mathbf{D} = \\mathbf{0}\\) (elimina efeitos fixos)\nDados transformados: \\[\\ddot{\\mathbf{y}} = \\mathbf{Q}\\mathbf{y}, \\quad \\ddot{\\mathbf{X}} = \\mathbf{Q}\\mathbf{X}\\]\nInterpretação: \\(\\ddot{y}_{it} = y_{it} - \\bar{y}_i\\), \\(\\ddot{\\mathbf{x}}_{it} = \\mathbf{x}_{it} - \\bar{\\mathbf{x}}_i\\)"
  },
  {
    "objectID": "index.html#estimador-within",
    "href": "index.html#estimador-within",
    "title": "Avaliação de Política Públicas",
    "section": "Estimador Within",
    "text": "Estimador Within\n\\[\\hat{\\boldsymbol{\\beta}}_{FE} = (\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{X}})^{-1}\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{y}}\\]\nForma alternativa: \\[\\hat{\\boldsymbol{\\beta}}_{FE} = \\left(\\sum_{i=1}^N \\sum_{t=1}^T \\ddot{\\mathbf{x}}_{it}\\ddot{\\mathbf{x}}_{it}'\\right)^{-1} \\sum_{i=1}^N \\sum_{t=1}^T \\ddot{\\mathbf{x}}_{it}\\ddot{y}_{it}\\]"
  },
  {
    "objectID": "index.html#tabela-de-consistência",
    "href": "index.html#tabela-de-consistência",
    "title": "Avaliação de Política Públicas",
    "section": "Tabela de Consistência",
    "text": "Tabela de Consistência\n\n\n\nModelo Verdadeiro\nPooled OLS\nRandom Effects\nFixed Effects\n\n\n\n\nPooled\n✓\n✓\n✓\n\n\nRandom Effects\n✓\n✓\n✓\n\n\nFixed Effects\n✗\n✗\n✓"
  },
  {
    "objectID": "index.html#condições-de-identificação",
    "href": "index.html#condições-de-identificação",
    "title": "Avaliação de Política Públicas",
    "section": "Condições de Identificação",
    "text": "Condições de Identificação\nPooled OLS: Requer \\(E[u_{it}|\\mathbf{x}_{it}] = 0\\)\nRandom Effects: Requer \\(E[\\alpha_i|\\mathbf{X}_i] = 0\\)\nFixed Effects: Apenas requer \\(E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\)"
  },
  {
    "objectID": "index.html#variáveis-identificadas",
    "href": "index.html#variáveis-identificadas",
    "title": "Avaliação de Política Públicas",
    "section": "Variáveis Identificadas",
    "text": "Variáveis Identificadas\n\nPooled/RE: Todas as variáveis (incluindo invariantes no tempo)\nFE: Apenas variáveis que variam no tempo"
  },
  {
    "objectID": "index.html#estruturas-matriciais-chave",
    "href": "index.html#estruturas-matriciais-chave",
    "title": "Avaliação de Política Públicas",
    "section": "Estruturas Matriciais Chave",
    "text": "Estruturas Matriciais Chave\nBetween transformation: \\[\\mathbf{P} = \\mathbf{D}(\\mathbf{D}'\\mathbf{D})^{-1}\\mathbf{D}' = \\mathbf{I}_N \\otimes \\frac{1}{T}\\mathbf{J}_T\\]\nWithin transformation: \\[\\mathbf{Q} = \\mathbf{I}_{NT} - \\mathbf{P}\\]\nPropriedades: - \\(\\mathbf{P} + \\mathbf{Q} = \\mathbf{I}_{NT}\\) - \\(\\mathbf{P}\\mathbf{Q} = \\mathbf{Q}\\mathbf{P} = \\mathbf{0}\\) - \\(\\mathbf{P}^2 = \\mathbf{P}\\), \\(\\mathbf{Q}^2 = \\mathbf{Q}\\) (idempotentes)"
  },
  {
    "objectID": "index.html#decomposição-da-variação",
    "href": "index.html#decomposição-da-variação",
    "title": "Avaliação de Política Públicas",
    "section": "Decomposição da Variação",
    "text": "Decomposição da Variação\n\\[\\mathbf{X}'\\mathbf{X} = \\mathbf{X}'\\mathbf{P}\\mathbf{X} + \\mathbf{X}'\\mathbf{Q}\\mathbf{X}\\]\n\n\\(\\mathbf{X}'\\mathbf{P}\\mathbf{X}\\): variação between\n\\(\\mathbf{X}'\\mathbf{Q}\\mathbf{X}\\): variação within"
  },
  {
    "objectID": "index.html#estimadores-em-termos-das-transformações",
    "href": "index.html#estimadores-em-termos-das-transformações",
    "title": "Avaliação de Política Públicas",
    "section": "Estimadores em Termos das Transformações",
    "text": "Estimadores em Termos das Transformações\nBetween estimator: \\[\\hat{\\boldsymbol{\\beta}}_B = (\\mathbf{X}'\\mathbf{P}\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{P}\\mathbf{y}\\]\nWithin estimator: \\[\\hat{\\boldsymbol{\\beta}}_W = (\\mathbf{X}'\\mathbf{Q}\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{Q}\\mathbf{y}\\]\nRandom Effects (combinação ponderada): \\[\\hat{\\boldsymbol{\\beta}}_{RE} = \\mathbf{W}_B\\hat{\\boldsymbol{\\beta}}_B + \\mathbf{W}_W\\hat{\\boldsymbol{\\beta}}_W\\]\nonde os pesos \\(\\mathbf{W}_B\\) e \\(\\mathbf{W}_W\\) dependem de \\(\\sigma_\\alpha^2\\) e \\(\\sigma_\\varepsilon^2\\).\n\nPróximos passos: Derivação detalhada de cada estimador, propriedades assintóticas e testes de especificação."
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html",
    "href": "posts/Modelos-em-Painel/index.html",
    "title": "Modelo de dados em painel",
    "section": "",
    "text": "Dados de painel: \\(\\{y_{it}, x_{it}: i = 1, ..., N; t = 1, ..., T\\}\\)\n\n\\(i\\): índice de indivíduos (cross-section)\n\\(t\\): índice temporal\n\n\\(N\\): número de indivíduos\n\\(T\\): número de períodos\n\n\n\n\nPara cada indivíduo \\(i\\):\n\\[\\mathbf{y}_i = \\begin{pmatrix} y_{i1} \\\\ y_{i2} \\\\ \\vdots \\\\ y_{iT} \\end{pmatrix}, \\quad \\mathbf{X}_i = \\begin{pmatrix} x_{i1}' \\\\ x_{i2}' \\\\ \\vdots \\\\ x_{iT}' \\end{pmatrix}, \\quad \\boldsymbol{\\varepsilon}_i = \\begin{pmatrix} \\varepsilon_{i1} \\\\ \\varepsilon_{i2} \\\\ \\vdots \\\\ \\varepsilon_{iT} \\end{pmatrix}\\]\nDados empilhados (pooled):\n\\[\\mathbf{y} = \\begin{pmatrix} \\mathbf{y}_1 \\\\ \\mathbf{y}_2 \\\\ \\vdots \\\\ \\mathbf{y}_N \\end{pmatrix}_{NT \\times 1}, \\quad \\mathbf{X} = \\begin{pmatrix} \\mathbf{X}_1 \\\\ \\mathbf{X}_2 \\\\ \\vdots \\\\ \\mathbf{X}_N \\end{pmatrix}_{NT \\times K}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#especificação",
    "href": "posts/Modelos-em-Painel/index.html#especificação",
    "title": "Modelo de dados em painel",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + u_{it}\\]\nForma matricial: \\[\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{u}\\]\nonde \\(\\mathbf{X}\\) inclui coluna de 1’s para o intercepto."
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais",
    "href": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais",
    "title": "Modelo de dados em painel",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade Estrita: \\[E[u_{it}|\\mathbf{X}_i] = 0, \\quad \\forall i,t\\]\nH2. Homocedasticidade: \\[Var[u_{it}|\\mathbf{X}_i] = \\sigma^2, \\quad \\forall i,t\\]\nH3. Não Autocorrelação: \\[Cov[u_{it}, u_{is}|\\mathbf{X}_i] = 0, \\quad \\forall t \\neq s\\]\nMatriz de Variância-Covariância: \\[\\boldsymbol{\\Omega} = E[\\mathbf{u}\\mathbf{u}'|\\mathbf{X}] = \\sigma^2 \\mathbf{I}_{NT}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#estimador",
    "href": "posts/Modelos-em-Painel/index.html#estimador",
    "title": "Modelo de dados em painel",
    "section": "Estimador",
    "text": "Estimador\n\\[\\hat{\\boldsymbol{\\beta}}_{POLS} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}\\]\nPropriedades: Consistente e eficiente sob H1-H3."
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#especificação-1",
    "href": "posts/Modelos-em-Painel/index.html#especificação-1",
    "title": "Modelo de dados em painel",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + (\\alpha_i + \\varepsilon_{it})\\]\nonde: - \\(\\alpha_i \\sim iid(0, \\sigma_\\alpha^2)\\): efeito aleatório individual - \\(\\varepsilon_{it} \\sim iid(0, \\sigma_\\varepsilon^2)\\): erro idiossincrático - \\(u_{it} = \\alpha_i + \\varepsilon_{it}\\): erro composto"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais-1",
    "href": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais-1",
    "title": "Modelo de dados em painel",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade dos Efeitos Aleatórios: \\[E[\\alpha_i|\\mathbf{X}_i] = 0\\]\nH2. Exogeneidade Estrita: \\[E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\]\nH3. Independência: \\[Cov[\\alpha_i, \\varepsilon_{it}] = 0, \\quad \\forall i,t\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#estrutura-de-correlação",
    "href": "posts/Modelos-em-Painel/index.html#estrutura-de-correlação",
    "title": "Modelo de dados em painel",
    "section": "Estrutura de Correlação",
    "text": "Estrutura de Correlação\nVariância: \\[Var[u_{it}] = \\sigma_\\alpha^2 + \\sigma_\\varepsilon^2\\]\nCovariância: \\[Cov[u_{it}, u_{is}] = \\sigma_\\alpha^2, \\quad t \\neq s\\]\nCorrelação interindividual: \\[\\rho = \\frac{\\sigma_\\alpha^2}{\\sigma_\\alpha^2 + \\sigma_\\varepsilon^2}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#matriz-de-variância-covariância",
    "href": "posts/Modelos-em-Painel/index.html#matriz-de-variância-covariância",
    "title": "Modelo de dados em painel",
    "section": "Matriz de Variância-Covariância",
    "text": "Matriz de Variância-Covariância\nPara cada indivíduo \\(i\\): \\[\\boldsymbol{\\Omega}_i = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma_\\varepsilon^2 \\mathbf{I}_T + \\sigma_\\alpha^2 \\mathbf{J}_T\\]\nonde \\(\\mathbf{J}_T = \\mathbf{e}_T\\mathbf{e}_T'\\) (matriz de 1’s).\nForma completa: \\[\\boldsymbol{\\Omega} = \\text{diag}(\\boldsymbol{\\Omega}_1, ..., \\boldsymbol{\\Omega}_N)\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#transformação-gls",
    "href": "posts/Modelos-em-Painel/index.html#transformação-gls",
    "title": "Modelo de dados em painel",
    "section": "Transformação GLS",
    "text": "Transformação GLS\nParâmetro de transformação: \\[\\theta = 1 - \\sqrt{\\frac{\\sigma_\\varepsilon^2}{\\sigma_\\varepsilon^2 + T\\sigma_\\alpha^2}}\\]\nDados transformados: \\[y_{it}^* = y_{it} - \\theta\\bar{y}_i, \\quad \\mathbf{x}_{it}^* = \\mathbf{x}_{it} - \\theta\\bar{\\mathbf{x}}_i\\]\nEstimador GLS: \\[\\hat{\\boldsymbol{\\beta}}_{RE} = (\\mathbf{X}^{*'}\\mathbf{X}^*)^{-1}\\mathbf{X}^{*'}\\mathbf{y}^*\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#especificação-2",
    "href": "posts/Modelos-em-Painel/index.html#especificação-2",
    "title": "Modelo de dados em painel",
    "section": "Especificação",
    "text": "Especificação\n\\[y_{it} = \\alpha_i + \\mathbf{x}_{it}'\\boldsymbol{\\beta} + \\varepsilon_{it}\\]\nonde \\(\\alpha_i\\) são parâmetros fixos específicos para cada indivíduo."
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais-2",
    "href": "posts/Modelos-em-Painel/index.html#hipóteses-fundamentais-2",
    "title": "Modelo de dados em painel",
    "section": "Hipóteses Fundamentais",
    "text": "Hipóteses Fundamentais\nH1. Exogeneidade Estrita: \\[E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\]\nH2. Homocedasticidade: \\[Var[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = \\sigma^2\\]\nH3. Não Autocorrelação: \\[Cov[\\varepsilon_{it}, \\varepsilon_{is}|\\alpha_i, \\mathbf{X}_i] = 0, \\quad t \\neq s\\]\nObservação Crucial: Permite \\(Cov[\\alpha_i, \\mathbf{x}_{it}] \\neq 0\\)"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#representação-matricial-com-dummies",
    "href": "posts/Modelos-em-Painel/index.html#representação-matricial-com-dummies",
    "title": "Modelo de dados em painel",
    "section": "Representação Matricial com Dummies",
    "text": "Representação Matricial com Dummies\n\\[\\mathbf{y} = \\mathbf{D}\\boldsymbol{\\alpha} + \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\]\nonde \\(\\mathbf{D}\\) é matriz \\(NT \\times N\\) de dummies individuais: \\[\\mathbf{D} = \\begin{pmatrix} \\mathbf{e}_T & \\mathbf{0} & \\cdots & \\mathbf{0} \\\\ \\mathbf{0} & \\mathbf{e}_T & \\cdots & \\mathbf{0} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\mathbf{0} & \\mathbf{0} & \\cdots & \\mathbf{e}_T \\end{pmatrix}\\]\n\nsummary(plm(y ~ x1+x2, \n        data=painel_exemplo, \n        model=\"within\",\n        index=c(\"ID\",\"t\")))\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = y ~ x1 + x2, data = painel_exemplo, model = \"within\", \n    index = c(\"ID\", \"t\"))\n\nBalanced Panel: n = 5, T = 3, N = 15\n\nResiduals:\n    Min.  1st Qu.   Median  3rd Qu.     Max. \n-2.99457 -1.39904  0.12801  1.53272  2.58529 \n\nCoefficients:\n   Estimate Std. Error t-value  Pr(>|t|)    \nx1  1.45299    0.17932  8.1027 3.983e-05 ***\nx2 -0.56217    0.14402 -3.9034  0.004523 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    513.33\nResidual Sum of Squares: 47.588\nR-Squared:      0.9073\nAdj. R-Squared: 0.83777\nF-statistic: 39.148 on 2 and 8 DF, p-value: 7.3858e-05\n\nsummary(lm(y ~ -1+x1+x2+factor(ID), \n        data=painel_exemplo,))\n\n\nCall:\nlm(formula = y ~ -1 + x1 + x2 + factor(ID), data = painel_exemplo)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-2.995 -1.399  0.128  1.533  2.585 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \nx1            1.4530     0.1793   8.103 3.98e-05 ***\nx2           -0.5622     0.1440  -3.903  0.00452 ** \nfactor(ID)1   3.8158     2.1436   1.780  0.11293    \nfactor(ID)2   0.9769     2.1143   0.462  0.65636    \nfactor(ID)3   1.4727     1.9199   0.767  0.46507    \nfactor(ID)4   2.1189     1.5133   1.400  0.19903    \nfactor(ID)5   1.5088     1.5837   0.953  0.36863    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.439 on 8 degrees of freedom\nMultiple R-squared:  0.9474,    Adjusted R-squared:  0.9013 \nF-statistic: 20.57 on 7 and 8 DF,  p-value: 0.0001618"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#transformação-within",
    "href": "posts/Modelos-em-Painel/index.html#transformação-within",
    "title": "Modelo de dados em painel",
    "section": "Transformação Within",
    "text": "Transformação Within\nMatriz de transformação within: \\[\\mathbf{Q} = \\mathbf{I}_{NT} - \\mathbf{D}(\\mathbf{D}'\\mathbf{D})^{-1}\\mathbf{D}'\\]\nPropriedade: \\(\\mathbf{Q}\\mathbf{D} = \\mathbf{0}\\) (elimina efeitos fixos)\nDados transformados: \\[\\ddot{\\mathbf{y}} = \\mathbf{Q}\\mathbf{y}, \\quad \\ddot{\\mathbf{X}} = \\mathbf{Q}\\mathbf{X}\\]\nInterpretação: \\(\\ddot{y}_{it} = y_{it} - \\bar{y}_i\\), \\(\\ddot{\\mathbf{x}}_{it} = \\mathbf{x}_{it} - \\bar{\\mathbf{x}}_i\\)"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#estimador-within",
    "href": "posts/Modelos-em-Painel/index.html#estimador-within",
    "title": "Modelo de dados em painel",
    "section": "Estimador Within",
    "text": "Estimador Within\n\\[\\hat{\\boldsymbol{\\beta}}_{FE} = (\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{X}})^{-1}\\ddot{\\mathbf{X}}'\\ddot{\\mathbf{y}}\\]\nForma alternativa: \\[\\hat{\\boldsymbol{\\beta}}_{FE} = \\left(\\sum_{i=1}^N \\sum_{t=1}^T \\ddot{\\mathbf{x}}_{it}\\ddot{\\mathbf{x}}_{it}'\\right)^{-1} \\sum_{i=1}^N \\sum_{t=1}^T \\ddot{\\mathbf{x}}_{it}\\ddot{y}_{it}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#tabela-de-consistência",
    "href": "posts/Modelos-em-Painel/index.html#tabela-de-consistência",
    "title": "Modelo de dados em painel",
    "section": "Tabela de Consistência",
    "text": "Tabela de Consistência\n\n\n\nModelo Verdadeiro\nPooled OLS\nRandom Effects\nFixed Effects\n\n\n\n\nPooled\n✓\n✓\n✓\n\n\nRandom Effects\n✓\n✓\n✓\n\n\nFixed Effects\n✗\n✗\n✓"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#condições-de-identificação",
    "href": "posts/Modelos-em-Painel/index.html#condições-de-identificação",
    "title": "Modelo de dados em painel",
    "section": "Condições de Identificação",
    "text": "Condições de Identificação\nPooled OLS: Requer \\(E[u_{it}|\\mathbf{x}_{it}] = 0\\)\nRandom Effects: Requer \\(E[\\alpha_i|\\mathbf{X}_i] = 0\\)\nFixed Effects: Apenas requer \\(E[\\varepsilon_{it}|\\alpha_i, \\mathbf{X}_i] = 0\\)"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#variáveis-identificadas",
    "href": "posts/Modelos-em-Painel/index.html#variáveis-identificadas",
    "title": "Modelo de dados em painel",
    "section": "Variáveis Identificadas",
    "text": "Variáveis Identificadas\n\nPooled/RE: Todas as variáveis (incluindo invariantes no tempo)\nFE: Apenas variáveis que variam no tempo"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#estruturas-matriciais-chave",
    "href": "posts/Modelos-em-Painel/index.html#estruturas-matriciais-chave",
    "title": "Modelo de dados em painel",
    "section": "Estruturas Matriciais Chave",
    "text": "Estruturas Matriciais Chave\nBetween transformation: \\[\\mathbf{P} = \\mathbf{D}(\\mathbf{D}'\\mathbf{D})^{-1}\\mathbf{D}' = \\mathbf{I}_N \\otimes \\frac{1}{T}\\mathbf{J}_T\\]\nWithin transformation: \\[\\mathbf{Q} = \\mathbf{I}_{NT} - \\mathbf{P}\\]\nPropriedades: - \\(\\mathbf{P} + \\mathbf{Q} = \\mathbf{I}_{NT}\\) - \\(\\mathbf{P}\\mathbf{Q} = \\mathbf{Q}\\mathbf{P} = \\mathbf{0}\\) - \\(\\mathbf{P}^2 = \\mathbf{P}\\), \\(\\mathbf{Q}^2 = \\mathbf{Q}\\) (idempotentes)"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#decomposição-da-variação",
    "href": "posts/Modelos-em-Painel/index.html#decomposição-da-variação",
    "title": "Modelo de dados em painel",
    "section": "Decomposição da Variação",
    "text": "Decomposição da Variação\n\\[\\mathbf{X}'\\mathbf{X} = \\mathbf{X}'\\mathbf{P}\\mathbf{X} + \\mathbf{X}'\\mathbf{Q}\\mathbf{X}\\]\n\n\\(\\mathbf{X}'\\mathbf{P}\\mathbf{X}\\): variação between\n\\(\\mathbf{X}'\\mathbf{Q}\\mathbf{X}\\): variação within"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#estimadores-em-termos-das-transformações",
    "href": "posts/Modelos-em-Painel/index.html#estimadores-em-termos-das-transformações",
    "title": "Modelo de dados em painel",
    "section": "Estimadores em Termos das Transformações",
    "text": "Estimadores em Termos das Transformações\nBetween estimator: \\[\\hat{\\boldsymbol{\\beta}}_B = (\\mathbf{X}'\\mathbf{P}\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{P}\\mathbf{y}\\]\nWithin estimator: \\[\\hat{\\boldsymbol{\\beta}}_W = (\\mathbf{X}'\\mathbf{Q}\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{Q}\\mathbf{y}\\]\nRandom Effects (combinação ponderada): \\[\\hat{\\boldsymbol{\\beta}}_{RE} = \\mathbf{W}_B\\hat{\\boldsymbol{\\beta}}_B + \\mathbf{W}_W\\hat{\\boldsymbol{\\beta}}_W\\]\nonde os pesos \\(\\mathbf{W}_B\\) e \\(\\mathbf{W}_W\\) dependem de \\(\\sigma_\\alpha^2\\) e \\(\\sigma_\\varepsilon^2\\)."
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#caso-1-modelo-pooled-ols",
    "href": "posts/Modelos-em-Painel/index.html#caso-1-modelo-pooled-ols",
    "title": "Modelo de dados em painel",
    "section": "Caso 1: Modelo Pooled OLS",
    "text": "Caso 1: Modelo Pooled OLS\n\nPressupostos\n\n\\(E[u_{it}u_{js}] = 0\\) para \\(i \\neq j\\) (independência entre indivíduos)\n\\(E[u_{it}u_{is}] = 0\\) para \\(t \\neq s\\) (não autocorrelação temporal)\n\\(E[u_{it}^2] = \\sigma^2\\) (homocedasticidade)\n\n\n\nMatriz Individual \\(\\boldsymbol{\\Omega}_i\\) (Pooled)\nPara cada indivíduo \\(i\\) com \\(T\\) períodos:\n\\[\\boldsymbol{\\Omega}_i^{Pooled} = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma^2 \\mathbf{I}_T\\]\nForma explícita para \\(T = 4\\):\n\\[\\boldsymbol{\\Omega}_i^{Pooled} = \\begin{pmatrix}\n\\sigma^2 & 0 & 0 & 0 \\\\\n0 & \\sigma^2 & 0 & 0 \\\\\n0 & 0 & \\sigma^2 & 0 \\\\\n0 & 0 & 0 & \\sigma^2\n\\end{pmatrix}\\]\n\n\nMatriz Completa \\(\\boldsymbol{\\Omega}\\) (Pooled)\nPara \\(N = 3\\) indivíduos e \\(T = 4\\) períodos:\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\sigma^2 \\mathbf{I}_{NT} = \\sigma^2 \\mathbf{I}_{12}\\]\nEstrutura em blocos:\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\begin{pmatrix}\n\\boldsymbol{\\Omega}_1^{Pooled} & \\mathbf{0} & \\mathbf{0} \\\\\n\\mathbf{0} & \\boldsymbol{\\Omega}_2^{Pooled} & \\mathbf{0} \\\\\n\\mathbf{0} & \\mathbf{0} & \\boldsymbol{\\Omega}_3^{Pooled}\n\\end{pmatrix}\\]\nForma completa \\(12 \\times 12\\):\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\sigma^2 \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#caso-2-modelo-de-efeitos-aleatórios",
    "href": "posts/Modelos-em-Painel/index.html#caso-2-modelo-de-efeitos-aleatórios",
    "title": "Modelo de dados em painel",
    "section": "Caso 2: Modelo de Efeitos Aleatórios",
    "text": "Caso 2: Modelo de Efeitos Aleatórios\n\nPressupostos\n\n\\(u_{it} = \\alpha_i + \\varepsilon_{it}\\)\n\\(E[\\alpha_i^2] = \\sigma_\\alpha^2\\)\n\\(E[\\varepsilon_{it}^2] = \\sigma_\\varepsilon^2\\)\n\\(E[\\alpha_i\\varepsilon_{it}] = 0\\)\n\n\n\nCálculo da Estrutura de Correlação\nVariância: \\[Var[u_{it}] = Var[\\alpha_i + \\varepsilon_{it}] = \\sigma_\\alpha^2 + \\sigma_\\varepsilon^2\\]\nCovariância (mesmo indivíduo, períodos diferentes): \\[Cov[u_{it}, u_{is}] = Cov[\\alpha_i + \\varepsilon_{it}, \\alpha_i + \\varepsilon_{is}] = \\sigma_\\alpha^2, \\quad t \\neq s\\]\nCovariância (indivíduos diferentes): \\[Cov[u_{it}, u_{js}] = 0, \\quad i \\neq j\\]\n\n\nMatriz Individual \\(\\boldsymbol{\\Omega}_i\\) (Efeitos Aleatórios)\n\\[\\boldsymbol{\\Omega}_i^{RE} = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma_\\varepsilon^2 \\mathbf{I}_T + \\sigma_\\alpha^2 \\mathbf{J}_T\\]\nonde \\(\\mathbf{J}_T = \\mathbf{e}_T\\mathbf{e}_T'\\) é a matriz \\(T \\times T\\) de 1’s.\nDecomposição: - \\(\\mathbf{I}_T\\): matriz identidade \\(T \\times T\\) - \\(\\mathbf{J}_T\\): matriz de 1’s \\(T \\times T\\)\n\\[\\mathbf{J}_T = \\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\\]\nForma explícita para \\(T = 4\\):\n\\[\\boldsymbol{\\Omega}_i^{RE} = \\sigma_\\varepsilon^2 \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix} + \\sigma_\\alpha^2 \\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\\]\n\\[\\boldsymbol{\\Omega}_i^{RE} = \\begin{pmatrix}\n\\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2\n\\end{pmatrix}\\]\n\n\nMatriz Completa \\(\\boldsymbol{\\Omega}\\) (Efeitos Aleatórios)\n\\[\\boldsymbol{\\Omega}^{RE} = \\text{diag}(\\boldsymbol{\\Omega}_1^{RE}, \\boldsymbol{\\Omega}_2^{RE}, \\boldsymbol{\\Omega}_3^{RE})\\]\nEstrutura em blocos para \\(N = 3, T = 4\\):\n\\[\\boldsymbol{\\Omega}^{RE} = \\begin{pmatrix}\n\\boldsymbol{\\Omega}_1^{RE} & \\mathbf{0} & \\mathbf{0} \\\\\n\\mathbf{0} & \\boldsymbol{\\Omega}_2^{RE} & \\mathbf{0} \\\\\n\\mathbf{0} & \\mathbf{0} & \\boldsymbol{\\Omega}_3^{RE}\n\\end{pmatrix}\\]\nForma completa \\(12 \\times 12\\) (usando \\(\\sigma_1^2 = \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2\\) e \\(\\sigma_0^2 = \\sigma_\\alpha^2\\)):\n\\[\\boldsymbol{\\Omega}^{RE} = \\begin{pmatrix}\n\\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2\n\\end{pmatrix}\\]\n##AAAAAAAAAAAAAAAAAAAAAAAAAA"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#matriz-de-variância-covariância-pooled-x-aleatório",
    "href": "posts/Modelos-em-Painel/index.html#matriz-de-variância-covariância-pooled-x-aleatório",
    "title": "Modelo de dados em painel",
    "section": "Matriz de Variância-Covariância: Pooled x Aleatório",
    "text": "Matriz de Variância-Covariância: Pooled x Aleatório\n\nEstrutura das Matrizes de Variância-Covariância\n\nMatriz Individual \\(\\boldsymbol{\\Omega}_i\\) (Pooled)\nPara cada indivíduo \\(i\\) com \\(T\\) períodos:\n\\[\\boldsymbol{\\Omega}_i^{Pooled} = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma^2 \\mathbf{I}_T\\]\nForma explícita para \\(T = 4\\):\n\\[\\boldsymbol{\\Omega}_i^{Pooled} = \\begin{pmatrix}\n\\sigma^2 & 0 & 0 & 0 \\\\\n0 & \\sigma^2 & 0 & 0 \\\\\n0 & 0 & \\sigma^2 & 0 \\\\\n0 & 0 & 0 & \\sigma^2\n\\end{pmatrix}\\]\n\nMatriz Completa \\(\\boldsymbol{\\Omega}\\) (Pooled)\nPara \\(N = 3\\) indivíduos e \\(T = 4\\) períodos:\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\sigma^2 \\mathbf{I}_{NT} = \\sigma^2 \\mathbf{I}_{12}\\]\nEstrutura em blocos:\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\begin{pmatrix}\n\\boldsymbol{\\Omega}_1^{Pooled} & \\mathbf{0} & \\mathbf{0} \\\\\n\\mathbf{0} & \\boldsymbol{\\Omega}_2^{Pooled} & \\mathbf{0} \\\\\n\\mathbf{0} & \\mathbf{0} & \\boldsymbol{\\Omega}_3^{Pooled}\n\\end{pmatrix}\\]\nForma completa \\(12 \\times 12\\):\n\\[\\boldsymbol{\\Omega}^{Pooled} = \\sigma^2 \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\\]\n\n\n\nCaso 2: Modelo de Efeitos Aleatórios\n\nCálculo da Estrutura da Matriz\nVariância: \\[Var[u_{it}] = Var[\\alpha_i + \\varepsilon_{it}] = \\sigma_\\alpha^2 + \\sigma_\\varepsilon^2\\]\nCovariância (mesmo indivíduo, períodos diferentes): \\[Cov[u_{it}, u_{is}] = Cov[\\alpha_i + \\varepsilon_{it}, \\alpha_i + \\varepsilon_{is}] = \\sigma_\\alpha^2, \\quad t \\neq s\\]\nCovariância (indivíduos diferentes): \\[Cov[u_{it}, u_{js}] = 0, \\quad i \\neq j\\]\n\n\nMatriz Individual \\(\\boldsymbol{\\Omega}_i\\) (Efeitos Aleatórios)\n\\[\\boldsymbol{\\Omega}_i^{RE} = E[\\mathbf{u}_i\\mathbf{u}_i'] = \\sigma_\\varepsilon^2 \\mathbf{I}_T + \\sigma_\\alpha^2 \\mathbf{J}_T\\]\nonde \\(\\mathbf{J}_T = \\mathbf{e}_T\\mathbf{e}_T'\\) é a matriz \\(T \\times T\\) de 1’s.\nDecomposição: - \\(\\mathbf{I}_T\\): matriz identidade \\(T \\times T\\) - \\(\\mathbf{J}_T\\): matriz de 1’s \\(T \\times T\\)\n\\[\\mathbf{J}_T = \\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\\]\nForma explícita para \\(T = 4\\):\n\\[\\boldsymbol{\\Omega}_i^{RE} = \\sigma_\\varepsilon^2 \\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix} + \\sigma_\\alpha^2 \\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\\]\n\\[\\boldsymbol{\\Omega}_i^{RE} = \\begin{pmatrix}\n\\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2 & \\sigma_\\alpha^2 \\\\\n\\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\alpha^2 & \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2\n\\end{pmatrix}\\]\n\n\nMatriz Completa \\(\\boldsymbol{\\Omega}\\) (Efeitos Aleatórios)\n\\[\\boldsymbol{\\Omega}^{RE} = \\text{diag}(\\boldsymbol{\\Omega}_1^{RE}, \\boldsymbol{\\Omega}_2^{RE}, \\boldsymbol{\\Omega}_3^{RE})\\]\nEstrutura em blocos para \\(N = 3, T = 4\\):\n\\[\\boldsymbol{\\Omega}^{RE} = \\begin{pmatrix}\n\\boldsymbol{\\Omega}_1^{RE} & \\mathbf{0} & \\mathbf{0} \\\\\n\\mathbf{0} & \\boldsymbol{\\Omega}_2^{RE} & \\mathbf{0} \\\\\n\\mathbf{0} & \\mathbf{0} & \\boldsymbol{\\Omega}_3^{RE}\n\\end{pmatrix}\\]\nForma completa \\(12 \\times 12\\) (usando \\(\\sigma_1^2 = \\sigma_\\varepsilon^2 + \\sigma_\\alpha^2\\) e \\(\\sigma_0^2 = \\sigma_\\alpha^2\\)):\n\\[\\boldsymbol{\\Omega}^{RE} = \\begin{pmatrix}\n\\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2 & \\sigma_0^2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_0^2 & \\sigma_1^2\n\\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#relação-com-os-estimadores-within-e-between",
    "href": "posts/Modelos-em-Painel/index.html#relação-com-os-estimadores-within-e-between",
    "title": "Modelo de dados em painel",
    "section": "Relação com os estimadores within e between",
    "text": "Relação com os estimadores within e between\nO pooled MQO pode ser visto como uma combinação do estimador within e between\nVisualizar exemplo em excel\n\nlibrary(readxl)\nlibrary(plm)\n\n\npainel_exemplo <- read_excel(\"painel_exemplo1.xlsx\")\n\nsummary(plm(y ~ x1+x2, \n        data=painel_exemplo, \n        model=\"between\",\n        index=c(\"ID\",\"t\")))\n\nOneway (individual) effect Between Model\n\nCall:\nplm(formula = y ~ x1 + x2, data = painel_exemplo, model = \"between\", \n    index = c(\"ID\", \"t\"))\n\nBalanced Panel: n = 5, T = 3, N = 15\nObservations used in estimation: 5\n\nResiduals:\n        1         2         3         4         5 \n 1.568503 -0.970257 -0.922984  0.254599  0.070138 \n\nCoefficients:\n            Estimate Std. Error t-value Pr(>|t|)  \n(Intercept)  1.92170    2.21558  0.8674  0.47718  \nx1           1.66948    0.46653  3.5785  0.06999 .\nx2          -0.68763    0.51234 -1.3421  0.31162  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    44.8\nResidual Sum of Squares: 4.3232\nR-Squared:      0.9035\nAdj. R-Squared: 0.807\nF-statistic: 9.3626 on 2 and 2 DF, p-value: 0.096501\n\n\n\nsummary(plm(y ~ x1+x2, \n        data=painel_exemplo, \n        model=\"within\",\n        index=c(\"ID\",\"t\")))\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = y ~ x1 + x2, data = painel_exemplo, model = \"within\", \n    index = c(\"ID\", \"t\"))\n\nBalanced Panel: n = 5, T = 3, N = 15\n\nResiduals:\n    Min.  1st Qu.   Median  3rd Qu.     Max. \n-2.99457 -1.39904  0.12801  1.53272  2.58529 \n\nCoefficients:\n   Estimate Std. Error t-value  Pr(>|t|)    \nx1  1.45299    0.17932  8.1027 3.983e-05 ***\nx2 -0.56217    0.14402 -3.9034  0.004523 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    513.33\nResidual Sum of Squares: 47.588\nR-Squared:      0.9073\nAdj. R-Squared: 0.83777\nF-statistic: 39.148 on 2 and 8 DF, p-value: 7.3858e-05\n\n\n\nsummary(plm(y ~ x1+x2, \n        data=painel_exemplo, \n        model=\"pooling\",\n        index=c(\"ID\",\"t\")))\n\nPooling Model\n\nCall:\nplm(formula = y ~ x1 + x2, data = painel_exemplo, model = \"pooling\", \n    index = c(\"ID\", \"t\"))\n\nBalanced Panel: n = 5, T = 3, N = 15\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-3.2151 -1.9570  0.9529  1.5686  3.0181 \n\nCoefficients:\n            Estimate Std. Error t-value  Pr(>|t|)    \n(Intercept)  1.80451    1.03936  1.7362 0.1081093    \nx1           1.48969    0.14296 10.4206 2.291e-07 ***\nx2          -0.55747    0.12379 -4.5034 0.0007223 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    647.73\nResidual Sum of Squares: 61.825\nR-Squared:      0.90455\nAdj. R-Squared: 0.88864\nF-statistic: 56.8612 on 2 and 12 DF, p-value: 7.5616e-07"
  },
  {
    "objectID": "posts/Modelos-em-Painel/index.html#teste-de-hausman-fe-vs-re",
    "href": "posts/Modelos-em-Painel/index.html#teste-de-hausman-fe-vs-re",
    "title": "Modelo de dados em painel",
    "section": "Teste de Hausman: FE vs RE",
    "text": "Teste de Hausman: FE vs RE\nIdeia. Sob \\(H_0\\) (sem correlação entre os efeitos individuais \\(\\alpha_i\\) e as regressores \\(\\mathbf X_i\\), o estimador RE é consistente e eficiente e o FE também é consistente. Sob \\(H_1\\), RE torna-se inconsistente e FE permanece consistente. Assim, a distância entre \\(\\hat\\beta_{RE}\\) e \\(\\hat\\beta_{FE}\\) serve para decidir entre os modelos.\nHipóteses. - \\[H_0:\\ \\mathbb{E}[\\alpha_i\\mid \\ \\mathbf X_i]=0\\] - \\[H_1:\\ \\mathbb{E}[\\alpha_i\\mid \\ \\mathbf X_i]\\neq 0\\]\nEstatística (forma clássica). \\[\nH=(\\hat\\beta_{RE}-\\hat\\beta_{FE})'\n\\big[\\mathrm{Var}(\\hat\\beta_{FE})-\\mathrm{Var}(\\hat\\beta_{RE})\\big]^{-1}\n(\\hat\\beta_{RE}-\\hat\\beta_{FE})\n\\ \\sim\\ \\chi^2_{K},\n\\] com \\(K\\) = número de regressoras (sem a constante).\nInterpretação: p-valor pequeno \\(\\Rightarrow\\) rejeita \\(H_0\\) \\(\\Rightarrow\\) usar FE; p-valor alto \\(\\Rightarrow\\) usar RE.\n\nlibrary(readxl)\nlibrary(plm)\n\n# Base do exemplo (ajuste o caminho se necessário)\npainel_exemplo <- read_excel(\"painel_exemplo1.xlsx\")\npdata <- pdata.frame(painel_exemplo, index = c(\"ID\",\"t\"))\n\n# Estimadores FE e RE\nfe <- plm(y ~ x1 + x2, data = pdata, model = \"within\")\nre <- plm(y ~ x1 + x2, data = pdata, model = \"random\")\n\n# Teste de Hausman clássico\nphtest(fe, re)\n\n\n    Hausman Test\n\ndata:  y ~ x1 + x2\nchisq = 0.10349, df = 2, p-value = 0.9496\nalternative hypothesis: one model is inconsistent"
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html",
    "title": "Introdução à avaliação de Impacto",
    "section": "",
    "text": "Você já se perguntou qual o verdadeiro efeito de um novo programa educacional nas notas dos alunos? Ou se uma campanha de marketing realmente aumentou as vendas de um produto? A avaliação de impacto é a ferramenta que nos permite responder a essas perguntas de forma rigorosa. Ela busca medir a contribuição de uma intervenção ou programa para um resultado de interesse, comparando o que aconteceu com a intervenção com o que teria acontecido sem ela — o chamado contrafactual.\nO grande desafio é que nunca observamos essa realidade alternativa. Não podemos, para o mesmo indivíduo e ao mesmo tempo, saber o que aconteceria com e sem o programa. Portanto, a avaliação de impacto é, em essência, um exercício de construção de um contrafactual crível para isolar o efeito causal da intervenção de todos os outros fatores que podem influenciar o resultado.\nNeste guia, vamos explorar os conceitos e métodos que formam a base da avaliação de impacto e da inferência causal, desde a teoria dos resultados potenciais até as técnicas mais utilizadas no mercado e na academia.\n\n\n\n\n\n\nO Problema Central\n\n\n\nO desafio da avaliação de impacto é estimar um contrafactual — o que teria acontecido na ausência do programa — para isolar o verdadeiro efeito da intervenção."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#quando-avaliar-ex-ante-vs.-ex-post",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#quando-avaliar-ex-ante-vs.-ex-post",
    "title": "Introdução à avaliação de Impacto",
    "section": "Quando Avaliar: Ex-Ante vs. Ex-Post",
    "text": "Quando Avaliar: Ex-Ante vs. Ex-Post\nA decisão de quando realizar uma avaliação de impacto é crucial e depende dos objetivos. Existem dois momentos principais:\n\nAvaliação Ex-Ante: Realizada antes da implementação do programa, ela projeta os possíveis impactos e custos. Seu principal objetivo é informar a decisão sobre a adoção do programa, comparar alternativas de desenho e justificar o investimento. Por natureza, baseia-se em modelos teóricos e simulações, pois ainda não existem dados de beneficiários.\nAvaliação Ex-Post: Realizada durante ou após a execução do programa. Ela pode ser:\n\nDe percurso: Acontece enquanto o programa está em andamento. É ideal para verificar se as previsões ex-ante estão se confirmando e para orientar ajustes, aperfeiçoando o desenho em tempo real. É comum em programas piloto ou contínuos.\nDe encerramento: Feita após o término da intervenção, busca julgar a eficácia da alocação de recursos e capturar impactos de longo prazo, que podem demorar a se manifestar. Ajuda a consolidar o aprendizado e a informar o desenho de futuros programas.\n\n\nEm resumo, a avaliação ex-ante foca no planejamento e na otimização do desenho, enquanto a ex-post se concentra em medir o impacto real e gerar aprendizados a partir da experiência."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#correlação-não-implica-causalidade",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#correlação-não-implica-causalidade",
    "title": "Introdução à avaliação de Impacto",
    "section": "Correlação não Implica Causalidade",
    "text": "Correlação não Implica Causalidade\nUm dos mantras mais repetidos em estatística e ciência de dados é: correlação não implica causalidade. Encontrar uma associação estatística entre duas variáveis, A e B, não é suficiente para concluir que A causa B. Existem pelo menos quatro possibilidades:\n\nCausalidade Direta: A de fato causa B (A → B).\nCausalidade Reversa: B, na verdade, causa A (B → A).\nFator de Confusão: Uma terceira variável, C, é a verdadeira causa tanto de A quanto de B (A ← C → B).\nCoincidência: A correlação observada é puramente acidental, um ruído nos dados sem significado prático.\n\nPor exemplo, o aumento nas vendas de sorvete pode estar correlacionado com o aumento no número de afogamentos. Seria um erro concluir que tomar sorvete causa afogamentos. O fator de confusão aqui é o verão: dias mais quentes (C) levam as pessoas a comprarem mais sorvete (A) e também a nadarem mais (B), aumentando o risco de afogamentos.\nPara que a causalidade de A para B seja plausível, a correlação é uma condição necessária (a menos que um outro fator C anule exatamente o efeito de A), mas definitivamente não é uma condição suficiente. A inferência causal busca justamente métodos para ir além da simples correlação e isolar o verdadeiro efeito causal."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#as-hipóteses-chave-para-identificação-causal",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#as-hipóteses-chave-para-identificação-causal",
    "title": "Introdução à avaliação de Impacto",
    "section": "As Hipóteses-Chave para Identificação Causal",
    "text": "As Hipóteses-Chave para Identificação Causal\nPara que possamos estimar os efeitos causais de forma válida a partir de dados observacionais, precisamos de algumas hipóteses que tornem a nossa análise crível. As três mais importantes são:\n\n1. Ignorabilidade (ou Independência Condicional)\nFormalmente, esta hipótese diz que, uma vez que controlamos por um conjunto de variáveis observáveis X, a alocação do tratamento é independente dos resultados potenciais.\n\\[\n(Y^1, Y^0) \\perp D \\mid X\n\\]\nEm um experimento aleatório controlado (RCT), essa hipótese é garantida pelo próprio desenho, pois a aleatorização torna o tratamento independente de qualquer característica dos indivíduos, observada ou não. Em estudos observacionais, a plausibilidade da ignorabilidade depende da nossa capacidade de medir e controlar por todos os fatores de confusão relevantes (o conjunto X).\n\n\n2. Suporte Comum (ou Overlap)\nEsta hipótese garante que, para qualquer conjunto de características X, existem tanto indivíduos tratados quanto não tratados.\n\\[\n0 < P(D=1 \\mid X) < 1\n\\]\nIntuitivamente, não podemos comparar o incomparável. Se um programa de reforço escolar é oferecido apenas para alunos com notas muito baixas, não temos um grupo de controle com características similares (notas baixas) para fazer a comparação. A falta de suporte comum impede a estimação do efeito causal para certos subgrupos da população.\n\n\n3. SUTVA (Stable Unit Treatment Value Assumption)\nA SUTVA é composta por duas sub-hipóteses:\n\nConsistência: O resultado potencial de um indivíduo sob um determinado tratamento corresponde ao resultado observado se ele de fato recebe aquele tratamento. Isso implica que não existem múltiplas “versões” do tratamento com efeitos diferentes.\nNão-Interferência: O tratamento recebido por uma unidade não afeta os resultados potenciais de outra unidade. Por exemplo, em um programa de vacinação, a vacinação de uma pessoa pode gerar um efeito de transbordamento (spillover) positivo para outras, protegendo-as também. A SUTVA assume que esses efeitos de interferência não existem.\n\nSem as hipóteses de ignorabilidade e suporte comum, a identificação do efeito causal falha. Sem a SUTVA, os próprios resultados potenciais não estão bem definidos."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#como-obter-variação-exógena-os-desenhos-clássicos-de-identificação",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#como-obter-variação-exógena-os-desenhos-clássicos-de-identificação",
    "title": "Introdução à avaliação de Impacto",
    "section": "Como Obter Variação Exógena? Os Desenhos Clássicos de Identificação",
    "text": "Como Obter Variação Exógena? Os Desenhos Clássicos de Identificação\nO grande objetivo dos métodos de inferência causal é encontrar (ou simular) uma fonte de variação no tratamento que seja “tão boa quanto aleatória”. Cada método se baseia em um conjunto diferente de hipóteses para alcançar a identificação.\n\nExperimentos Aleatórios Controlados (RCTs)\nConsiderado o padrão-ouro, o RCT resolve o problema do viés de seleção ao aleatorizar a alocação do tratamento. A randomização garante, em média, que os grupos de tratamento e controle sejam idênticos em todas as características, observáveis e não observáveis. Assim, qualquer diferença nos resultados pode ser atribuída ao tratamento. Sob aleatorização o coeficiente de ua regressão simples é uma boa estimativa do ATE"
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#inferência-por-randomização-teste-de-permutação-de-fisher",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#inferência-por-randomização-teste-de-permutação-de-fisher",
    "title": "Introdução à avaliação de Impacto",
    "section": "Inferência por Randomização (Teste de Permutação de Fisher)",
    "text": "Inferência por Randomização (Teste de Permutação de Fisher)\nUma abordagem elegante para testar a hipótese nula de que o tratamento não tem efeito nenhum (\\(\\\\delta_i = 0\\) para todos) é a inferência por randomização. Ela é particularmente poderosa em RCTs.\n\nHipótese Nula Aguda: Assume-se que o tratamento não teve efeito para nenhuma unidade.\nImputação: Sob essa hipótese, o resultado observado seria o mesmo com ou sem tratamento (\\(Y_i^1 = Y_i^0 = Y_i^{\\text{obs}}\\)).\nPermutação: Gera-se um grande número de alocações alternativas do tratamento, mantendo o mesmo número de tratados e controles do experimento original.\nDistribuição Nula: Para cada permutação, calcula-se a estatística de teste (e.g., a diferença de médias). Isso cria uma distribuição empírica da estatística sob a hipótese nula.\nP-valor: O p-valor é a proporção de estatísticas simuladas que são mais extremas que a estatística observada no experimento real.\n\nEssa abordagem não depende de suposições sobre a distribuição dos dados e fornece um p-valor exato para a hipótese nula aguda."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#boas-práticas-e-armadilhas",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#boas-práticas-e-armadilhas",
    "title": "Introdução à avaliação de Impacto",
    "section": "Boas Práticas e Armadilhas",
    "text": "Boas Práticas e Armadilhas\n\nPré-registro: Sempre que possível, pré-registre o desenho da sua análise e os resultados primários de interesse para evitar “p-hacking” (a busca por resultados estatisticamente significantes).\nVerificação de Hipóteses: Teste a plausibilidade das hipóteses do seu método (balanceamento de covariáveis, tendências paralelas, relevância do instrumento, etc.).\nAnálise de Sensibilidade: Verifique se seus resultados são robustos a diferentes especificações do modelo e hipóteses alternativas.\nInterpretação: Seja claro sobre qual parâmetro você está estimando (ATE, ATT, LATE) e para qual população ele se aplica."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#conclusão-a-busca-pelo-contrafactual",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#conclusão-a-busca-pelo-contrafactual",
    "title": "Introdução à avaliação de Impacto",
    "section": "Conclusão: A Busca pelo Contrafactual",
    "text": "Conclusão: A Busca pelo Contrafactual\nInferência causal é, em última análise, um problema de informação faltante: a busca pelo contrafactual. Sem uma fonte de variação exógena no tratamento — seja ela criada por um experimento ou encontrada de forma inteligente em dados observacionais — nossas conclusões estarão sempre sujeitas ao risco de viés. Os métodos que exploramos oferecem um arsenal para construir contrafactuais críveis e, assim, tomar decisões mais informadas em políticas públicas, negócios e na ciência."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#o-modelo-de-resultados-potenciais-formalizando-a-causalidade",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#o-modelo-de-resultados-potenciais-formalizando-a-causalidade",
    "title": "Introdução à avaliação de Impacto",
    "section": "O Modelo de Resultados Potenciais: Formalizando a Causalidade",
    "text": "O Modelo de Resultados Potenciais: Formalizando a Causalidade\nPara superar o desafio do contrafactual, o Modelo de Resultados Potenciais (Potential Outcomes), popularizado por Donald Rubin, oferece uma estrutura conceitual poderosa. A ideia é definir a causalidade em termos de resultados que poderiam ter acontecido.\n\nA Ideia Central\nPara cada unidade de análise (um indivíduo, uma empresa, uma escola), imaginamos dois estados do mundo:\n\n\\(Y_i^1\\): O resultado que a unidade i teria se recebesse o tratamento (D=1).\n\\(Y_i^0\\): O resultado que a mesma unidade i teria se não recebesse o tratamento (D=0).\n\nO efeito causal individual do tratamento para a unidade i é a diferença entre esses dois resultados potenciais:\n\\[\n\\delta_i = Y_i^1 - Y_i^0\n\\]\nO problema fundamental, como já vimos, é que para cada unidade i, só podemos observar um desses resultados. O outro permanece um contrafactual. A equação de comutação formaliza isso:\n\\[\nY_i = D_i \\cdot Y_i^1 + (1 - D_i) \\cdot Y_i^0\n\\]\nOnde \\(D_i\\) é uma variável que indica se a unidade i recebeu o tratamento (\\(D_i=1\\)) ou não (\\(D_i=0\\)).\n\n\nEfeitos Médios de Interesse\nComo não podemos estimar o efeito individual para todos, o foco da avaliação de impacto se volta para os efeitos médios em uma população:\n\nATE (Average Treatment Effect): O efeito médio do tratamento para a população como um todo. É a média de todos os efeitos individuais.\n\\[\nATE = E[\\delta_i] = E[Y^1] - E[Y^0]\n\\]\nATT (Average Treatment Effect on the Treated): O efeito médio do tratamento apenas para aqueles que efetivamente o receberam.\n\\[\nATT = E[\\delta_i | D=1] = E[Y^1 | D=1] - E[Y^0 | D=1]\n\\]\nATU (Average Treatment Effect on the Untreated): O efeito médio do tratamento caso ele fosse aplicado naqueles que não o receberam.\n\\[\nATU = E[\\delta_i | D=0] = E[Y^1 | D=0] - E[Y^0 | D=0]\n\\]\n\nQuando os efeitos do tratamento são heterogêneos (ou seja, variam entre os indivíduos), esses três parâmetros podem ser bem diferentes. Por exemplo, um programa de qualificação profissional pode ter um impacto muito maior (ATT) para os que escolheram participar do que teria para a população em geral (ATE).\n\n\nPor que a Simples Comparação de Médias é Enganosa\nUma primeira abordagem, mais ingênua, seria simplesmente comparar a média do resultado para o grupo que recebeu o tratamento com a média do grupo que não recebeu:\n\\[\n\\text{Diferença ingênua} = E[Y | D=1] - E[Y | D=0]\n\\]\nNo entanto, essa diferença quase nunca corresponde ao verdadeiro efeito causal. Uma decomposição matemática revela por quê:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + (E[Y^0 | D=1] - E[Y^0 | D=0])\n\\]\nO segundo termo, \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), é o viés de seleção. Ele representa a diferença que já existia entre os grupos antes mesmo do tratamento. Se os indivíduos que procuram um curso de qualificação (D=1) já são, em média, mais motivados e teriam salários mais altos (\\(Y^0\\)) do que os que não procuram (D=0), a comparação simples irá superestimar o efeito do curso, misturando o impacto real com essa diferença pré-existente.\n\nA moral da história é que as escolhas (auto-seleção para o tratamento) são geralmente endógenas, ou seja, correlacionadas com os resultados potenciais. Sem uma fonte de variação exógena (aleatória), a comparação bruta é quase sempre enviesada.\n\n\n\nDecompondo o ATE\nUma das relações mais importantes na inferência causal é como o Average Treatment Effect (ATE) pode ser decomposto em função do Average Treatment Effect on the Treated (ATT) e do Average Treatment Effect on the Untreated (ATU). Esta decomposição é crucial para entender a heterogeneidade dos efeitos do tratamento, o viés de seleção e como generalizar resultados de um grupo para toda a população.\nO ATE pode ser expresso como uma média ponderada do ATT e ATU, onde os pesos são as proporções de indivíduos tratados e não tratados na população:\n\\[\nATE = P(D=1) \\times ATT + P(D=0) \\times ATU\n\\]\nEssa fórmula nos mostra que o efeito médio geral é uma combinação dos efeitos específicos em cada grupo. Se o efeito do tratamento for maior para aqueles que o escolheram (ATT > ATU), e esse grupo for grande, o ATE será mais próximo do ATT. A derivação matemática, baseada na lei da expectativa total, revela como essa relação emerge naturalmente das definições de cada parâmetro.\n\n\nDecompondo a diferença ingênua\nA diferença ingênua pode ser decomposta em ATE, viés de seleção e viés de heterogeneidade. Partindo da relação \\(E[Y | D=1] - E[Y | D=0] = ATT + (E[Y^0 | D=1] - E[Y^0 | D=0])\\), somando e subtraindo o ATE do lado direito da equação\n\\[\nE[Y | D=1] - E[Y | D=0] = ATE + ATT + (E[Y^0 | D=1] - E[Y^0 | D=0]) - ATE\n\\] Usando o fato que \\(ATE = P(D=1) \\times ATT + (1-P(D=1)) \\times ATU\\) temos que:\n\\[\n\\begin{align}\nE[Y | D=1] - E[Y | D=0] &= ATE + (1-P(D=1)) \\times (ATT - ATU) + (E[Y^0 | D=1] - E[Y^0 | D=0]) \\\\\n&= ATE + \\text{Viés de Heterogeneidade} + \\text{Viés de Seleção}\n\\end{align}\n\\]"
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#a-relação-fundamental-decompondo-o-ate",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#a-relação-fundamental-decompondo-o-ate",
    "title": "Introdução à avaliação de Impacto",
    "section": "A Relação Fundamental: Decompondo o ATE",
    "text": "A Relação Fundamental: Decompondo o ATE\nUma das relações mais importantes na inferência causal é como o Average Treatment Effect (ATE) pode ser decomposto em função do Average Treatment Effect on the Treated (ATT) e do Average Treatment Effect on the Untreated (ATU). Esta decomposição é crucial para entender a heterogeneidade dos efeitos do tratamento, o viés de seleção e como generalizar resultados de um grupo para toda a população.\nO ATE pode ser expresso como uma média ponderada do ATT e ATU, onde os pesos são as proporções de indivíduos tratados e não tratados na população:\n\\[\nATE = P(D=1) \\times ATT + P(D=0) \\times ATU\n\\]\nEssa fórmula nos mostra que o efeito médio geral é uma combinação dos efeitos específicos em cada grupo. Se o efeito do tratamento for maior para aqueles que o escolheram (ATT > ATU), e esse grupo for grande, o ATE será mais próximo do ATT. A derivação matemática, baseada na lei da expectativa total, revela como essa relação emerge naturalmente das definições de cada parâmetro.\n_\n\nExemplo Prático: Programa de Treinamento Profissional\nImagine um programa de treinamento profissional onde 40% dos trabalhadores elegíveis decidem participar. É razoável supor que aqueles que participam são diferentes daqueles que não participam (e.g., mais motivados), e que o efeito do treinamento pode ser diferente para esses dois grupos.\nPodemos simular este cenário usando R para ilustrar a decomposição do ATE.\n\n# Configurando dados hipotéticos\nset.seed(42)\nn_total <- 1000\nprop_treated <- 0.4\n\n# Efeitos heterogêneos\natt_true <- 5000\natu_true <- 2000\n\n# Resultados potenciais\nn_treated <- round(n_total * prop_treated)\ny0_treated <- rnorm(n_treated, mean = 30000, sd = 5000)\ny1_treated <- y0_treated + att_true + rnorm(n_treated, mean = 0, sd = 1000)\n\nn_untreated <- n_total - n_treated\ny0_untreated <- rnorm(n_untreated, mean = 25000, sd = 5000)\ny1_untreated <- y0_untreated + atu_true + rnorm(n_untreated, mean = 0, sd = 1000)\n\n# Criando data frame\ndata <- tibble(\n  id = 1:n_total,\n  D = c(rep(1, n_treated), rep(0, n_untreated)),\n  Y0 = c(y0_treated, y0_untreated),\n  Y1 = c(y1_treated, y1_untreated)\n) %>%\n  mutate(Y_obs = D * Y1 + (1 - D) * Y0)\n\n# Calculando os efeitos\neffects <- data %>%\n  summarise(\n    ATT = mean(Y1[D == 1]) - mean(Y0[D == 1]),\n    ATU = mean(Y1[D == 0]) - mean(Y0[D == 0]),\n    ATE_direct = mean(Y1) - mean(Y0),\n    prop_treated = mean(D)\n  ) %>%\n  mutate(ATE_decomposed = prop_treated * ATT + (1 - prop_treated) * ATU)\n\n# Exibindo resultados\ncat(\"ATT (efeito nos tratados): $\", round(effects$ATT, 0), \"\\n\")\n\nATT (efeito nos tratados): $ 4907 \n\ncat(\"ATU (efeito nos não-tratados): $\", round(effects$ATU, 0), \"\\n\")\n\nATU (efeito nos não-tratados): $ 2018 \n\ncat(\"ATE (cálculo direto): $\", round(effects$ATE_direct, 0), \"\\n\")\n\nATE (cálculo direto): $ 3173 \n\ncat(\"ATE (via decomposição): $\", round(effects$ATE_decomposed, 0), \"\\n\")\n\nATE (via decomposição): $ 3173 \n\n\nEste código simula uma população onde o grupo tratado tem um salário base maior e um efeito do tratamento mais elevado, refletindo um cenário de auto-seleção positiva. Os resultados do cálculo confirmam a decomposição do ATE e mostram como o ATE é uma média ponderada do ATT e do ATU.\n\n\nPor que Esta Decomposição Importa?\nA decomposição do ATE em função do ATT e ATU tem implicações profundas para a interpretação de resultados e o desenho de políticas públicas.\nViés de Seleção: A comparação ingênua entre tratados e controles pode ser decomposta como:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + \\text{Viés de Seleção}\n\\]\nOnde o viés de seleção é \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), representando a diferença que já existia entre os grupos antes do tratamento. Se os indivíduos que procuram um curso de qualificação já são mais motivados e teriam salários mais altos mesmo sem o curso, a comparação simples superestimará o efeito do programa.\nImplicações para Política Pública: Considere dois cenários para o programa de treinamento:\n\nExpansão Total: Oferecer o programa para toda a população elegível\nManutenção: Manter apenas para quem já participa\n\nA análise custo-benefício deve considerar que o efeito médio para novos participantes (ATU) pode ser diferente do efeito para os participantes atuais (ATT). Se o ATU for significativamente menor que o ATT, a expansão pode não ser custo-efetiva, mesmo que o programa atual seja bem-sucedido.\nGeneralização de Resultados: Quando extrapolamos resultados de um estudo para uma população diferente, precisamos considerar se a composição da nova população (proporção de “tipos” de indivíduos) é similar à do estudo original. Um programa que funciona bem em uma população com alta proporção de indivíduos motivados pode ter resultados diferentes em uma população com características distintas.\nPodemos também criar uma visualização para melhor compreender a distribuição dos efeitos:\n\n# Criando visualização dos efeitos individuais\ndata %>%\n  mutate(individual_effect = Y1 - Y0) %>%\n  ggplot(aes(x = individual_effect, fill = factor(D))) +\n  geom_histogram(alpha = 0.7, bins = 30, position = \"identity\") +\n  geom_vline(xintercept = effects$ATE_direct, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribuição dos Efeitos Individuais do Tratamento\",\n    x = \"Efeito Individual ($)\",\n    y = \"Frequência\",\n    fill = \"Grupo\",\n    caption = \"Linha vermelha tracejada representa o ATE\"\n  ) +\n  scale_fill_discrete(labels = c(\"Controle\", \"Tratamento\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n# Gráfico de barras mostrando a decomposição\ndecomp_data <- tibble(\n  Parametro = c(\"ATT\", \"ATU\", \"ATE\"),\n  Valor = c(effects$ATT, effects$ATU, effects$ATE_direct),\n  Peso = c(paste0(\"Peso: \", round(effects$prop_treated * 100, 1), \"%\"),\n           paste0(\"Peso: \", round((1 - effects$prop_treated) * 100, 1), \"%\"),\n           \"Média Ponderada\")\n)\n\nggplot(decomp_data, aes(x = Parametro, y = Valor, fill = Parametro)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(\"$\", round(Valor, 0), \"\\n\", Peso)), \n            vjust = -0.5, size = 3.5) +\n  labs(\n    title = \"Decomposição do ATE\",\n    x = \"Parâmetro\",\n    y = \"Efeito do Tratamento ($)\",\n    fill = \"Parâmetro\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_brewer(type = \"qual\", palette = \"Set2\")"
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#decompondo-o-ate",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#decompondo-o-ate",
    "title": "Introdução à avaliação de Impacto",
    "section": "Decompondo o ATE",
    "text": "Decompondo o ATE\nUma das relações mais importantes na inferência causal é como o Average Treatment Effect (ATE) pode ser decomposto em função do Average Treatment Effect on the Treated (ATT) e do Average Treatment Effect on the Untreated (ATU). Esta decomposição é crucial para entender a heterogeneidade dos efeitos do tratamento, o viés de seleção e como generalizar resultados de um grupo para toda a população.\nO ATE pode ser expresso como uma média ponderada do ATT e ATU, onde os pesos são as proporções de indivíduos tratados e não tratados na população:\n\\[\nATE = P(D=1) \\times ATT + P(D=0) \\times ATU\n\\]\nEssa fórmula nos mostra que o efeito médio geral é uma combinação dos efeitos específicos em cada grupo. Se o efeito do tratamento for maior para aqueles que o escolheram (ATT > ATU), e esse grupo for grande, o ATE será mais próximo do ATT. A derivação matemática, baseada na lei da expectativa total, revela como essa relação emerge naturalmente das definições de cada parâmetro.\n_\n\nExemplo Prático: Programa de Treinamento Profissional\nImagine um programa de treinamento profissional onde 40% dos trabalhadores elegíveis decidem participar. É razoável supor que aqueles que participam são diferentes daqueles que não participam (e.g., mais motivados), e que o efeito do treinamento pode ser diferente para esses dois grupos.\n\n# Configurando dados hipotéticos\nset.seed(42)\nn_total <- 1000\nprop_treated <- 0.4\n\n# Efeitos heterogêneos\natt_true <- 5000\natu_true <- 2000\n\n# Resultados potenciais\nn_treated <- round(n_total * prop_treated)\ny0_treated <- rnorm(n_treated, mean = 30000, sd = 5000)\ny1_treated <- y0_treated + att_true + rnorm(n_treated, mean = 0, sd = 1000)\n\nn_untreated <- n_total - n_treated\ny0_untreated <- rnorm(n_untreated, mean = 25000, sd = 5000)\ny1_untreated <- y0_untreated + atu_true + rnorm(n_untreated, mean = 0, sd = 1000)\n\n# Criando data frame\ndata <- tibble(\n  id = 1:n_total,\n  D = c(rep(1, n_treated), rep(0, n_untreated)),\n  Y0 = c(y0_treated, y0_untreated),\n  Y1 = c(y1_treated, y1_untreated)\n) %>%\n  mutate(Y_obs = D * Y1 + (1 - D) * Y0)\n\n# Calculando os efeitos\neffects <- data %>%\n  summarise(\n    ATT = mean(Y1[D == 1]) - mean(Y0[D == 1]),\n    ATU = mean(Y1[D == 0]) - mean(Y0[D == 0]),\n    ATE_direct = mean(Y1) - mean(Y0),\n    prop_treated = mean(D)\n  ) %>%\n  mutate(ATE_decomposed = prop_treated * ATT + (1 - prop_treated) * ATU)\n\n# Exibindo resultados\ncat(\"ATT (efeito nos tratados): $\", round(effects$ATT, 3), \"\\n\")\n\nATT (efeito nos tratados): $ 4907.124 \n\ncat(\"ATU (efeito nos não-tratados): $\", round(effects$ATU, 3), \"\\n\")\n\nATU (efeito nos não-tratados): $ 2017.598 \n\ncat(\"ATE (cálculo direto): $\", round(effects$ATE_direct, 3), \"\\n\")\n\nATE (cálculo direto): $ 3173.408 \n\ncat(\"ATE (via decomposição): $\", round(effects$ATE_decomposed, 3), \"\\n\")\n\nATE (via decomposição): $ 3173.408 \n\n\nEste código simula uma população onde o grupo tratado tem um salário base maior e um efeito do tratamento mais elevado, refletindo um cenário de auto-seleção positiva. Os resultados do cálculo confirmam a decomposição do ATE e mostram como o ATE é uma média ponderada do ATT e do ATU.\nVisualizar exemplo em excel\n\n\nPor que Esta Decomposição Importa?\nA decomposição do ATE em função do ATT e ATU tem implicações profundas para a interpretação de resultados e o desenho de políticas públicas.\nViés de Seleção: A comparação ingênua entre tratados e controles pode ser decomposta como:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + \\text{Viés de Seleção}\n\\]\nOnde o viés de seleção é \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), representando a diferença que já existia entre os grupos antes do tratamento. Se os indivíduos que procuram um curso de qualificação já são mais motivados e teriam salários mais altos mesmo sem o curso, a comparação simples superestimará o efeito do programa.\nImplicações para Política Pública: Considere dois cenários para o programa de treinamento:\n\nExpansão Total: Oferecer o programa para toda a população elegível\nManutenção: Manter apenas para quem já participa\n\nA análise custo-benefício deve considerar que o efeito médio para novos participantes (ATU) pode ser diferente do efeito para os participantes atuais (ATT). Se o ATU for significativamente menor que o ATT, a expansão pode não ser custo-efetiva, mesmo que o programa atual seja bem-sucedido.\nGeneralização de Resultados: Quando extrapolamos resultados de um estudo para uma população diferente, precisamos considerar se a composição da nova população (proporção de “tipos” de indivíduos) é similar à do estudo original. Um programa que funciona bem em uma população com alta proporção de indivíduos motivados pode ter resultados diferentes em uma população com características distintas.\nPodemos também criar uma visualização para melhor compreender a distribuição dos efeitos:\n\n# Criando visualização dos efeitos individuais\ndata %>%\n  mutate(individual_effect = Y1 - Y0) %>%\n  ggplot(aes(x = individual_effect, fill = factor(D))) +\n  geom_histogram(alpha = 0.7, bins = 30, position = \"identity\") +\n  geom_vline(xintercept = effects$ATE_direct, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribuição dos Efeitos Individuais do Tratamento\",\n    x = \"Efeito Individual ($)\",\n    y = \"Frequência\",\n    fill = \"Grupo\",\n    caption = \"Linha vermelha tracejada representa o ATE\"\n  ) +\n  scale_fill_discrete(labels = c(\"Controle\", \"Tratamento\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n# Gráfico de barras mostrando a decomposição\ndecomp_data <- tibble(\n  Parametro = c(\"ATT\", \"ATU\", \"ATE\"),\n  Valor = c(effects$ATT, effects$ATU, effects$ATE_direct),\n  Peso = c(paste0(\"Peso: \", round(effects$prop_treated * 100, 1), \"%\"),\n           paste0(\"Peso: \", round((1 - effects$prop_treated) * 100, 1), \"%\"),\n           \"Média Ponderada\")\n)\n\nggplot(decomp_data, aes(x = Parametro, y = Valor, fill = Parametro)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(\"$\", round(Valor, 0), \"\\n\", Peso)), \n            vjust = -0.5, size = 3.5) +\n  labs(\n    title = \"Decomposição do ATE\",\n    x = \"Parâmetro\",\n    y = \"Efeito do Tratamento ($)\",\n    fill = \"Parâmetro\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_brewer(type = \"qual\", palette = \"Set2\")"
  },
  {
    "objectID": "posts/Pareamento/index.html",
    "href": "posts/Pareamento/index.html",
    "title": "Pareamento",
    "section": "",
    "text": "Pergunta de pesquisa: Programas de treinamento corporativo aumentam a produtividade dos funcionários?\nVariáveis: - Y: Produtividade mensal (R$ mil) - D: Participação em treinamento (0/1) - X: Experiência no cargo (anos)\n\n\n\nDefinição: Um confounder é uma variável que afeta tanto o tratamento quanto o resultado.\nNo nosso exemplo:\n\nExperiência → Treinamento: Funcionários inexperientes são mais enviados para treinamento\nExperiência → Produtividade: Funcionários experientes são naturalmente mais produtivos\n\nConclusão: não levar em conta o confounder (experiência) causa endogeneidade (viés de variável obtida).\n\n\n\n\nlibrary(tidyverse)\nlibrary(MatchIt)\nlibrary(Matching)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(123)\nn <- 800\n\n# Gerar dados com confounding negativo\ndados <- tibble(\n  # Experiência (confounder)\n  experiencia = pmax(0, rgamma(n, shape = 2, rate = 0.4)),\n  \n  # Probabilidade de treinamento (maior para inexperientes)\n  prob_treinamento = plogis(1.5 - 0.3 * experiencia),\n  treinamento = rbinom(n, 1, prob_treinamento),\n  \n  # Produtividade (depende de experiência E treinamento)\n  # Efeito verdadeiro do treinamento: +15 mil\n  produtividade = 25 + 8 * experiencia + 15 * treinamento + rnorm(n, 0, 10)\n) %>%\n  mutate(produtividade = pmax(5, produtividade))\n\n# Estatísticas por grupo\ndados %>%\n  group_by(treinamento) %>%\n  summarise(\n    n = n(),\n    experiencia_media = round(mean(experiencia), 1),\n    produtividade_media = round(mean(produtividade), 1),\n    .groups = \"drop\"\n  ) %>%\n  mutate(grupo = c(\"Sem Treinamento\", \"Com Treinamento\")) %>%\n  dplyr::select(grupo, everything(), -treinamento) %>%\n  kable()\n\n\n\n\ngrupo\nn\nexperiencia_media\nprodutividade_media\n\n\n\n\nSem Treinamento\n383\n5.9\n71.6\n\n\nCom Treinamento\n417\n3.5\n68.1\n\n\n\n\n\n\n\n\n\n# Análise ingênua (INCORRETA)\ndiferenca_ingenua <- dados %>%\n  group_by(treinamento) %>%\n  summarise(prod_media = mean(produtividade)) %>%\n  summarise(diferenca = diff(prod_media)) %>%\n  pull(diferenca)\n\ncat(\"Efeito aparente (sem controles):\", round(diferenca_ingenua, 1), \"mil reais \\n\")\n\nEfeito aparente (sem controles): -3.5 mil reais \n\ncat(\"Efeito verdadeiro (por construção): +15.0 mil reais \\n\")\n\nEfeito verdadeiro (por construção): +15.0 mil reais \n\ncat(\"Conclusão errônea: 'Treinamento não funciona!'\")\n\nConclusão errônea: 'Treinamento não funciona!'\n\n\nVisualização do problema:\n\np1 <- dados %>%\n  ggplot(aes(x = factor(treinamento), y = experiencia)) +\n  geom_boxplot() +\n  labs(title = \"Funcionários treinados têm menos experiência\",\n       x = \"Treinamento\", y = \"Experiência (anos)\")\n\np2 <- dados %>%\n  ggplot(aes(x = experiencia, y = produtividade, color = factor(treinamento))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Experiência confunde a relação\",\n       x = \"Experiência (anos)\", y = \"Produtividade (R$ mil)\",\n       color = \"Treinamento\")\n\nlibrary(gridExtra)\n\nWarning: pacote 'gridExtra' foi compilado no R versão 4.4.3\n\n\n\nAnexando pacote: 'gridExtra'\n\n\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    combine\n\ngrid.arrange(p1, p2, ncol = 2)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "posts/Pareamento/index.html#quando-avaliar-ex-ante-vs.-ex-post",
    "href": "posts/Pareamento/index.html#quando-avaliar-ex-ante-vs.-ex-post",
    "title": "Pareamento",
    "section": "Quando Avaliar: Ex-Ante vs. Ex-Post",
    "text": "Quando Avaliar: Ex-Ante vs. Ex-Post\nA decisão de quando realizar uma avaliação de impacto é crucial e depende dos objetivos. Existem dois momentos principais:\n\nAvaliação Ex-Ante: Realizada antes da implementação do programa, ela projeta os possíveis impactos e custos. Seu principal objetivo é informar a decisão sobre a adoção do programa, comparar alternativas de desenho e justificar o investimento. Por natureza, baseia-se em modelos teóricos e simulações, pois ainda não existem dados de beneficiários.\nAvaliação Ex-Post: Realizada durante ou após a execução do programa. Ela pode ser:\n\nDe percurso: Acontece enquanto o programa está em andamento. É ideal para verificar se as previsões ex-ante estão se confirmando e para orientar ajustes, aperfeiçoando o desenho em tempo real. É comum em programas piloto ou contínuos.\nDe encerramento: Feita após o término da intervenção, busca julgar a eficácia da alocação de recursos e capturar impactos de longo prazo, que podem demorar a se manifestar. Ajuda a consolidar o aprendizado e a informar o desenho de futuros programas.\n\n\nEm resumo, a avaliação ex-ante foca no planejamento e na otimização do desenho, enquanto a ex-post se concentra em medir o impacto real e gerar aprendizados a partir da experiência."
  },
  {
    "objectID": "posts/Pareamento/index.html#correlação-não-implica-causalidade",
    "href": "posts/Pareamento/index.html#correlação-não-implica-causalidade",
    "title": "Pareamento",
    "section": "Correlação não Implica Causalidade",
    "text": "Correlação não Implica Causalidade\nUm dos mantras mais repetidos em estatística e ciência de dados é: correlação não implica causalidade. Encontrar uma associação estatística entre duas variáveis, A e B, não é suficiente para concluir que A causa B. Existem pelo menos quatro possibilidades:\n\nCausalidade Direta: A de fato causa B (A → B).\nCausalidade Reversa: B, na verdade, causa A (B → A).\nFator de Confusão: Uma terceira variável, C, é a verdadeira causa tanto de A quanto de B (A ← C → B).\nCoincidência: A correlação observada é puramente acidental, um ruído nos dados sem significado prático.\n\nPor exemplo, o aumento nas vendas de sorvete pode estar correlacionado com o aumento no número de afogamentos. Seria um erro concluir que tomar sorvete causa afogamentos. O fator de confusão aqui é o verão: dias mais quentes (C) levam as pessoas a comprarem mais sorvete (A) e também a nadarem mais (B), aumentando o risco de afogamentos.\nPara que a causalidade de A para B seja plausível, a correlação é uma condição necessária (a menos que um outro fator C anule exatamente o efeito de A), mas definitivamente não é uma condição suficiente. A inferência causal busca justamente métodos para ir além da simples correlação e isolar o verdadeiro efeito causal."
  },
  {
    "objectID": "posts/Pareamento/index.html#o-modelo-de-resultados-potenciais-formalizando-a-causalidade",
    "href": "posts/Pareamento/index.html#o-modelo-de-resultados-potenciais-formalizando-a-causalidade",
    "title": "Pareamento",
    "section": "O Modelo de Resultados Potenciais: Formalizando a Causalidade",
    "text": "O Modelo de Resultados Potenciais: Formalizando a Causalidade\nPara superar o desafio do contrafactual, o Modelo de Resultados Potenciais (Potential Outcomes), popularizado por Donald Rubin, oferece uma estrutura conceitual poderosa. A ideia é definir a causalidade em termos de resultados que poderiam ter acontecido.\n\nA Ideia Central\nPara cada unidade de análise (um indivíduo, uma empresa, uma escola), imaginamos dois estados do mundo:\n\n\\(Y_i^1\\): O resultado que a unidade i teria se recebesse o tratamento (D=1).\n\\(Y_i^0\\): O resultado que a mesma unidade i teria se não recebesse o tratamento (D=0).\n\nO efeito causal individual do tratamento para a unidade i é a diferença entre esses dois resultados potenciais:\n\\[\n\\delta_i = Y_i^1 - Y_i^0\n\\]\nO problema fundamental, como já vimos, é que para cada unidade i, só podemos observar um desses resultados. O outro permanece um contrafactual. A equação de comutação formaliza isso:\n\\[\nY_i = D_i \\cdot Y_i^1 + (1 - D_i) \\cdot Y_i^0\n\\]\nOnde \\(D_i\\) é uma variável que indica se a unidade i recebeu o tratamento (\\(D_i=1\\)) ou não (\\(D_i=0\\)).\n\n\nEfeitos Médios de Interesse\nComo não podemos estimar o efeito individual para todos, o foco da avaliação de impacto se volta para os efeitos médios em uma população:\n\nATE (Average Treatment Effect): O efeito médio do tratamento para a população como um todo. É a média de todos os efeitos individuais.\n\\[\nATE = E[\\delta_i] = E[Y^1] - E[Y^0]\n\\]\nATT (Average Treatment Effect on the Treated): O efeito médio do tratamento apenas para aqueles que efetivamente o receberam.\n\\[\nATT = E[\\delta_i | D=1] = E[Y^1 | D=1] - E[Y^0 | D=1]\n\\]\nATU (Average Treatment Effect on the Untreated): O efeito médio do tratamento caso ele fosse aplicado naqueles que não o receberam.\n\\[\nATU = E[\\delta_i | D=0] = E[Y^1 | D=0] - E[Y^0 | D=0]\n\\]\n\nQuando os efeitos do tratamento são heterogêneos (ou seja, variam entre os indivíduos), esses três parâmetros podem ser bem diferentes. Por exemplo, um programa de qualificação profissional pode ter um impacto muito maior (ATT) para os que escolheram participar do que teria para a população em geral (ATE).\n\n\nPor que a Simples Comparação de Médias é Enganosa\nUma primeira abordagem, mais ingênua, seria simplesmente comparar a média do resultado para o grupo que recebeu o tratamento com a média do grupo que não recebeu:\n\\[\n\\text{Diferença ingênua} = E[Y | D=1] - E[Y | D=0]\n\\]\nNo entanto, essa diferença quase nunca corresponde ao verdadeiro efeito causal. Uma decomposição matemática revela por quê:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + (E[Y^0 | D=1] - E[Y^0 | D=0])\n\\]\nO segundo termo, \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), é o viés de seleção. Ele representa a diferença que já existia entre os grupos antes mesmo do tratamento. Se os indivíduos que procuram um curso de qualificação (D=1) já são, em média, mais motivados e teriam salários mais altos (\\(Y^0\\)) do que os que não procuram (D=0), a comparação simples irá superestimar o efeito do curso, misturando o impacto real com essa diferença pré-existente.\n\nA moral da história é que as escolhas (auto-seleção para o tratamento) são geralmente endógenas, ou seja, correlacionadas com os resultados potenciais. Sem uma fonte de variação exógena (aleatória), a comparação bruta é quase sempre enviesada."
  },
  {
    "objectID": "posts/Pareamento/index.html#decompondo-o-ate",
    "href": "posts/Pareamento/index.html#decompondo-o-ate",
    "title": "Pareamento",
    "section": "Decompondo o ATE",
    "text": "Decompondo o ATE\nUma das relações mais importantes na inferência causal é como o Average Treatment Effect (ATE) pode ser decomposto em função do Average Treatment Effect on the Treated (ATT) e do Average Treatment Effect on the Untreated (ATU). Esta decomposição é crucial para entender a heterogeneidade dos efeitos do tratamento, o viés de seleção e como generalizar resultados de um grupo para toda a população.\nO ATE pode ser expresso como uma média ponderada do ATT e ATU, onde os pesos são as proporções de indivíduos tratados e não tratados na população:\n\\[\nATE = P(D=1) \\times ATT + P(D=0) \\times ATU\n\\]\nEssa fórmula nos mostra que o efeito médio geral é uma combinação dos efeitos específicos em cada grupo. Se o efeito do tratamento for maior para aqueles que o escolheram (ATT > ATU), e esse grupo for grande, o ATE será mais próximo do ATT. A derivação matemática, baseada na lei da expectativa total, revela como essa relação emerge naturalmente das definições de cada parâmetro.\n_\n\nExemplo Prático: Programa de Treinamento Profissional\nImagine um programa de treinamento profissional onde 40% dos trabalhadores elegíveis decidem participar. É razoável supor que aqueles que participam são diferentes daqueles que não participam (e.g., mais motivados), e que o efeito do treinamento pode ser diferente para esses dois grupos.\n\n# Configurando dados hipotéticos\nset.seed(42)\nn_total <- 1000\nprop_treated <- 0.4\n\n# Efeitos heterogêneos\natt_true <- 5000\natu_true <- 2000\n\n# Resultados potenciais\nn_treated <- round(n_total * prop_treated)\ny0_treated <- rnorm(n_treated, mean = 30000, sd = 5000)\ny1_treated <- y0_treated + att_true + rnorm(n_treated, mean = 0, sd = 1000)\n\nn_untreated <- n_total - n_treated\ny0_untreated <- rnorm(n_untreated, mean = 25000, sd = 5000)\ny1_untreated <- y0_untreated + atu_true + rnorm(n_untreated, mean = 0, sd = 1000)\n\n# Criando data frame\ndata <- tibble(\n  id = 1:n_total,\n  D = c(rep(1, n_treated), rep(0, n_untreated)),\n  Y0 = c(y0_treated, y0_untreated),\n  Y1 = c(y1_treated, y1_untreated)\n) %>%\n  mutate(Y_obs = D * Y1 + (1 - D) * Y0)\n\n# Calculando os efeitos\neffects <- data %>%\n  summarise(\n    ATT = mean(Y1[D == 1]) - mean(Y0[D == 1]),\n    ATU = mean(Y1[D == 0]) - mean(Y0[D == 0]),\n    ATE_direct = mean(Y1) - mean(Y0),\n    prop_treated = mean(D)\n  ) %>%\n  mutate(ATE_decomposed = prop_treated * ATT + (1 - prop_treated) * ATU)\n\n# Exibindo resultados\ncat(\"ATT (efeito nos tratados): $\", round(effects$ATT, 3), \"\\n\")\n\nATT (efeito nos tratados): $ 4907.124 \n\ncat(\"ATU (efeito nos não-tratados): $\", round(effects$ATU, 3), \"\\n\")\n\nATU (efeito nos não-tratados): $ 2017.598 \n\ncat(\"ATE (cálculo direto): $\", round(effects$ATE_direct, 3), \"\\n\")\n\nATE (cálculo direto): $ 3173.408 \n\ncat(\"ATE (via decomposição): $\", round(effects$ATE_decomposed, 3), \"\\n\")\n\nATE (via decomposição): $ 3173.408 \n\n\nEste código simula uma população onde o grupo tratado tem um salário base maior e um efeito do tratamento mais elevado, refletindo um cenário de auto-seleção positiva. Os resultados do cálculo confirmam a decomposição do ATE e mostram como o ATE é uma média ponderada do ATT e do ATU.\nVisualizar exemplo em excel\n\n\nPor que Esta Decomposição Importa?\nA decomposição do ATE em função do ATT e ATU tem implicações profundas para a interpretação de resultados e o desenho de políticas públicas.\nViés de Seleção: A comparação ingênua entre tratados e controles pode ser decomposta como:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + \\text{Viés de Seleção}\n\\]\nOnde o viés de seleção é \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), representando a diferença que já existia entre os grupos antes do tratamento. Se os indivíduos que procuram um curso de qualificação já são mais motivados e teriam salários mais altos mesmo sem o curso, a comparação simples superestimará o efeito do programa.\nImplicações para Política Pública: Considere dois cenários para o programa de treinamento:\n\nExpansão Total: Oferecer o programa para toda a população elegível\nManutenção: Manter apenas para quem já participa\n\nA análise custo-benefício deve considerar que o efeito médio para novos participantes (ATU) pode ser diferente do efeito para os participantes atuais (ATT). Se o ATU for significativamente menor que o ATT, a expansão pode não ser custo-efetiva, mesmo que o programa atual seja bem-sucedido.\nGeneralização de Resultados: Quando extrapolamos resultados de um estudo para uma população diferente, precisamos considerar se a composição da nova população (proporção de “tipos” de indivíduos) é similar à do estudo original. Um programa que funciona bem em uma população com alta proporção de indivíduos motivados pode ter resultados diferentes em uma população com características distintas.\nPodemos também criar uma visualização para melhor compreender a distribuição dos efeitos:\n\n# Criando visualização dos efeitos individuais\ndata %>%\n  mutate(individual_effect = Y1 - Y0) %>%\n  ggplot(aes(x = individual_effect, fill = factor(D))) +\n  geom_histogram(alpha = 0.7, bins = 30, position = \"identity\") +\n  geom_vline(xintercept = effects$ATE_direct, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribuição dos Efeitos Individuais do Tratamento\",\n    x = \"Efeito Individual ($)\",\n    y = \"Frequência\",\n    fill = \"Grupo\",\n    caption = \"Linha vermelha tracejada representa o ATE\"\n  ) +\n  scale_fill_discrete(labels = c(\"Controle\", \"Tratamento\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n# Gráfico de barras mostrando a decomposição\ndecomp_data <- tibble(\n  Parametro = c(\"ATT\", \"ATU\", \"ATE\"),\n  Valor = c(effects$ATT, effects$ATU, effects$ATE_direct),\n  Peso = c(paste0(\"Peso: \", round(effects$prop_treated * 100, 1), \"%\"),\n           paste0(\"Peso: \", round((1 - effects$prop_treated) * 100, 1), \"%\"),\n           \"Média Ponderada\")\n)\n\nggplot(decomp_data, aes(x = Parametro, y = Valor, fill = Parametro)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(\"$\", round(Valor, 0), \"\\n\", Peso)), \n            vjust = -0.5, size = 3.5) +\n  labs(\n    title = \"Decomposição do ATE\",\n    x = \"Parâmetro\",\n    y = \"Efeito do Tratamento ($)\",\n    fill = \"Parâmetro\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_brewer(type = \"qual\", palette = \"Set2\")"
  },
  {
    "objectID": "posts/Pareamento/index.html#as-hipóteses-chave-para-identificação-causal",
    "href": "posts/Pareamento/index.html#as-hipóteses-chave-para-identificação-causal",
    "title": "Pareamento",
    "section": "As Hipóteses-Chave para Identificação Causal",
    "text": "As Hipóteses-Chave para Identificação Causal\nPara que possamos estimar os efeitos causais de forma válida a partir de dados observacionais, precisamos de algumas hipóteses que tornem a nossa análise crível. As três mais importantes são:\n\n1. Ignorabilidade (ou Independência Condicional)\nFormalmente, esta hipótese diz que, uma vez que controlamos por um conjunto de variáveis observáveis X, a alocação do tratamento é independente dos resultados potenciais.\n\\[\n(Y^1, Y^0) \\perp D \\mid X\n\\]\nEm um experimento aleatório controlado (RCT), essa hipótese é garantida pelo próprio desenho, pois a aleatorização torna o tratamento independente de qualquer característica dos indivíduos, observada ou não. Em estudos observacionais, a plausibilidade da ignorabilidade depende da nossa capacidade de medir e controlar por todos os fatores de confusão relevantes (o conjunto X).\n\n\n2. Suporte Comum (ou Overlap)\nEsta hipótese garante que, para qualquer conjunto de características X, existem tanto indivíduos tratados quanto não tratados.\n\\[\n0 < P(D=1 \\mid X) < 1\n\\]\nIntuitivamente, não podemos comparar o incomparável. Se um programa de reforço escolar é oferecido apenas para alunos com notas muito baixas, não temos um grupo de controle com características similares (notas baixas) para fazer a comparação. A falta de suporte comum impede a estimação do efeito causal para certos subgrupos da população.\n\n\n3. SUTVA (Stable Unit Treatment Value Assumption)\nA SUTVA é composta por duas sub-hipóteses:\n\nConsistência: O resultado potencial de um indivíduo sob um determinado tratamento corresponde ao resultado observado se ele de fato recebe aquele tratamento. Isso implica que não existem múltiplas “versões” do tratamento com efeitos diferentes.\nNão-Interferência: O tratamento recebido por uma unidade não afeta os resultados potenciais de outra unidade. Por exemplo, em um programa de vacinação, a vacinação de uma pessoa pode gerar um efeito de transbordamento (spillover) positivo para outras, protegendo-as também. A SUTVA assume que esses efeitos de interferência não existem.\n\nSem as hipóteses de ignorabilidade e suporte comum, a identificação do efeito causal falha. Sem a SUTVA, os próprios resultados potenciais não estão bem definidos."
  },
  {
    "objectID": "posts/Pareamento/index.html#como-obter-variação-exógena-os-desenhos-clássicos-de-identificação",
    "href": "posts/Pareamento/index.html#como-obter-variação-exógena-os-desenhos-clássicos-de-identificação",
    "title": "Pareamento",
    "section": "Como Obter Variação Exógena? Os Desenhos Clássicos de Identificação",
    "text": "Como Obter Variação Exógena? Os Desenhos Clássicos de Identificação\nO grande objetivo dos métodos de inferência causal é encontrar (ou simular) uma fonte de variação no tratamento que seja “tão boa quanto aleatória”. Cada método se baseia em um conjunto diferente de hipóteses para alcançar a identificação.\n\nExperimentos Aleatórios Controlados (RCTs)\nConsiderado o padrão-ouro, o RCT resolve o problema do viés de seleção ao aleatorizar a alocação do tratamento. A randomização garante, em média, que os grupos de tratamento e controle sejam idênticos em todas as características, observáveis e não observáveis. Assim, qualquer diferença nos resultados pode ser atribuída ao tratamento."
  },
  {
    "objectID": "posts/Introducao-Avaliacao-Impacto/index.html#exemplo-prático-programa-de-treinamento-profissional",
    "href": "posts/Introducao-Avaliacao-Impacto/index.html#exemplo-prático-programa-de-treinamento-profissional",
    "title": "Introdução à avaliação de Impacto",
    "section": "Exemplo Prático: Programa de Treinamento Profissional",
    "text": "Exemplo Prático: Programa de Treinamento Profissional\nImagine um programa de treinamento profissional onde 40% dos trabalhadores elegíveis decidem participar. É razoável supor que aqueles que participam são diferentes daqueles que não participam (e.g., mais motivados), e que o efeito do treinamento pode ser diferente para esses dois grupos.\n\n# Configurando dados hipotéticos\nset.seed(42)\nn_total <- 1000\nprop_treated <- 0.4\n\n# Efeitos heterogêneos\natt_true <- 5000\natu_true <- 2000\n\n# Resultados potenciais\nn_treated <- round(n_total * prop_treated)\ny0_treated <- rnorm(n_treated, mean = 30000, sd = 5000)\ny1_treated <- y0_treated + att_true + rnorm(n_treated, mean = 0, sd = 1000)\n\nn_untreated <- n_total - n_treated\ny0_untreated <- rnorm(n_untreated, mean = 25000, sd = 5000)\ny1_untreated <- y0_untreated + atu_true + rnorm(n_untreated, mean = 0, sd = 1000)\n\n# Criando data frame\ndata <- tibble(\n  id = 1:n_total,\n  D = c(rep(1, n_treated), rep(0, n_untreated)),\n  Y0 = c(y0_treated, y0_untreated),\n  Y1 = c(y1_treated, y1_untreated)\n) %>%\n  mutate(Y_obs = D * Y1 + (1 - D) * Y0)\n\n# Calculando os efeitos e a decomposição completa\neffects <- data %>%\n  summarise(\n    ATT = mean(Y1[D == 1]) - mean(Y0[D == 1]),\n    ATU = mean(Y1[D == 0]) - mean(Y0[D == 0]),\n    ATE_direct = mean(Y1) - mean(Y0),\n    prop_treated = mean(D),\n    # Diferença ingênua\n    naive_diff = mean(Y_obs[D == 1]) - mean(Y_obs[D == 0]),\n    # Viés de seleção\n    selection_bias = mean(Y0[D == 1]) - mean(Y0[D == 0]),\n    # Viés de heterogeneidade\n    heterogeneity_bias = (1 - mean(D)) * (ATT - ATU)\n  ) %>%\n  mutate(\n    ATE_decomposed = prop_treated * ATT + (1 - prop_treated) * ATU,\n    # Verificação da decomposição completa\n    naive_decomposed = ATE_direct + selection_bias + heterogeneity_bias\n  )\n\n# Exibindo resultados da decomposição completa\ncat(\"=== DECOMPOSIÇÃO DA DIFERENÇA INGÊNUA ===\\n\")\n\n=== DECOMPOSIÇÃO DA DIFERENÇA INGÊNUA ===\n\ncat(\"Diferença ingênua observada: $\", round(effects$naive_diff, 0), \"\\n\")\n\nDiferença ingênua observada: $ 9878 \n\ncat(\"ATE (efeito causal verdadeiro): $\", round(effects$ATE_direct, 0), \"\\n\")\n\nATE (efeito causal verdadeiro): $ 3173 \n\ncat(\"Viés de seleção: $\", round(effects$selection_bias, 0), \"\\n\")\n\nViés de seleção: $ 4970 \n\ncat(\"Viés de heterogeneidade: $\", round(effects$heterogeneity_bias, 0), \"\\n\")\n\nViés de heterogeneidade: $ 1734 \n\ncat(\"Soma dos componentes: $\", round(effects$naive_decomposed, 0), \"\\n\\n\")\n\nSoma dos componentes: $ 9878 \n\ncat(\"=== DECOMPOSIÇÃO DO ATE ===\\n\")\n\n=== DECOMPOSIÇÃO DO ATE ===\n\ncat(\"ATT (efeito nos tratados): $\", round(effects$ATT, 0), \"\\n\")\n\nATT (efeito nos tratados): $ 4907 \n\ncat(\"ATU (efeito nos não-tratados): $\", round(effects$ATU, 0), \"\\n\")\n\nATU (efeito nos não-tratados): $ 2018 \n\ncat(\"ATE (cálculo direto): $\", round(effects$ATE_direct, 0), \"\\n\")\n\nATE (cálculo direto): $ 3173 \n\ncat(\"ATE (via decomposição): $\", round(effects$ATE_decomposed, 0), \"\\n\")\n\nATE (via decomposição): $ 3173 \n\n\nEste código simula uma população onde o grupo tratado tem um salário base maior e um efeito do tratamento mais elevado, refletindo um cenário de auto-seleção positiva. Os resultados do cálculo confirmam a decomposição do ATE e mostram como o ATE é uma média ponderada do ATT e do ATU.\nVisualizar exemplo em excel\n\nPor que Esta Decomposição Importa?\nA decomposição do ATE em função do ATT e ATU tem implicações profundas para a interpretação de resultados e o desenho de políticas públicas.\nViés de Seleção: A comparação ingênua entre tratados e controles pode ser decomposta como:\n\\[\nE[Y | D=1] - E[Y | D=0] = ATT + \\text{Viés de Seleção}\n\\]\nOnde o viés de seleção é \\(E[Y^0 | D=1] - E[Y^0 | D=0]\\), representando a diferença que já existia entre os grupos antes do tratamento. Se os indivíduos que procuram um curso de qualificação já são mais motivados e teriam salários mais altos mesmo sem o curso, a comparação simples superestimará o efeito do programa.\nImplicações para Política Pública: Considere dois cenários para o programa de treinamento:\n\nExpansão Total: Oferecer o programa para toda a população elegível\nManutenção: Manter apenas para quem já participa\n\nA análise custo-benefício deve considerar que o efeito médio para novos participantes (ATU) pode ser diferente do efeito para os participantes atuais (ATT). Se o ATU for significativamente menor que o ATT, a expansão pode não ser custo-efetiva, mesmo que o programa atual seja bem-sucedido.\nGeneralização de Resultados: Quando extrapolamos resultados de um estudo para uma população diferente, precisamos considerar se a composição da nova população (proporção de “tipos” de indivíduos) é similar à do estudo original. Um programa que funciona bem em uma população com alta proporção de indivíduos motivados pode ter resultados diferentes em uma população com características distintas.\nPodemos também criar uma visualização para melhor compreender a distribuição dos efeitos:\n\n# Criando visualização dos efeitos individuais\ndata %>%\n  mutate(individual_effect = Y1 - Y0) %>%\n  ggplot(aes(x = individual_effect, fill = factor(D))) +\n  geom_histogram(alpha = 0.7, bins = 30, position = \"identity\") +\n  geom_vline(xintercept = effects$ATE_direct, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribuição dos Efeitos Individuais do Tratamento\",\n    x = \"Efeito Individual ($)\",\n    y = \"Frequência\",\n    fill = \"Grupo\",\n    caption = \"Linha vermelha tracejada representa o ATE\"\n  ) +\n  scale_fill_discrete(labels = c(\"Controle\", \"Tratamento\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n# Gráfico de barras mostrando a decomposição\ndecomp_data <- tibble(\n  Parametro = c(\"ATT\", \"ATU\", \"ATE\"),\n  Valor = c(effects$ATT, effects$ATU, effects$ATE_direct),\n  Peso = c(paste0(\"Peso: \", round(effects$prop_treated * 100, 1), \"%\"),\n           paste0(\"Peso: \", round((1 - effects$prop_treated) * 100, 1), \"%\"),\n           \"Média Ponderada\")\n)\n\nggplot(decomp_data, aes(x = Parametro, y = Valor, fill = Parametro)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(\"$\", round(Valor, 0), \"\\n\", Peso)), \n            vjust = -0.5, size = 3.5) +\n  labs(\n    title = \"Decomposição do ATE\",\n    x = \"Parâmetro\",\n    y = \"Efeito do Tratamento ($)\",\n    fill = \"Parâmetro\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = \"none\") +\n  scale_fill_brewer(type = \"qual\", palette = \"Set2\")"
  },
  {
    "objectID": "posts/Pareamento/index.html#intuição-básica",
    "href": "posts/Pareamento/index.html#intuição-básica",
    "title": "Pareamento",
    "section": "Intuição Básica",
    "text": "Intuição Básica\nIdeia central: Comparar funcionários similares que diferem apenas no tratamento.\nEstratégia:\n\nEncontrar funcionários com mesma experiência\nAlguns receberam treinamento, outros não\nCalcular diferença na produtividade"
  },
  {
    "objectID": "posts/Pareamento/index.html#framework-de-resultados-potenciais",
    "href": "posts/Pareamento/index.html#framework-de-resultados-potenciais",
    "title": "Pareamento",
    "section": "Framework de Resultados Potenciais",
    "text": "Framework de Resultados Potenciais\nPara cada funcionário \\(i\\):\n\n\\(Y_i^1\\): produtividade se recebe treinamento\n\\(Y_i^0\\): produtividade se não recebe treinamento\n\\(D_i\\): indicador de treinamento\n\\(X_i\\): experiência\n\nSuposição de Independência Condicional (CIA): \\[(Y_i^1, Y_i^0) \\perp D_i | X_i\\]\nInterpretação: Condicionalmente à experiência, a seleção para treinamento é “como se fosse” aleatória."
  },
  {
    "objectID": "posts/Pareamento/index.html#demonstração-subclassificação-manual",
    "href": "posts/Pareamento/index.html#demonstração-subclassificação-manual",
    "title": "Pareamento",
    "section": "Demonstração: Subclassificação Manual",
    "text": "Demonstração: Subclassificação Manual\nA subclassificação consiste em estimar o efeito do tratamento pela soma da diferença ponderada entre tratados e controles. A ponderação permite lidar com o problema de “covariates imbalance” (diferença na distribuição dos X’s entre os grupos).\n\n# Criar 4 estratos de experiência (simplificado)\ndados <- dados %>%\n  mutate(estrato_exp = case_when(\n    experiencia < 2 ~ \"Muito Inexperiente\",\n    experiencia < 4 ~ \"Inexperiente\", \n    experiencia < 7 ~ \"Intermediário\",\n    TRUE ~ \"Experiente\"\n  ))\n\n# Verificar distribuição dos estratos\ndados %>%\n  count(estrato_exp, treinamento) %>%\n  pivot_wider(names_from = treinamento, values_from = n, names_prefix = \"treinamento_\") %>%\n  kable(col.names = c(\"Estrato\", \"Sem Treinamento\", \"Com Treinamento\"))\n\n\n\n\nEstrato\nSem Treinamento\nCom Treinamento\n\n\n\n\nExperiente\n126\n28\n\n\nInexperiente\n98\n140\n\n\nIntermediário\n117\n127\n\n\nMuito Inexperiente\n42\n122\n\n\n\n\n# Calcular efeito dentro de cada estrato\nefeitos_por_estrato <- dados %>%\n  group_by(estrato_exp) %>%\n  summarise(\n    n = n(),\n    n_tratados = sum(treinamento),\n    n_controles = sum(1 - treinamento),\n    efeito = mean(produtividade[treinamento == 1]) - \n             mean(produtividade[treinamento == 0]),\n    .groups = \"drop\"\n  )\n\nefeitos_por_estrato %>%\n  kable(digits = 2, col.names = c(\"Estrato\", \"N Total\", \"N Tratados\", \"N Controles\", \"Efeito (R$ mil)\"))\n\n\n\n\nEstrato\nN Total\nN Tratados\nN Controles\nEfeito (R$ mil)\n\n\n\n\nExperiente\n154\n28\n126\n3.98\n\n\nInexperiente\n238\n140\n98\n15.04\n\n\nIntermediário\n244\n127\n117\n14.47\n\n\nMuito Inexperiente\n164\n122\n42\n14.11\n\n\n\n\n# Efeito médio ponderado\nate_corrigido <- efeitos_por_estrato %>%\n  mutate(peso = n / sum(n)) %>%\n  summarise(ate = sum(efeito * peso)) %>%\n  pull(ate)\n\ncat(\"Efeito corrigido:\", round(ate_corrigido, 2), \"mil reais\")\n\nEfeito corrigido: 12.55 mil reais\n\ncat(\"Agora recuperamos algo próximo do efeito verdadeiro\")\n\nAgora recuperamos algo próximo do efeito verdadeiro\n\n\nNesse caso estamos calculando o ATE a partir de 4 estratos da nossa amostra:\n\nA: Inexperiente\nB: Experiente\nC: Intermediário\nD: Muito Inexperiente\n\nO calculo do ATE foi baseado na soma ponderada de cada estrato da amostra:\n\\[\nATE =\n\\left ( \\bar{Y}^{1,A} - \\bar{Y}^{0,A} \\right ) \\frac{N^{A}}{N} +\n\\left ( \\bar{Y}^{1,B} - \\bar{Y}^{0,B} \\right ) \\frac{N^{B}}{N} +\n\\left ( \\bar{Y}^{1,C} - \\bar{Y}^{0,C} \\right ) \\frac{N^{C}}{N} +\n\\left ( \\bar{Y}^{1,D} - \\bar{Y}^{0,D} \\right ) \\frac{N^{D}}{N}\n\\] Imagine que exista outro confundidor: o regime de trabalho. Os trabalhadores CLT são mais engajados em participar do treinamento, mas tendem a ser menos produtivos. Já os trabalhadores PJ são menos engajados em participar do treinamento, mas tendem a ser mais produtivos.Nesse casos, considerando as classificações de experiencia e de regime de trabalho, temos 8 estratos:\n\nA1: Inexperiente e CLT\nA2: Inexperiente e PJ\nB1: Experiente e CLT\nB2: Experiente e PJ\nC1: Intermediário e CLT\nC2: Intermediário e PJ\nD1: Muito Inexperiente e CLT\nD2: Muito Inexperiente e PJ\n\nA medida que as variáveis de controle aumentam, começamos a ter dificuldade em colocar cada unidade (tratada ou não) em uma “caixinha” do X’s. Se a variável confundidora não for discreta (e.g. experiência em anos) a dificuldade aumenta.\nNesses casos, estimar o ATT pode ser mais fácil. Por exemplo, digamos que você não consegue colocar todas as unidades tratadas em um estrato, mas consegue colocar todas do grupo de controle. Logo, para cada estrato de unidade tratada você poderá construir um contrafactual (mas você não conseguirá um contrafactual par a grupo controle).\n\\[\nATT = \\sum^{K}_{k=1}\n\\left ( \\bar{Y}^{1,k} - \\bar{Y}^{0,k} \\right ) \\frac{N^{k}_{T}}{N_{T}}\n\\] Este problema causado pela dimensionalidade é um problema de suporte comum. Alternativamente, se preenchêssemos o resultado potencial ausente para cada unidade de tratamento usando uma unidade do grupo de controle que fosse “mais próxima” da unidade do grupo de tratamento para algum fator de confusão, poderíamos simplesmente calcular a média das diferenças. Esse método é conhecido como pareamento."
  },
  {
    "objectID": "posts/Pareamento/index.html#pareamento-exato",
    "href": "posts/Pareamento/index.html#pareamento-exato",
    "title": "Pareamento",
    "section": "3.1 Pareamento Exato",
    "text": "3.1 Pareamento Exato\nDefinição: Parear unidades com valores idênticos das covariáveis.\nVantagens: - Transparente e fácil de entender - Balance perfeito por construção - Não requer suposições funcionais\nDesvantagens: - Maldição da dimensionalidade - Perda de observações - Só funciona com covariáveis categóricas"
  },
  {
    "objectID": "posts/Pareamento/index.html#pareamento-aproximado",
    "href": "posts/Pareamento/index.html#pareamento-aproximado",
    "title": "Pareamento",
    "section": "3.2 Pareamento Aproximado",
    "text": "3.2 Pareamento Aproximado\nMotivação: Quando pareamento exato não é viável, pois tenho covariadas contínuas ou um conjunto de covariadas.\nEstratégias: - Nearest neighbor matching - Caliper matching\nO estimador do paraemento “1 para 1” é definido por: \\[\nATT = \\frac{1}{N_{T}}\\sum_{d_{i}=1}\\left (Y_{i} - Y_{j(i)} \\right )\n\\] Em que a unidade \\(j\\) é a unidade do grupo controle “mais próxima em termos de X” da unidade \\(i\\) do grupo tratado. Este estimador computa o ATT, pois a média é condicional a \\(d_{i}=1\\).\nSe no grupo controle encontrarmos mais de uma unidade parecida com a unidade tratada em termos dos Xs, podemos usar a média.\n\\[\nATT = \\frac{1}{N_{T}}\\sum_{d_{i}=1}\\left (Y_{i} - \\left [\\frac{1}{M} \\sum^{M}_{m=1} Y_{j_{m}(i) } \\right ] \\right )\n\\]\n\ndados$numeric_estrato_exp <- as.numeric(as.factor(dados$estrato_exp))\n\nM1_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 1,\n                estimand='ATT')\nsummary(M1_att) # The default estimate is ATT here\n\n\nEstimate...  15.406 \nAI SE......  0.94063 \nT-stat.....  16.379 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  600 \n\npares_detalhado <- data.frame(\n  tratado_id    = M1_att$index.treated,\n  controle_id   = M1_att$index.control,\n  produtividade_tratado = dados$produtividade[M1_att$index.treated],\n  produtividade_controle = dados$produtividade[M1_att$index.control],\n  X_tratado = dados$experiencia[M1_att$index.treated],\n  X_controle = dados$experiencia[M1_att$index.control]\n)\nhead(pares_detalhado)\n\n  tratado_id controle_id produtividade_tratado produtividade_controle X_tratado\n1          3           8              56.66426               19.52045 0.3609374\n2          4         388              76.77873               60.26301 4.1563083\n3          7         433              59.62470               35.35006 0.8767943\n4         10         326              71.28918               59.01813 4.9326166\n5         10         402              71.28918               59.50021 4.9326166\n6         13           1              59.29248               37.74784 2.2411907\n  X_controle\n1  0.3260003\n2  4.1818486\n3  0.8471077\n4  4.9292527\n5  4.9417003\n6  2.2302339\n\n\nPerceba que: o tratado 3 pareou com o controle 8, o tratado 4 com o controle 388, etc. Vamos definir um M=3.\n\nM3_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 3,\n                estimand='ATT')\nsummary(M3_att) # The default estimate is ATT here\n\n\nEstimate...  15.244 \nAI SE......  0.84785 \nT-stat.....  17.98 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  1303 \n\npares_detalhado_M3 <- data.frame(\n  tratado_id    = M3_att$index.treated,\n  controle_id   = M3_att$index.control,\n  produtividade_tratado = dados$produtividade[M3_att$index.treated],\n  produtividade_controle = dados$produtividade[M3_att$index.control],\n  X_tratado = dados$experiencia[M3_att$index.treated],\n  X_controle = dados$experiencia[M3_att$index.control]\n)\nhead(pares_detalhado_M3)\n\n  tratado_id controle_id produtividade_tratado produtividade_controle X_tratado\n1          3           8              56.66426               19.52045 0.3609374\n2          3         594              56.66426               26.65428 0.3609374\n3          3         690              56.66426               58.48778 0.3609374\n4          4         365              76.77873               65.01573 4.1563083\n5          4         388              76.77873               60.26301 4.1563083\n6          4         425              76.77873               61.86003 4.1563083\n  X_controle\n1  0.3260003\n2  0.4281087\n3  0.4083420\n4  4.1860628\n5  4.1818486\n6  4.1227288\n\n\nPerceba que: o tratado 3 pareou com o controle 8, 594 e 690; o tratado 4 com o controle 365, 388 e 425, etc. Vamos definir um M=3.\nÉ possível calcular o ATE usando o pareamento. O estimador é dado por: \\[\nATE = \\frac{1}{N}\\sum_{i=1}^{N} (2D_{i}-1) \\left (Y_{i} - \\left [\\frac{1}{M} \\sum^{M}_{m=1} Y_{j_{m}(i) } \\right ] \\right )\n\\] Quando \\(D_{i}=1\\), então esse termo principal se torna 1. E quando \\(D_{i}=0\\), então esse termo principal se torna -1, e os resultados invertem a ordem para que a observação do tratamento possa ser imputada.\n\nM3_ate <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 3,\n                estimand='ATE')\nsummary(M3_ate) # The default estimate is ATT here\n\n\nEstimate...  14.814 \nAI SE......  0.84969 \nT-stat.....  17.434 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  800 \nMatched number of observations  (unweighted).  2536 \n\n\nQuando temos muitas covariadas, podemos usar um criterio para medir a distancia entre elas e definir um caliper\n\nMaha_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                caliper  = .25,\n                Weight = 2, #mahalanobis\n                estimand='ATT')\nsummary(Maha_att) # The default estimate is ATT here\n\n\nEstimate...  15.406 \nAI SE......  0.94063 \nT-stat.....  16.379 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  600 \n\nCaliper (SDs)........................................   0.25 \nNumber of obs dropped by 'exact' or 'caliper'  0 \n\n\n\nDistância Euclidiana\n\nConceito: Distância “em linha reta” no espaço multidimensional.\nFórmula: \\(d = \\sqrt{\\sum_{k=1}^p (x_{1k} - x_{2k})^2}\\)\nonde \\(k\\) é o número de covariadas\nQuando usar: Poucas variáveis com escalas similares.\n\nDistância Mahalanobis\n\nConceito: Distância que considera a estrutura de correlação dos dados.\nFórmula: \\(d = \\sqrt{(x_1 - x_2)^T S^{-1} (x_1 - x_2)}\\)\nonde \\(S\\) é a matriz de covariância.\nQuando usar: Múltiplas covariáveis correlacionadas.\nO caliper define o limite máximo de distância para aceitar um pareamento. É como um “raio de busca” - só forma pares dentro desse raio."
  },
  {
    "objectID": "posts/Pareamento/index.html#propensity-score-matching",
    "href": "posts/Pareamento/index.html#propensity-score-matching",
    "title": "Pareamento",
    "section": "3.3 Propensity Score Matching",
    "text": "3.3 Propensity Score Matching\nIdeia revolucionária (Rosenbaum & Rubin, 1983): Reduzir dimensionalidade usando probabilidade de tratamento.\nPropensity Score: \\(e(X) = P(D = 1 | X)\\)\nTeorema: Se \\((Y^1, Y^0) \\perp D | X\\), então \\((Y^1, Y^0) \\perp D | e(X)\\)\n\nPassos do Propensity Score Matching:\n\nEstimar propensity score\nVerificar overlap\nFazer pareamento\nVerificar balance\nEstimar efeito\n\n\nO que é Balance? *Balance significa que os grupos tratado e controle têm distribuições similares das covariáveis após o pareamento.\nObjetivo: Se conseguimos balance perfeito, as únicas diferenças entre os grupos serão devido ao tratamento, não aos confounders.\n\n*|Diff.Adj| < 0.1: Excelente balance\n\n# Passo 1: Estimar propensity score\nps_model <- glm(treinamento ~ experiencia + I(experiencia^2), \n                data = dados, family = binomial)\n\nX  <- ps_model$fitted\nY  <- dados$produtividade\nTr  <- dados$treinamento\n\n# Passo 2: Verificar overlap\ndados$pscore <- predict(ps_model, type = \"response\")\n\ndados %>%\n  ggplot(aes(x = pscore, fill = factor(treinamento))) +\n  geom_histogram(alpha = 0.7, position = \"identity\", bins = 25) +\n  labs(title = \"Distribuição dos Propensity Scores\",\n       x = \"Propensity Score\", y = \"Frequência\",\n       fill = \"Treinamento\") +\n  theme_minimal()\n\n\n\n# Passo 3: Fazer pareamento\nrr  <- Match(Y=Y, Tr=Tr, X=X, M=1);\nsummary(rr)\n\n\nEstimate...  15.281 \nAI SE......  0.9384 \nT-stat.....  16.284 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  571 \n\nmb  <- MatchBalance(treinamento ~ experiencia + I(experiencia^2),  data=dados, match.out=rr, nboots=10)\n\nWarning in ks.test.default(...): O valor-p será aproximado na presença de\nempates\nWarning in ks.test.default(...): O valor-p será aproximado na presença de\nempates\n\n\n\n***** (V1) experiencia *****\n                       Before Matching       After Matching\nmean treatment........     3.5041            3.5041 \nmean control..........     5.9115            3.5064 \nstd mean diff.........    -106.34          -0.10125 \n\nmean raw eQQ diff.....     2.4243           0.01421 \nmed  raw eQQ diff.....     1.9071         0.0079278 \nmax  raw eQQ diff.....     7.3303           0.29034 \n\nmean eCDF diff........    0.20697         0.0025845 \nmed  eCDF diff........    0.23461         0.0017513 \nmax  eCDF diff........     0.3012          0.015762 \n\nvar ratio (Tr/Co).....    0.37858            1.0009 \nT-test p-value........ < 2.22e-16           0.14818 \nKS Bootstrap p-value.. < 2.22e-16                 1 \nKS Naive p-value...... 3.7114e-16                 1 \nKS Statistic..........     0.3012          0.015762 \n\n\n***** (V2) I(experiencia^2) *****\n                       Before Matching       After Matching\nmean treatment........     17.391            17.391 \nmean control..........     48.447            17.403 \nstd mean diff.........    -134.36         -0.050585 \n\nmean raw eQQ diff.....     31.299          0.099713 \nmed  raw eQQ diff.....     15.674           0.04658 \nmax  raw eQQ diff.....     234.91            5.9291 \n\nmean eCDF diff........    0.20697         0.0025845 \nmed  eCDF diff........    0.23461         0.0017513 \nmax  eCDF diff........     0.3012          0.015762 \n\nvar ratio (Tr/Co).....    0.14395           0.99165 \nT-test p-value........ < 2.22e-16           0.56036 \nKS Bootstrap p-value.. < 2.22e-16                 1 \nKS Naive p-value...... 3.7114e-16                 1 \nKS Statistic..........     0.3012          0.015762 \n\n\nBefore Matching Minimum p.value: < 2.22e-16 \nVariable Name(s): experiencia I(experiencia^2)  Number(s): 1 2 \n\nAfter Matching Minimum p.value: 0.14818 \nVariable Name(s): experiencia  Number(s): 1"
  },
  {
    "objectID": "posts/Pareamento/index.html#comparação-dos-métodos",
    "href": "posts/Pareamento/index.html#comparação-dos-métodos",
    "title": "Pareamento",
    "section": "Comparação dos Métodos",
    "text": "Comparação dos Métodos\n\nresultados_pareamento <- tibble(\n  Método = c(\"Análise Ingênua\", \"Subclassificação\", \"Pareamento Exato\", \n             \"Nearest Neighbor\", \"Propensity Score\"),\n  ATE = c(diferenca_ingenua, ate_corrigido, ate_exact, ate_nearest, ate_ps),\n  `Erro vs Verdadeiro` = c(diferenca_ingenua - 15, ate_corrigido - 15, \n                          ate_exact - 15, ate_nearest - 15, ate_ps - 15)\n)\n\nresultados_pareamento %>%\n  kable(digits = 2, caption = \"Comparação dos Métodos de Pareamento\")\n\n\nComparação dos Métodos de Pareamento\n\n\nMétodo\nATE\nErro vs Verdadeiro\n\n\n\n\nAnálise Ingênua\n-3.48\n-18.48\n\n\nSubclassificação\n12.55\n-2.45\n\n\nPareamento Exato\n11.38\n-3.62\n\n\nNearest Neighbor\n11.29\n-3.71\n\n\nPropensity Score\n-7.09\n-22.09"
  },
  {
    "objectID": "posts/Pareamento/index.html#teorema-da-equivalência",
    "href": "posts/Pareamento/index.html#teorema-da-equivalência",
    "title": "Pareamento",
    "section": "Teorema da Equivalência",
    "text": "Teorema da Equivalência\nResultado fundamental: Sob certas condições, pareamento exato e MQO múltiplo produzem estimativas idênticas.\n\nCondições Necessárias:\n\nCovariáveis discretas: X deve ser categórica\nEspecificação saturada: MQO deve incluir todas as interações\nSupport comum: Cada estrato deve ter tratados e controles"
  },
  {
    "objectID": "posts/Pareamento/index.html#demonstração-matemática",
    "href": "posts/Pareamento/index.html#demonstração-matemática",
    "title": "Pareamento",
    "section": "Demonstração Matemática",
    "text": "Demonstração Matemática\nPara \\(J\\) estratos definidos por \\(X\\):\nPareamento exato: \\[\\hat{\\tau}_{match} = \\frac{1}{J} \\sum_{j=1}^J (\\bar{Y}_{1j} - \\bar{Y}_{0j})\\]\nMQO saturado: \\[Y_i = \\alpha + \\tau D_i + \\sum_{j=1}^J \\beta_j X_{ij} + \\sum_{j=1}^J \\gamma_j (D_i \\times X_{ij}) + \\varepsilon_i\\]\nO coeficiente \\(\\hat{\\tau}\\) do MQO saturado é igual a \\(\\hat{\\tau}_{match}\\)."
  },
  {
    "objectID": "posts/Pareamento/index.html#demonstração-empírica",
    "href": "posts/Pareamento/index.html#demonstração-empírica",
    "title": "Pareamento",
    "section": "Demonstração Empírica",
    "text": "Demonstração Empírica\n\n# MQO simples (sem interações)\nmodelo_simples <- lm(produtividade ~ treinamento + estrato_exp, data = dados)\n\n# MQO saturado (com interações)\nmodelo_saturado <- lm(produtividade ~ treinamento * estrato_exp, data = dados)\n\n# Comparar com pareamento exato\ncomparacao_equivalencia <- tibble(\n  Método = c(\"Pareamento Exato\", \"MQO Simples\", \"MQO Saturado\"),\n  ATE = c(ate_exact, \n          coef(modelo_simples)[\"treinamento\"],\n          coef(modelo_saturado)[\"treinamento\"]),\n  `Diferença vs Pareamento` = c(0,\n                               coef(modelo_simples)[\"treinamento\"] - ate_exact,\n                               coef(modelo_saturado)[\"treinamento\"] - ate_exact)\n)\n\ncomparacao_equivalencia %>%\n  kable(digits = 4, caption = \"Demonstração da Equivalência\")\n\n\nDemonstração da Equivalência\n\n\nMétodo\nATE\nDiferença vs Pareamento\n\n\n\n\nPareamento Exato\n11.3848\n0.0000\n\n\nMQO Simples\n13.2043\n1.8195\n\n\nMQO Saturado\n3.9840\n-7.4009\n\n\n\n\n\nResultado: MQO saturado = Pareamento exato (diferença ≈ 0)"
  },
  {
    "objectID": "posts/Pareamento/index.html#por-que-a-equivalência-funciona",
    "href": "posts/Pareamento/index.html#por-que-a-equivalência-funciona",
    "title": "Pareamento",
    "section": "Por que a Equivalência Funciona?",
    "text": "Por que a Equivalência Funciona?\nIntuição: - MQO saturado estima efeito separado em cada estrato - Pareamento exato calcula diferença dentro de cada estrato - Ambos fazem média ponderada pelos tamanhos dos estratos\nDiferença na ponderação: - MQO: pondera pelo tamanho dos estratos na amostra total - Pareamento: pondera pelo número de pares formados"
  },
  {
    "objectID": "posts/Pareamento/index.html#quando-a-equivalência-falha",
    "href": "posts/Pareamento/index.html#quando-a-equivalência-falha",
    "title": "Pareamento",
    "section": "Quando a Equivalência Falha?",
    "text": "Quando a Equivalência Falha?\n\n1. Covariáveis Contínuas\n\n# MQO com experiência contínua\nmodelo_continuo <- lm(produtividade ~ treinamento + experiencia, data = dados)\n\n# Comparar com propensity score\ncat(\"MQO contínuo:\", round(coef(modelo_continuo)[\"treinamento\"], 2), \"mil reais\\n\")\n\nMQO contínuo: 15.63 mil reais\n\ncat(\"Propensity Score:\", round(ate_ps, 2), \"mil reais\\n\")\n\nPropensity Score: -7.09 mil reais\n\ncat(\"Diferença:\", round(coef(modelo_continuo)[\"treinamento\"] - ate_ps, 2), \"mil reais\")\n\nDiferença: 22.71 mil reais\n\n\n\n\n2. Especificação Não-Saturada\n\ncat(\"MQO simples (sem interações):\", round(coef(modelo_simples)[\"treinamento\"], 2), \"mil reais\\n\")\n\nMQO simples (sem interações): 13.2 mil reais\n\ncat(\"Pareamento exato:\", round(ate_exact, 2), \"mil reais\\n\")\n\nPareamento exato: 11.38 mil reais\n\ncat(\"Diferença:\", round(coef(modelo_simples)[\"treinamento\"] - ate_exact, 2), \"mil reais\")\n\nDiferença: 1.82 mil reais\n\n\n\n\n3. Amostras Desbalanceadas\nQuando alguns estratos têm poucos tratados ou controles, as ponderações diferem significativamente."
  },
  {
    "objectID": "posts/Pareamento/index.html#implicações-práticas",
    "href": "posts/Pareamento/index.html#implicações-práticas",
    "title": "Pareamento",
    "section": "Implicações Práticas",
    "text": "Implicações Práticas\nQuando usar cada método?\n\n\n\n\n\n\n\n\nSituação\nMétodo Recomendado\nRazão\n\n\n\n\nPoucas covariáveis categóricas\nPareamento exato ou MQO saturado\nEquivalentes\n\n\nMuitas covariáveis\nPropensity score\nReduz dimensionalidade\n\n\nCovariáveis contínuas\nMQO ou propensity score\nPareamento exato inviável\n\n\nTransparência necessária\nPareamento\nMais fácil de explicar\n\n\nEficiência estatística\nMQO\nUsa toda a amostra"
  },
  {
    "objectID": "posts/Pareamento/index.html#principais-conceitos",
    "href": "posts/Pareamento/index.html#principais-conceitos",
    "title": "Pareamento",
    "section": "Principais Conceitos",
    "text": "Principais Conceitos\n\nConfounders podem mascarar efeitos causais verdadeiros\nPareamento corrige o problema comparando unidades similares\nTipos de pareamento: exato, aproximado, propensity score\nEquivalência: MQO saturado = pareamento exato (sob condições específicas)"
  },
  {
    "objectID": "posts/Pareamento/index.html#lições-práticas",
    "href": "posts/Pareamento/index.html#lições-práticas",
    "title": "Pareamento",
    "section": "Lições Práticas",
    "text": "Lições Práticas\n\nSempre suspeite de análises que ignoram confounders\nVerifique balance após pareamento\nUse propensity score quando há muitas covariáveis\nMQO e pareamento são complementares, não substitutos"
  },
  {
    "objectID": "posts/Pareamento/index.html#próxima-aula",
    "href": "posts/Pareamento/index.html#próxima-aula",
    "title": "Pareamento",
    "section": "Próxima Aula",
    "text": "Próxima Aula\n\nRegression Discontinuity Design\nExplorando descontinuidades na atribuição de tratamento"
  },
  {
    "objectID": "posts/Pareamento/index.html#referências",
    "href": "posts/Pareamento/index.html#referências",
    "title": "Pareamento",
    "section": "Referências",
    "text": "Referências\n\nRosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41-55.\nImbens, G. W., & Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences. Cambridge University Press.\nAngrist, J. D., & Pischke, J. S. (2008). Mostly Harmless Econometrics. Princeton University Press."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html",
    "href": "posts/Diferenças-em-diferenças/index.html",
    "title": "DID",
    "section": "",
    "text": "Normalmente, o pesquisador não tem acesso a dados de experimentos controlados e randomizados. Mesmo assim o infêrencial causal continua sendo de interesse. O método de diferenças em diferenças utiliza a dinamica temporal para dirimir a víes de seleção. A sua beleza reside na simplicidade com que, sob certas hipóteses, consegue isolar o efeito de um tratamento, controlando por fatores não observáveis que poderiam confundir a nossa análise.\nNeste post, vamos mergulhar na intuição por trás do DiD. Começaremos com a intuição do método. Em seguida, desvendaremos como o DiD elimina o viés de seleção, qual a sua hipótese fundamental – as tendências paralelas – e como podemos testá-la visualmente através de estudos de eventos. Por fim, abordaremos uma extensão robusta, as Triplas Diferenças (DDD), e ilustraremos todos esses conceitos com dados simulados, mostrando o poder do método na prática."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#a-intuição-do-método-did",
    "href": "posts/Diferenças-em-diferenças/index.html#a-intuição-do-método-did",
    "title": "DID",
    "section": "A Intuição do Método DiD",
    "text": "A Intuição do Método DiD\n\nPor que Comparações Simples Falham?\nImagine que queremos avaliar se a desoneração aumentou o emprego. Poderíamos ser tentados a fazer duas comparações simples:\n\nComparação Cross-Sectional (2012-2017): Comparar o emprego médio nos setores desonerados com os não desonerados após a política. O problema? Os setores desonerados (como TI e construção civil) já eram naturalmente mais intensivos em mão de obra antes da política. Essa diferença estrutural entre os setores é o que chamamos de viés de seleção ou efeito fixo de grupo.\nComparação Temporal (Setores Desonerados): Comparar o emprego nos setores desonerados antes e depois de 2012. O problema? Entre 2008 e 2017, a economia brasileira passou por ciclos de crescimento e recessão que afetaram todos os setores. Atribuir toda a mudança à desoneração ignoraria essas tendências temporais comuns.\n\n\n\nO DiD\nO DiD combina ambas as abordagens de forma engenhosa. A primeira diferença (temporal) para cada grupo remove os efeitos fixos. A segunda diferença (entre grupos) remove as tendências temporais comuns. O que sobra é o efeito causal da política.\nVamos decompor isso com um exemplo intuitivo usando símbolos:\n\n\n\n\n\n\n\n\n\nGrupo\nAntes (2008-2011)\nDepois (2012-2017)\nDiferença Temporal\n\n\n\n\nSetores Desonerados\nD + S\nD + S + T + E\nT + E\n\n\nSetores Não Desonerados\nS\nS + T\nT\n\n\nDiferença entre Grupos\nD\nD + E\nE ← DiD\n\n\n\nLegenda dos Efeitos:\n\nD: Efeito fixo dos setores desonerados (ex: TI e construção são naturalmente mais intensivos em mão de obra)\nS: Efeito fixo dos setores não desonerados (baseline comum)\nT: Tendência temporal comum (crescimento/recessão econômica que afeta todos os setores)\nE: Efeito causal da desoneração (o que queremos estimar)\n\nComo o DiD Funciona:\n\nPrimeira diferença temporal elimina os efeitos fixos (D e S desaparecem)\nSegunda diferença entre grupos elimina a tendência temporal comum (T desaparece)\nO que sobra é E: o efeito causal puro da desoneração\n\nFormalmente, o estimador DiD é:\n\\[\nDiD = [E[Y | D=1, Post] - E[Y | D=1, Pre]] - [E[Y | D=0, Post] - E[Y | D=0, Pre]]\n\\] ## Como o DiD Elimina o Viés de Seleção do ATT\n\n\nO Problema Fundamental da Inferência Causal\nO que realmente queremos estimar é o Efeito Médio do Tratamento sobre os Tratados (ATT):\n\\[\nATT = E[Y^{1} | D=1] - E[Y^{0} | D=1]\n\\]\nOnde \\(Y^{1}\\) é o emprego com desoneração e \\(Y^{0}\\) é o emprego sem desoneração. O primeiro termo é observável (vemos o emprego nos setores desonerados após 2012). O problema é o segundo termo: o emprego contrafactual que teria ocorrido nos setores desonerados se a política não tivesse sido implementada. Esse contrafactual é, por definição, inobservável.\nComo agora acompanhamos as unidades no tempo, podemos reescrever nosso ATT como:\n\\[\nATT = E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Post]\n\\]\nUma vez que se \\(D=1\\) estamos considerando o período pós tratamento.\n\n\nA Hipótese de Tendências Paralelas\nO DiD resolve esse problema fazendo uma hipótese crucial: na ausência do tratamento, a trajetória do emprego nos setores desonerados teria sido a mesma que a trajetória observada nos setores não desonerados. Formalmente:\n\\[\nE[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre] = E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre=1]\n\\]\nEm palavras: a mudança no emprego para os setores controle é um bom proxy para a mudança que teria ocorrido nos setores desonerados na ausência da política. Se essa hipótese for válida, o DiD identifica perfeitamente o ATT.\n\n\nDecomposição do Estimador\nPodemos decompor o estimador DiD da seguinte forma: \\[\nDiD = ATT + [E[Y^{0}|D=1,Post] - E[Y^{0}|D=1,Pre]] - [E[Y^{0} |D=0,Post] - E[Y^{0}|D=0,Pre]]\n\\] O segundo termo é o viés de tendências não-paralelas. Se as tendências forem paralelas (segundo termo = 0), então DiD = ATT. O método usa a tendência do grupo controle para construir o contrafactual não observado do grupo tratado.\nPara entender como chegamos na decomposição acima, vamos rescrever o estimador DiD por meio dos resultados potenciais:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]\n\\] Somando e subtraindo do lado direito da equação por \\([E[Y^{0} | D=1, Post]\\), temos:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]] + ([E[Y^{0} | D=1, Post] - [E[Y^{0} | D=1, Post])\n\\] Rearranjando as expressões temos:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - [E[Y^{0} | D=1, Post] + [E[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]  \n\\] Em que:\n\n\\([E[Y^{1} | D=1, Post] - [E[Y^{0} | D=1, Post]= ATT\\)\n\\([E[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]\\) é o viés causado por tendencias não paralelas\n\n\n\nOutras Hipóteses Necessárias\nAlém de tendências paralelas, o DiD requer:\n\nSUTVA (Stable Unit Treatment Value Assumption): O tratamento de uma empresa não afeta o resultado de outras\nExogeneidade do Timing: A implementação em 2012 não foi antecipada de forma a alterar comportamentos pré-tratamento\nComposição Estável: A composição dos setores não muda drasticamente (ex: empresas não migram entre setores)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#como-o-did-elimina-o-viés-de-seleção-do-att",
    "href": "posts/Diferenças-em-diferenças/index.html#como-o-did-elimina-o-viés-de-seleção-do-att",
    "title": "DID",
    "section": "Como o DiD Elimina o Viés de Seleção do ATT",
    "text": "Como o DiD Elimina o Viés de Seleção do ATT\n\nO Problema Fundamental da Inferência Causal\nO que realmente queremos estimar é o Efeito Médio do Tratamento sobre os Tratados (ATT):\n\\[\nATT = E[Y^{1} | D=1] - E[Y^{0} | D=1]\n\\]\nOnde \\(Y^{1}\\) é o emprego com desoneração e \\(Y^{0}\\) é o emprego sem desoneração. O primeiro termo é observável (vemos o emprego nos setores desonerados após 2012). O problema é o segundo termo: o emprego contrafactual que teria ocorrido nos setores desonerados se a política não tivesse sido implementada. Esse contrafactual é, por definição, inobservável.\nComo agora acompanhamos as unidades no tempo, podemos reescrever nosso ATT como:\n\\[\nATT = E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Post]\n\\]\nUma vez que se \\(D=1\\) estamos considerando o período pós tratamento.\n\n\nA Hipótese de Tendências Paralelas\nO DiD resolve esse problema fazendo uma hipótese crucial: na ausência do tratamento, a trajetória do emprego nos setores desonerados teria sido a mesma que a trajetória observada nos setores não desonerados. Formalmente:\n\\[\nE[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre] = E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre=1]\n\\]\nEm palavras: a mudança no emprego para os setores controle é um bom proxy para a mudança que teria ocorrido nos setores desonerados na ausência da política. Se essa hipótese for válida, o DiD identifica perfeitamente o ATT.\n\n\nDecomposição do Estimador\nPodemos decompor o estimador DiD da seguinte forma: \\[\nDiD = ATT + [E[Y^{0}|D=1,Post] - E[Y^{0}|D=1,Pre]] - [E[Y^{0} |D=0,Post] - E[Y^{0}|D=0,Pre]]\n\\] O segundo termo é o viés de tendências não-paralelas. Se as tendências forem paralelas (segundo termo = 0), então DiD = ATT. O método usa a tendência do grupo controle para construir o contrafactual não observado do grupo tratado.\nPara entender como chegamos na decomposição acima, vamos rescrever o estimador DiD por meio dos resultados potenciais:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]\n\\] Somando e subtraindo do lado direito da equação por \\([E[Y^{0} | D=1, Post]\\), temos:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]] + ([E[Y^{0} | D=1, Post] - [E[Y^{0} | D=1, Post])\n\\] Rearranjando as expressões temos:\n\\[\nDiD = [E[Y^{1} | D=1, Post] - [E[Y^{0} | D=1, Post] + [E[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]  \n\\] Em que:\n\n\\([E[Y^{1} | D=1, Post] - [E[Y^{0} | D=1, Post]= ATT\\)\n\\([E[Y^{0} | D=1, Post] - E[Y^{0} | D=1, Pre]] - [E[Y^{0} | D=0, Post] - E[Y^{0} | D=0, Pre]]\\) é o viés causado por tendencias não paralelas\n\n\n\nOutras Hipóteses Necessárias\nAlém de tendências paralelas, o DiD requer:\n\nSUTVA (Stable Unit Treatment Value Assumption): O tratamento de uma empresa não afeta o resultado de outras\nExogeneidade do Timing: A implementação em 2012 não foi antecipada de forma a alterar comportamentos pré-tratamento\nComposição Estável: A composição dos setores não muda drasticamente (ex: empresas não migram entre setores)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#do-cálculo-manual-à-regressão-ols",
    "href": "posts/Diferenças-em-diferenças/index.html#do-cálculo-manual-à-regressão-ols",
    "title": "DID",
    "section": "Do Cálculo Manual à Regressão OLS",
    "text": "Do Cálculo Manual à Regressão OLS\nAté agora, estimamos o DiD calculando manualmente as diferenças de médias. Mas há uma forma mais elegante e flexível: regressão por Mínimos Quadrados Ordinários (OLS). Surpreendentemente, uma regressão simples com uma interação recupera exatamente o mesmo estimador DiD.\n\nA Especificação de Regressão\nConsidere o seguinte modelo de regressão linear:\n\\[Y_{it} = \\beta_0 + \\beta_1 \\text{Desonerado}_i + \\beta_2 \\text{Post}_t + \\beta_3 (\\text{Desonerado}_i \\times \\text{Post}_t) + \\varepsilon_{it}\\]\nOnde: - \\(Y_{it}\\) é o número de trabalhadores na empresa \\(i\\) no período \\(t\\) - \\(\\text{Desonerado}_i = 1\\) se a empresa está em setor desonerado, 0 caso contrário - \\(\\text{Post}_t = 1\\) se o período é pós-2012, 0 caso contrário - \\(\\text{Desonerado}_i \\times \\text{Post}_t\\) é a interação entre tratamento e período\nInterpretação dos Coeficientes: - \\(\\beta_0\\): Emprego médio nos setores não desonerados antes de 2012 (grupo base) - \\(\\beta_1\\): Diferença fixa entre setores desonerados e não desonerados (efeito fixo de grupo) - \\(\\beta_2\\): Mudança temporal comum a todos os setores (tendência temporal) - \\(\\beta_3\\): Efeito causal da desoneração (DiD/ATT)\n\n\nDemonstração Matemática: \\(\\beta_3 = \\text{DiD}\\)\nVamos provar que \\(\\beta_3\\) é exatamente igual ao estimador DiD que calculamos manualmente.\nPasso 1: Valores Esperados para Cada Grupo-Período\nUsando a equação de regressão, podemos calcular o valor esperado de \\(Y\\) para cada combinação de grupo e período:\n\n\n\n\n\n\n\n\n\n\n\nGrupo\nPeríodo\nDesonerado\nPost\nInteração\n\\(E[Y]\\)\n\n\n\n\nNão Desonerado\nAntes\n0\n0\n0\n\\(\\beta_0\\)\n\n\nNão Desonerado\nDepois\n0\n1\n0\n\\(\\beta_0 + \\beta_2\\)\n\n\nDesonerado\nAntes\n1\n0\n0\n\\(\\beta_0 + \\beta_1\\)\n\n\nDesonerado\nDepois\n1\n1\n1\n\\(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3\\)\n\n\n\nPasso 2: Primeira Diferença (Temporal) para Cada Grupo\nSetores Desonerados: \\[\\Delta_{\\text{Desonerado}} = (\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3) - (\\beta_0 + \\beta_1) = \\beta_2 + \\beta_3\\]\nSetores Não Desonerados: \\[\\Delta_{\\text{Não Desonerado}} = (\\beta_0 + \\beta_2) - \\beta_0 = \\beta_2\\]\nPasso 3: Segunda Diferença (DiD)\n\\[\\text{DiD} = \\Delta_{\\text{Desonerado}} - \\Delta_{\\text{Não Desonerado}} = (\\beta_2 + \\beta_3) - \\beta_2 = \\beta_3\\]\nConclusão: O coeficiente da interação \\(\\beta_3\\) é exatamente o estimador DiD!\n\n\nVisualização da Decomposição\nPodemos reorganizar a tabela acima para ver claramente como cada componente contribui:\n\n\n\n\n\n\n\n\n\nGrupo\nPeríodo\nValor Esperado\nDecomposição\n\n\n\n\nNão Desonerado\nAntes\n\\(\\beta_0\\)\nBaseline\n\n\nNão Desonerado\nDepois\n\\(\\beta_0 + \\beta_2\\)\nBaseline + Tendência\n\n\nDesonerado\nAntes\n\\(\\beta_0 + \\beta_1\\)\nBaseline + Efeito Fixo\n\n\nDesonerado\nDepois\n\\(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3\\)\nBaseline + Efeito Fixo + Tendência + DiD\n\n\n\nNote que: - \\(\\beta_0\\) cancela em todas as diferenças - \\(\\beta_1\\) cancela na diferença temporal - \\(\\beta_2\\) cancela na diferença entre grupos - \\(\\beta_3\\) sobrevive como o único termo não cancelado"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#aplicação-prática-com-dados-simulados-n100",
    "href": "posts/Diferenças-em-diferenças/index.html#aplicação-prática-com-dados-simulados-n100",
    "title": "DID",
    "section": "Aplicação Prática com Dados Simulados (N=100)",
    "text": "Aplicação Prática com Dados Simulados (N=100)\nPara tornar os conceitos mais concretos, vamos simular dados de painel com 100 empresas (50 em setores desonerados, 50 em setores controle) ao longo de 9 anos (2007-2015). A desoneração é implementada em 2012 e tem um efeito verdadeiro de +25 trabalhadores.\n\n# Configurar seed para reprodutibilidade\nset.seed(42)\n\n# Parâmetros da simulação\nn_empresas <- 100\nn_anos <- 9  # 2007-2015\nano_inicio <- 2007\nano_desoneracao <- 2012\n\n# Metade das empresas em setores desonerados\nn_desonerado <- n_empresas / 2\n\n# Criar data frame vazio\ndados <- data.frame()\n\nfor (i in 1:n_empresas) {\n  # Determinar se empresa está em setor desonerado\n  desonerado <- ifelse(i <= n_desonerado, 1, 0)\n  \n  # Efeito fixo da empresa\n  # Setores desonerados têm baseline maior (mais intensivos em mão de obra)\n  efeito_fixo <- 100 + (30 * desonerado) + rnorm(1, mean = 0, sd = 10)\n  \n  for (t in 0:(n_anos - 1)) {\n    ano <- ano_inicio + t\n    \n    # Tendência temporal comum (crescimento econômico)\n    tendencia_temporal <- 5 * t\n    \n    # Efeito da desoneração (apenas após 2012 para setores desonerados)\n    efeito_desoneracao <- ifelse(desonerado == 1 & ano >= ano_desoneracao, 25, 0)\n    \n    # Ruído aleatório\n    erro <- rnorm(1, mean = 0, sd = 5)\n    \n    # Número de trabalhadores\n    n_trabalhadores <- efeito_fixo + tendencia_temporal + efeito_desoneracao + erro\n    \n    # Criar variável post\n    post <- ifelse(ano >= ano_desoneracao, 1, 0)\n    \n    # Criar variável de interação\n    desoneracao <- desonerado * post\n    \n    # Adicionar linha ao data frame\n    dados <- rbind(dados, data.frame(\n      empresa_id = i,\n      ano = ano,\n      tempo = t,\n      desonerado = desonerado,\n      post = post,\n      desoneracao = desoneracao,\n      n_trabalhadores = n_trabalhadores\n    ))\n  }\n}\n\n###Regressão OLS\n\n# Estimar modelo: Y = β0 + β1*Desonerado + β2*Post + β3*(Desonerado×Post) + ε\nmodelo <- lm(n_trabalhadores ~ desonerado + post + desoneracao, data = dados)\n\n\nInterpretação dos Coeficientes\n\n# Extrair coeficientes\nbeta_0 <- coef(modelo)[\"(Intercept)\"]\nbeta_1 <- coef(modelo)[\"desonerado\"]\nbeta_2 <- coef(modelo)[\"post\"]\nbeta_3 <- coef(modelo)[\"desoneracao\"]\n\ncat(\"\\n=== INTERPRETAÇÃO DOS COEFICIENTES ===\\n\\n\")\n\n\n=== INTERPRETAÇÃO DOS COEFICIENTES ===\n\ncat(sprintf(\"β₀ (Intercepto):         %.4f\\n\", beta_0))\n\nβ₀ (Intercepto):         110.1420\n\ncat(\"   → Emprego médio nos setores não desonerados antes de 2012\\n\\n\")\n\n   → Emprego médio nos setores não desonerados antes de 2012\n\ncat(sprintf(\"β₁ (Desonerado):         %.4f\\n\", beta_1))\n\nβ₁ (Desonerado):         31.5908\n\ncat(\"   → Diferença fixa entre setores (efeito fixo de grupo)\\n\\n\")\n\n   → Diferença fixa entre setores (efeito fixo de grupo)\n\ncat(sprintf(\"β₂ (Post):               %.4f\\n\", beta_2))\n\nβ₂ (Post):               22.1818\n\ncat(\"   → Tendência temporal comum (crescimento econômico)\\n\\n\")\n\n   → Tendência temporal comum (crescimento econômico)\n\ncat(sprintf(\"β₃ (Desonerado × Post):  %.4f ***\\n\", beta_3))\n\nβ₃ (Desonerado × Post):  25.2538 ***\n\ncat(\"   → EFEITO CAUSAL DA DESONERAÇÃO (DiD/ATT)\\n\")\n\n   → EFEITO CAUSAL DA DESONERAÇÃO (DiD/ATT)\n\n\n\n\nVisualização: Tendências Paralelas\n\n# Calcular médias por ano e grupo\nmedias_ano <- aggregate(n_trabalhadores ~ ano + desonerado, data = dados, FUN = mean)\n\n# Criar gráfico\npar(mar = c(5, 5, 4, 2))\n\n# Plotar setores não desonerados\nplot(medias_ano$ano[medias_ano$desonerado == 0], \n     medias_ano$n_trabalhadores[medias_ano$desonerado == 0],\n     type = \"b\", pch = 15, col = \"#e74c3c\", lwd = 3, cex = 1.5,\n     xlab = \"Ano\", ylab = \"Número de Trabalhadores\",\n     main = \"Impacto da Desoneração da Folha no Emprego\\nTendências Paralelas\",\n     ylim = range(medias_ano$n_trabalhadores),\n     cex.lab = 1.3, cex.main = 1.4, cex.axis = 1.2)\n\n# Adicionar setores desonerados\nlines(medias_ano$ano[medias_ano$desonerado == 1], \n      medias_ano$n_trabalhadores[medias_ano$desonerado == 1],\n      type = \"b\", pch = 16, col = \"#27ae60\", lwd = 3, cex = 1.5)\n\n# Linha vertical no ano da desoneração\nabline(v = ano_desoneracao - 0.5, col = \"gray\", lty = 2, lwd = 2.5)\n\n# Legenda\nlegend(\"topleft\", \n       legend = c(\"Setores Desonerados\", \"Setores Não Desonerados\"),\n       col = c(\"#27ae60\", \"#e74c3c\"), \n       pch = c(16, 15), \n       lwd = 3, \n       cex = 1.2,\n       bty = \"n\")\n\n# Anotação\ntext(ano_desoneracao - 0.5, max(medias_ano$n_trabalhadores) * 0.95, \n     \"Lei 12.546/2011\\nDesoneração (2012)\", \n     pos = 4, cex = 1.1, font = 2)\n\n# Grid\ngrid(col = \"gray\", lty = \"dotted\")\n\n\n\n\nTendências paralelas em dados simulados da desoneração da folha. As trajetórias são similares antes de 2012 e divergem após a implementação da política.\n\n\n\n\n\n\nResultados\nO gráfico acima visualiza as tendências paralelas. Note como:\n\nAntes de 2012: As linhas dos dois grupos são aproximadamente paralelas, validando visualmente nossa hipótese identificadora\nApós 2012: A linha dos setores desonerados se afasta para cima, capturando o efeito positivo da política\nMagnitude: O gap vertical entre as linhas após 2012 representa o efeito DiD de aproximadamente +25 trabalhadores\n\nTabela Resumo dos Resultados:\n\n\n\nMétodo\nEstimativa\nErro Padrão\nEstatística t\np-valor\n\n\n\n\nDiD Manual\n+25.25\n-\n-\n-\n\n\nRegressão OLS (β₃)\n+25.25\n1.69\n14.96\n< 0.001\n\n\n\nConclusão: A desoneração da folha aumentou o emprego em aproximadamente 25 trabalhadores nas empresas beneficiadas, controlando por tendências temporais comuns e diferenças fixas entre setores. O efeito é altamente significativo estatisticamente."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#event-studies-testando-tendências-paralelas-e-efeitos-dinâmicos",
    "href": "posts/Diferenças-em-diferenças/index.html#event-studies-testando-tendências-paralelas-e-efeitos-dinâmicos",
    "title": "DID",
    "section": "Event Studies: Testando Tendências Paralelas e Efeitos Dinâmicos",
    "text": "Event Studies: Testando Tendências Paralelas e Efeitos Dinâmicos\n\nDa Estimativa Única aos Efeitos Dinâmicos\nAté agora, estimamos um único efeito médio da desoneração: +25 trabalhadores. Mas essa abordagem esconde informações importantes:\n\nO efeito foi imediato ou gradual?\nO efeito cresceu ou diminuiu ao longo do tempo?\nMais importante: as tendências eram realmente paralelas antes de 2012?\n\nO Event Study (ou estudo de eventos) responde a essas perguntas estimando um efeito separado para cada ano relativo ao tratamento.\n\n\nA Especificação de Regressão do Event Study\nEm vez de uma única dummy Post, criamos dummies para cada ano relativo ao tratamento:\n\\[Y_{it} = \\alpha_i + \\lambda_t + \\sum_{k \\neq -1} \\beta_k \\cdot \\mathbb{1}\\{\\text{Tempo Relativo}_{it} = k\\} \\cdot D_i + \\varepsilon_{it}\\]\nOnde: - \\(\\text{Tempo Relativo}_{it} = t - 2012\\) (anos relativos à desoneração) - \\(k \\in \\{-5, -4, -3, -2, -1, 0, 1, 2, 3\\}\\) são os anos relativos - \\(\\beta_k\\) são os coeficientes de interesse (efeito no ano \\(k\\)) - Normalização: Omitimos \\(k = -1\\) como período de referência\n\n\nInterpretação dos Parâmetros Temporais\nCoeficientes Pré-Tratamento (\\(\\beta_k\\) para \\(k < 0\\)):\n\nCapturam diferenças nas tendências antes da política\nDevem ser ≈ 0 se as tendências forem paralelas\nSe \\(\\beta_k \\neq 0\\): evidência de violação de tendências paralelas\n\nCoeficientes Pós-Tratamento (\\(\\beta_k\\) para \\(k \\geq 0\\)):\n\nCapturam o efeito causal dinâmico da desoneração\n\\(\\beta_0\\): efeito imediato (2012)\n\\(\\beta_1, \\beta_2, \\beta_3\\): efeitos subsequentes\n\n\n\nPor que Event Studies Testam Tendências Paralelas?\nA hipótese de tendências paralelas não pode ser testada diretamente (o contrafactual é inobservável). Mas podemos fazer um teste indireto:\n\nSe as tendências eram paralelas antes, é plausível que continuariam paralelas na ausência do tratamento\nSe as tendências divergiam antes, não há razão para acreditar que convergiriam após 2012\nEvent study revela essas tendências através dos coeficientes pré-tratamento\n\nTeste Visual: Plotar \\(\\beta_k\\) com intervalos de confiança e verificar se \\(\\beta_k \\approx 0\\) para \\(k < 0\\).\n\n\nImplementação com Dados Simulados\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(fixest)\n# Criar variável de tempo relativo\ndados <- dados %>%\n  mutate(tempo_relativo = ano - ano_desoneracao)\n\n\nmodelo_event <- feols(\n  n_trabalhadores ~ i(tempo_relativo, desonerado, ref = -1) | \n                    empresa_id + ano,\n  data = dados,\n  cluster = ~empresa_id  # Erros padrão clusterizados\n)\n\n# Extrair resultados\nresultados_event <- broom::tidy(modelo_event, conf.int = TRUE)\n\n# Ou visualizar diretamente\niplot(modelo_event ,\n      main = \"Event Study: Desoneração da Folha\",\n      xlab = \"Tempo Relativo\",\n      ylab = \"Efeito no Emprego\")\n\n\n\n\n\n\nO que o Gráfico Revela?\n\n\n\n\n\n\n\n\nCoeficiente\nNotação\nInterpretação\n\n\n\n\nβ₋₅\ntempo_relativo = -5\nDiferença no emprego entre setores desonerados e não desonerados 5 anos antes da política (2007 vs 2007), controlando por FEs de empresa e tempo.\n\n\nβ₋₄\ntempo_relativo = -4\nDiferença no emprego entre setores desonerados e não desonerados 4 anos antes da política (2008 vs 2008), controlando por FEs.\n\n\nβ₋₃\ntempo_relativo = -3\nDiferença no emprego entre setores desonerados e não desonerados 3 anos antes da política (2009 vs 2009), controlando por FEs.\n\n\nβ₋₂\ntempo_relativo = -2\nDiferença no emprego entre setores desonerados e não desonerados 2 anos antes da política (2010 vs 2010), controlando por FEs.\n\n\nβ₋₁\ntempo_relativo = -1\nPERÍODO DE REFERÊNCIA (omitido)Normalizado em zero por construção (2011).\n\n\nβ₀\ntempo_relativo = 0\nEfeito causal imediato da desoneração no ano de implementação (2012).Mudança no emprego dos setores desonerados relativa aos não desonerados, comparado com 2011.\n\n\nβ₁\ntempo_relativo = 1\nEfeito causal 1 ano após a desoneração (2013).Acúmulo do efeito da política após 1 ano.\n\n\nβ₂\ntempo_relativo = 2\nEfeito causal 2 anos após a desoneração (2014).Acúmulo do efeito da política após 2 anos.\n\n\nβ₃\ntempo_relativo = 3\nEfeito causal 3 anos após a desoneração (2015).Efeito de longo prazo da política.\n\n\n\n\n\nNotas Importantes\nInterpretação Formal dos Coeficientes:\nPara qualquer tempo relativo k, o coeficiente β_k representa:\n\\[\n\\beta_k = E[Y_{it} | \\text{Desonerado}_i = 1, \\text{TempoRelativo}_{it} = k] - E[Y_{it} | \\text{Desonerado}_i = 0, \\text{TempoRelativo}_{it} = k]\n\\]\nControlando por efeitos fixos de empresa (α_i) e efeitos fixos de tempo (λ_t).\nEm palavras simples: > β_k mede a diferença no número de trabalhadores entre setores desonerados e não desonerados no período k relativo à desoneração, comparado com a diferença no período de referência (k = -1).\nCondições para Identificação Causal:\n\nTendências Paralelas (Pré-Tratamento):\n\nβ₋₅, β₋₄, β₋₃, β₋₂ devem ser estatisticamente indistinguíveis de zero\nSe todos ≈ 0: forte evidência de que setores desonerados e não desonerados teriam evoluído de forma paralela na ausência da política\n\nAusência de Antecipação:\n\nCoeficientes pré-tratamento não devem mostrar “salto” antes de 2012\nEmpresas não devem ter ajustado emprego em antecipação à política\n\nEfeito Causal (Pós-Tratamento):\n\nβ₀, β₁, β₂, β₃ > 0: a desoneração aumentou o emprego\nSe β₀ < β₁ < β₂: efeito crescente (ajuste gradual)\nSe β₀ ≈ β₁ ≈ β₂: efeito imediato e constante"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#did-22-vs.-two-way-fixed-effects-twfe",
    "href": "posts/Diferenças-em-diferenças/index.html#did-22-vs.-two-way-fixed-effects-twfe",
    "title": "DID",
    "section": "DiD 2×2 vs. Two-Way Fixed Effects (TWFE)",
    "text": "DiD 2×2 vs. Two-Way Fixed Effects (TWFE)\n\nDa Regressão Simples aos Efeitos Fixos\nAté agora, estimamos o DiD usando uma especificação simples com dummies de grupo e período. Mas e se quisermos controlar características específicas de cada empresa e choques temporais não-lineares? É aqui que entra o Two-Way Fixed Effects (TWFE).\nNesta seção, vamos comparar as duas abordagens usando valores esperados para entender exatamente o que cada parâmetro significa.\n\n\nModelo 1: DiD 2×2 (Especificação Simples)\nA especificação tradicional do DiD é:\n\\[Y_{it} = \\beta_0 + \\beta_1 \\cdot Desonerado_i + \\beta_2 \\cdot Post_t + \\beta_3 \\cdot (Desonerado_i \\times Post_t) + \\varepsilon_{it}\\]\n\nValores Esperados por Grupo-Período\nPodemos expressar o valor esperado de \\(Y_{it}\\) para cada combinação de grupo e período:\n\n\n\nGrupo\nPeríodo\n\\(E[Y_{it}]\\)\nComponentes\n\n\n\n\nControle\nPré\n\\(\\beta_0\\)\nIntercepto\n\n\nControle\nPós\n\\(\\beta_0 + \\beta_2\\)\nIntercepto + Tendência\n\n\nTratado\nPré\n\\(\\beta_0 + \\beta_1\\)\nIntercepto + Efeito de grupo\n\n\nTratado\nPós\n\\(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3\\)\nTudo\n\n\n\n\n\nInterpretação dos Parâmetros\n\\(\\beta_0\\): Nível médio de emprego nos controles no período pré-tratamento\n\\[\\beta_0 = E[Y_{it} | Desonerado=0, Post=0]\\]\n\\(\\beta_1\\): Diferença de nível entre tratados e controles no período pré\n\\[\\beta_1 = E[Y_{it} | Desonerado=1, Post=0] - E[Y_{it} | Desonerado=0, Post=0]\\]\nImportante: \\(\\beta_1\\) NÃO é efeito causal! É apenas a diferença estrutural entre os grupos.\n\\(\\beta_2\\): Mudança temporal nos controles (tendência comum)\n\\[\\beta_2 = E[Y_{it} | Desonerado=0, Post=1] - E[Y_{it} | Desonerado=0, Post=0]\\]\n\\(\\beta_3\\): Efeito causal da desoneração (DiD)\n\\[\\beta_3 = [E[Y | D=1, Post=1] - E[Y | D=1, Post=0]] - [E[Y | D=0, Post=1] - E[Y | D=0, Post=0]]\\]\n\n\n\nModelo 2: TWFE (Two-Way Fixed Effects)\nA especificação TWFE é:\n\\[Y_{it} = \\alpha_i + \\lambda_t + \\beta \\cdot Desoneracao_{it} + \\varepsilon_{it}\\]\nOnde: - \\(\\alpha_i\\) = efeito fixo da empresa \\(i\\) (um parâmetro para cada empresa) - \\(\\lambda_t\\) = efeito fixo do ano \\(t\\) (um parâmetro para cada ano) - \\(Desoneracao_{it} = Desonerado_i \\times Post_t\\)\n\nValores Esperados por Empresa-Período\n\n\n\n\n\n\n\n\n\nGrupo\nPeríodo\n\\(E[Y_{it}]\\)\nComponentes\n\n\n\n\nControle (empresa i)\nPré (ano t)\n\\(\\alpha_i + \\lambda_t\\)\nFE empresa + FE ano\n\n\nControle (empresa i)\nPós (ano t’)\n\\(\\alpha_i + \\lambda_{t'}\\)\nFE empresa + FE ano\n\n\nTratado (empresa j)\nPré (ano t)\n\\(\\alpha_j + \\lambda_t\\)\nFE empresa + FE ano\n\n\nTratado (empresa j)\nPós (ano t’)\n\\(\\alpha_j + \\lambda_{t'} + \\beta\\)\nFE empresa + FE ano + Tratamento\n\n\n\n\n\nInterpretação dos Parâmetros\n\\(\\alpha_i\\): Nível médio de emprego da empresa \\(i\\) (removendo variação temporal)\n\\[\\alpha_i = E[Y_{it} | empresa=i] - E[\\lambda_t]\\]\nCada empresa tem seu próprio \\(\\alpha_i\\)! Isso controla heterogeneidade dentro dos grupos.\n\\(\\lambda_t\\): Choque temporal comum no ano \\(t\\) (removendo variação entre empresas)\n\\[\\lambda_t = E[Y_{it} | ano=t] - E[\\alpha_i]\\]\nCada ano tem seu próprio \\(\\lambda_t\\)! Isso controla choques temporais não-lineares.\n\\(\\beta\\): Efeito causal da desoneração (DiD com efeitos fixos)\n\\[\\beta = [E[Y_{jt'} | Tratado, Pós] - E[Y_{jt} | Tratado, Pré]] - [E[Y_{it'} | Controle, Pós] - E[Y_{it} | Controle, Pré]]\\]\n\n\n\nComparação com Dados Simulados\n\nlibrary(tidyverse)\nlibrary(broom)\n\n# Usar os mesmos dados simulados anteriormente\n# (assumindo que 'dados' já existe no ambiente)\n\n\nEstimar DiD 2×2\n\n# Estimar DiD 2×2 tradicional\nmodelo_did <- lm(\n  n_trabalhadores ~ desonerado + post + desoneracao,\n  data = dados\n)\n\n# Extrair coeficientes\ncoef_did <- tidy(modelo_did) %>%\n  select(term, estimate, std.error, p.value)\n\ncoef_did\n\n# A tibble: 4 × 4\n  term        estimate std.error   p.value\n  <chr>          <dbl>     <dbl>     <dbl>\n1 (Intercept)    110.      0.796 0        \n2 desonerado      31.6     1.13  6.27e-125\n3 post            22.2     1.19  1.81e- 65\n4 desoneracao     25.3     1.69  2.40e- 45\n\n\n\n\nEstimar TWFE\n\n# Estimar TWFE com efeitos fixos de empresa e ano\nmodelo_twfe <- lm(\n  n_trabalhadores ~ desoneracao + factor(empresa_id) + factor(ano) - 1,\n  data = dados\n)\n\n# Extrair apenas o coeficiente de interesse\ncoef_twfe <- tidy(modelo_twfe) %>%\n  filter(term == \"desoneracao\") %>%\n  select(term, estimate, std.error, p.value)\n\ncoef_twfe\n\n# A tibble: 1 × 4\n  term        estimate std.error   p.value\n  <chr>          <dbl>     <dbl>     <dbl>\n1 desoneracao     25.3     0.681 3.43e-175\n\n\n\n\nComparar Estimativas\n\n# Comparar os efeitos causais\ntibble(\n  Modelo = c(\"DiD 2×2\", \"TWFE\"),\n  `Efeito Causal` = c(\n    coef(modelo_did)[\"desoneracao\"],\n    coef(modelo_twfe)[\"desoneracao\"]\n  ),\n  `Erro Padrão` = c(\n    summary(modelo_did)$coefficients[\"desoneracao\", \"Std. Error\"],\n    summary(modelo_twfe)$coefficients[\"desoneracao\", \"Std. Error\"]\n  )\n) %>%\n  mutate(across(where(is.numeric), ~round(., 2)))\n\n# A tibble: 2 × 3\n  Modelo  `Efeito Causal` `Erro Padrão`\n  <chr>             <dbl>         <dbl>\n1 DiD 2×2            25.2          1.69\n2 TWFE               25.2          0.68\n\n\n\n\n\nReconstruir Valores Esperados\nVamos verificar que os valores esperados correspondem às fórmulas teóricas.\n\nValores Esperados do DiD 2×2\n\n# Extrair coeficientes\nb0 <- coef(modelo_did)[\"(Intercept)\"]\nb1 <- coef(modelo_did)[\"desonerado\"]\nb2 <- coef(modelo_did)[\"post\"]\nb3 <- coef(modelo_did)[\"desoneracao\"]\n\n# Calcular valores esperados\nvalores_did <- tibble(\n  Grupo = c(\"Controle\", \"Controle\", \"Tratado\", \"Tratado\"),\n  Período = c(\"Pré\", \"Pós\", \"Pré\", \"Pós\"),\n  `E[Y] (fórmula)` = c(\n    b0,\n    b0 + b2,\n    b0 + b1,\n    b0 + b1 + b2 + b3\n  )\n)\n\n# Calcular médias observadas\nvalores_observados <- dados %>%\n  group_by(desonerado, post) %>%\n  summarise(`E[Y] (dados)` = mean(n_trabalhadores), .groups = \"drop\") %>%\n  arrange(desonerado, post) %>%\n  pull(`E[Y] (dados)`)\n\nvalores_did <- valores_did %>%\n  mutate(`E[Y] (dados)` = valores_observados,\n         Diferença = `E[Y] (fórmula)` - `E[Y] (dados)`)\n\nvalores_did %>%\n  mutate(across(where(is.numeric), ~round(., 2)))\n\n# A tibble: 4 × 5\n  Grupo    Período `E[Y] (fórmula)` `E[Y] (dados)` Diferença\n  <chr>    <chr>              <dbl>          <dbl>     <dbl>\n1 Controle Pré                 110.           110.         0\n2 Controle Pós                 132.           132.         0\n3 Tratado  Pré                 142.           142.         0\n4 Tratado  Pós                 189.           189.         0\n\n\nInterpretação: As diferenças devem ser próximas de zero, confirmando que os coeficientes recuperam os valores esperados!\n\n\nValores Esperados do TWFE (Exemplo)\n\n# Selecionar duas empresas exemplo (uma tratada, uma controle)\nempresa_tratada <- dados %>% filter(desonerado == 1) %>% pull(empresa_id) %>% first()\nempresa_controle <- dados %>% filter(desonerado == 0) %>% pull(empresa_id) %>% first()\n\n# Extrair efeitos fixos\nalpha_tratada <- coef(modelo_twfe)[paste0(\"factor(empresa_id)\", empresa_tratada)]\nalpha_controle <- coef(modelo_twfe)[paste0(\"factor(empresa_id)\", empresa_controle)]\nlambda_2011 <- coef(modelo_twfe)[\"factor(ano)2011\"]\nlambda_2012 <- coef(modelo_twfe)[\"factor(ano)2012\"]\nbeta_twfe <- coef(modelo_twfe)[\"desoneracao\"]\n\n# Calcular valores esperados\nvalores_twfe <- tibble(\n  Empresa = c(\n    paste(\"Controle\", empresa_controle),\n    paste(\"Controle\", empresa_controle),\n    paste(\"Tratada\", empresa_tratada),\n    paste(\"Tratada\", empresa_tratada)\n  ),\n  Período = c(\"2011\", \"2012\", \"2011\", \"2012\"),\n  `E[Y] (fórmula)` = c(\n    alpha_controle + lambda_2011,\n    alpha_controle + lambda_2012,\n    alpha_tratada + lambda_2011,\n    alpha_tratada + lambda_2012 + beta_twfe\n  )\n)\n\n# Valores observados\nvalores_twfe <- valores_twfe %>%\n  left_join(\n    dados %>% \n      filter(empresa_id %in% c(empresa_tratada, empresa_controle),\n             ano %in% c(2011, 2012)) %>%\n      mutate(Empresa = paste(ifelse(desonerado == 1, \"Tratada\", \"Controle\"), empresa_id),\n             Período = as.character(ano)) %>%\n      select(Empresa, Período, `E[Y] (dados)` = n_trabalhadores),\n    by = c(\"Empresa\", \"Período\")\n  ) %>%\n  mutate(Diferença = `E[Y] (fórmula)` - `E[Y] (dados)`)\n\nvalores_twfe %>%\n  mutate(across(where(is.numeric), ~round(., 2)))\n\n# A tibble: 4 × 5\n  Empresa     Período `E[Y] (fórmula)` `E[Y] (dados)` Diferença\n  <chr>       <chr>              <dbl>          <dbl>     <dbl>\n1 Controle 51 2011                129.           129.     -0.08\n2 Controle 51 2012                134.           130.      3.69\n3 Tratada 1   2011                166.           163.      2.87\n4 Tratada 1   2012                196.           201.     -5.35\n\n\n\n\n\nQuando DiD 2×2 = TWFE?\nOs dois modelos produzem o mesmo efeito causal quando:\n\nNão há heterogeneidade dentro dos grupos: Todas as empresas tratadas têm o mesmo nível médio, assim como todas as controles.\nTendências temporais são lineares: O crescimento ao longo do tempo é constante.\n\nMatematicamente, se: - \\(\\alpha_i = \\beta_0 + \\beta_1 \\cdot Desonerado_i\\) - \\(\\lambda_t = \\beta_2 \\cdot Post_t\\)\nEntão \\(\\beta = \\beta_3\\).\n\nTeste Visual: Heterogeneidade\n\n# Visualizar heterogeneidade dentro dos grupos\ndados %>%\n  filter(ano %in% c(2011, 2012)) %>%\n  mutate(\n    Grupo = ifelse(desonerado == 1, \"Desonerados\", \"Não Desonerados\"),\n    Período = ifelse(ano == 2011, \"Pré (2011)\", \"Pós (2012)\")\n  ) %>%\n  ggplot(aes(x = Período, y = n_trabalhadores, group = empresa_id)) +\n  geom_line(alpha = 0.3, color = \"gray50\") +\n  geom_point(alpha = 0.5, size = 2) +\n  stat_summary(aes(group = 1), fun = mean, geom = \"line\", \n               color = \"red\", linewidth = 1.5) +\n  stat_summary(aes(group = 1), fun = mean, geom = \"point\", \n               color = \"red\", size = 4) +\n  facet_wrap(~Grupo) +\n  labs(\n    title = \"Heterogeneidade Dentro dos Grupos\",\n    subtitle = \"Linhas cinzas = empresas individuais; Linha vermelha = média do grupo\",\n    x = NULL,\n    y = \"Número de Trabalhadores\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    strip.text = element_text(face = \"bold\", size = 12)\n  )\n\n\n\n\nInterpretação: Se as linhas cinzas estão muito dispersas, há heterogeneidade significativa. TWFE controla isso, DiD 2×2 não.\n\n\n\nResumo Comparativo\n\ntibble(\n  Aspecto = c(\n    \"Efeitos fixos de empresa\",\n    \"Efeitos fixos de ano\",\n    \"Controla heterogeneidade\",\n    \"Controla choques não-lineares\",\n    \"Número de parâmetros\",\n    \"Interpretação\",\n    \"Eficiência\"\n  ),\n  `DiD 2×2` = c(\n    \"Não (apenas β₁ para grupo)\",\n    \"Não (apenas β₂ linear)\",\n    \"Não\",\n    \"Não\",\n    \"4\",\n    \"Simples\",\n    \"Alta (se especificação correta)\"\n  ),\n  TWFE = c(\n    \"Sim (αᵢ para cada empresa)\",\n    \"Sim (λₜ para cada ano)\",\n    \"Sim\",\n    \"Sim\",\n    paste0(\"4 + N + T - 2 = \", 4 + n_distinct(dados$empresa_id) + n_distinct(dados$ano) - 2),\n    \"Complexa\",\n    \"Menor (mais parâmetros)\"\n  )\n)\n\n# A tibble: 7 × 3\n  Aspecto                       `DiD 2×2`                       TWFE            \n  <chr>                         <chr>                           <chr>           \n1 Efeitos fixos de empresa      Não (apenas β₁ para grupo)      Sim (αᵢ para ca…\n2 Efeitos fixos de ano          Não (apenas β₂ linear)          Sim (λₜ para ca…\n3 Controla heterogeneidade      Não                             Sim             \n4 Controla choques não-lineares Não                             Sim             \n5 Número de parâmetros          4                               4 + N + T - 2 =…\n6 Interpretação                 Simples                         Complexa        \n7 Eficiência                    Alta (se especificação correta) Menor (mais par…\n\n\n\n\nQuando Usar Cada Modelo?\nUse DiD 2×2 quando: - ✓ Grupos são homogêneos internamente - ✓ Tendências temporais são aproximadamente lineares - ✓ Você quer interpretação simples - ✓ Amostra é pequena (eficiência importa)\nUse TWFE quando: - ✓ Há heterogeneidade significativa dentro dos grupos - ✓ Choques temporais são não-lineares - ✓ Você quer ser conservador/robusto - ✓ Amostra é grande (muitos parâmetros não são problema)\n\n\nConclusão\nAmbos os modelos estimam o mesmo efeito causal sob as condições certas. A escolha entre eles depende de:\n\nEstrutura dos dados: Há heterogeneidade? Tendências são lineares?\nObjetivo: Simplicidade vs. robustez?\nTamanho da amostra: Eficiência importa?\n\nNa prática, é comum estimar ambos e verificar que os resultados são similares, o que fortalece a credibilidade das estimativas."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#two-way-fixed-effects-twfe",
    "href": "posts/Diferenças-em-diferenças/index.html#two-way-fixed-effects-twfe",
    "title": "DID",
    "section": "Two-Way Fixed Effects (TWFE)",
    "text": "Two-Way Fixed Effects (TWFE)\nAté agora, trabalhamos com o caso mais simples do DiD: dois grupos (tratado e controle) e dois períodos (antes e depois). Mas o que acontece quando temos múltiplos grupos tratados em diferentes momentos? Por exemplo, se alguns setores foram desonerados em 2012, outros em 2013, e outros nunca foram desonerados?\nNesse cenário mais realista, é comum usar o estimador Two-Way Fixed Effects (TWFE), que é simplesmente uma regressão com efeitos fixos de unidade e tempo:\n\\[\nY_{it} = \\alpha_i + \\lambda_t + \\beta \\cdot D_{it} + \\varepsilon_{it}\n\\]\nOnde \\(\\alpha_i\\) são efeitos fixos de unidade, \\(\\lambda_t\\) são efeitos fixos de tempo, e \\(D_{it}\\) é o indicador de tratamento.\nA grande questão: O que exatamente o coeficiente \\(\\beta\\) do TWFE está estimando quando há heterogeneidade no timing do tratamento?\nGoodman-Bacon (2021) provou um resultado matemático elegante e surpreendente:\n\nO estimador TWFE é uma média ponderada de todos os possíveis estimadores DD 2×2 que podem ser construídos com os dados.\n\nFormalmente:\n\\[\n\\hat{\\beta}^{DD} = \\sum_{k\\neq U} s_{kU} \\hat{\\beta}_{kU}^{2\\times2} + \\sum_{k\\neq U} \\sum_{\\ell > k} \\left[ s_{k\\ell}^k \\hat{\\beta}_{k\\ell}^{2\\times2,k} + s_{k\\ell}^\\ell \\hat{\\beta}_{k\\ell}^{2\\times2,\\ell} \\right]\n\\]\nOnde:\n\n\\(\\hat{\\beta}_{kU}^{2\\times2}\\): comparação entre grupo tratado (\\(k\\)) vs. nunca tratado (\\(U\\))\n\\(\\hat{\\beta}_{k\\ell}^{2\\times2,k}\\): comparação usando grupo \\(k\\) (tratado precocemente) como tratamento e grupo \\(\\ell\\) (tratado tardiamente) como controle\n\\(\\hat{\\beta}_{k\\ell}^{2\\times2,\\ell}\\): comparação usando grupo \\(\\ell\\) (tratado tardiamente) como tratamento e grupo \\(k\\) (já tratado) como controle\n\\(s_{kU}, s_{k\\ell}^k, s_{k\\ell}^\\ell\\): pesos que somam 1\n\nInterpretação: A decomposição tem três tipos de comparações:\n\nTratados vs. Nunca tratados (\\(\\hat{\\beta}_{kU}\\)): Cada grupo tratado comparado com o grupo nunca tratado\nTratados precoces vs. Tratados tardios (\\(\\hat{\\beta}_{k\\ell}^{k}\\)): Grupos tratados precocemente usando grupos ainda não tratados como controles\nTratados tardios vs. Tratados precoces (\\(\\hat{\\beta}_{k\\ell}^{\\ell}\\)): Grupos tratados tardiamente usando grupos já tratados como controles"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#aplicação-prática-com-dados-simulados",
    "href": "posts/Diferenças-em-diferenças/index.html#aplicação-prática-com-dados-simulados",
    "title": "DID",
    "section": "Aplicação Prática com Dados Simulados",
    "text": "Aplicação Prática com Dados Simulados\nPara tornar os conceitos mais concretos, vamos simular dados de painel com 100 empresas (50 em setores desonerados, 50 em setores controle) ao longo de 9 anos (2007-2015). A desoneração é implementada em 2012 e tem um efeito verdadeiro de +25 trabalhadores.\n\n# Configurar seed para reprodutibilidade\nset.seed(42)\n\n# Parâmetros da simulação\nn_empresas <- 100\nn_anos <- 9  # 2007-2015\nano_inicio <- 2007\nano_desoneracao <- 2012\n\n# Metade das empresas em setores desonerados\nn_desonerado <- n_empresas / 2\n\n# Criar data frame vazio\ndados <- data.frame()\n\nfor (i in 1:n_empresas) {\n  # Determinar se empresa está em setor desonerado\n  desonerado <- ifelse(i <= n_desonerado, 1, 0)\n  \n  # Efeito fixo da empresa\n  # Setores desonerados têm baseline maior (mais intensivos em mão de obra)\n  efeito_fixo <- 100 + (30 * desonerado) + rnorm(1, mean = 0, sd = 10)\n  \n  for (t in 0:(n_anos - 1)) {\n    ano <- ano_inicio + t\n    \n    # Tendência temporal comum (crescimento econômico)\n    tendencia_temporal <- 5 * t\n    \n    # Efeito da desoneração (apenas após 2012 para setores desonerados)\n    efeito_desoneracao <- ifelse(desonerado == 1 & ano >= ano_desoneracao, 25, 0)\n    \n    # Ruído aleatório\n    erro <- rnorm(1, mean = 0, sd = 5)\n    \n    # Número de trabalhadores\n    n_trabalhadores <- efeito_fixo + tendencia_temporal + efeito_desoneracao + erro\n    \n    # Criar variável post\n    post <- ifelse(ano >= ano_desoneracao, 1, 0)\n    \n    # Criar variável de interação\n    desoneracao <- desonerado * post\n    \n    # Adicionar linha ao data frame\n    dados <- rbind(dados, data.frame(\n      empresa_id = i,\n      ano = ano,\n      tempo = t,\n      desonerado = desonerado,\n      post = post,\n      desoneracao = desoneracao,\n      n_trabalhadores = n_trabalhadores\n    ))\n  }\n}\n\n###Regressão OLS\n\n# Estimar modelo: Y = β0 + β1*Desonerado + β2*Post + β3*(Desonerado×Post) + ε\nmodelo <- lm(n_trabalhadores ~ desonerado + post + desoneracao, data = dados)\n\n\nInterpretação dos Coeficientes\n\n# Extrair coeficientes\nbeta_0 <- coef(modelo)[\"(Intercept)\"]\nbeta_1 <- coef(modelo)[\"desonerado\"]\nbeta_2 <- coef(modelo)[\"post\"]\nbeta_3 <- coef(modelo)[\"desoneracao\"]\n\ncat(\"\\n=== INTERPRETAÇÃO DOS COEFICIENTES ===\\n\\n\")\n\n\n=== INTERPRETAÇÃO DOS COEFICIENTES ===\n\ncat(sprintf(\"β₀ (Intercepto):         %.4f\\n\", beta_0))\n\nβ₀ (Intercepto):         110.1420\n\ncat(\"   → Emprego médio nos setores não desonerados antes de 2012\\n\\n\")\n\n   → Emprego médio nos setores não desonerados antes de 2012\n\ncat(sprintf(\"β₁ (Desonerado):         %.4f\\n\", beta_1))\n\nβ₁ (Desonerado):         31.5908\n\ncat(\"   → Diferença fixa entre setores (efeito fixo de grupo)\\n\\n\")\n\n   → Diferença fixa entre setores (efeito fixo de grupo)\n\ncat(sprintf(\"β₂ (Post):               %.4f\\n\", beta_2))\n\nβ₂ (Post):               22.1818\n\ncat(\"   → Tendência temporal comum (crescimento econômico)\\n\\n\")\n\n   → Tendência temporal comum (crescimento econômico)\n\ncat(sprintf(\"β₃ (Desonerado × Post):  %.4f ***\\n\", beta_3))\n\nβ₃ (Desonerado × Post):  25.2538 ***\n\ncat(\"   → EFEITO CAUSAL DA DESONERAÇÃO (DiD/ATT)\\n\")\n\n   → EFEITO CAUSAL DA DESONERAÇÃO (DiD/ATT)\n\n\n\n\nVisualização: Tendências Paralelas\n\n# Calcular médias por ano e grupo\nmedias_ano <- aggregate(n_trabalhadores ~ ano + desonerado, data = dados, FUN = mean)\n\n# Criar gráfico\npar(mar = c(5, 5, 4, 2))\n\n# Plotar setores não desonerados\nplot(medias_ano$ano[medias_ano$desonerado == 0], \n     medias_ano$n_trabalhadores[medias_ano$desonerado == 0],\n     type = \"b\", pch = 15, col = \"#e74c3c\", lwd = 3, cex = 1.5,\n     xlab = \"Ano\", ylab = \"Número de Trabalhadores\",\n     main = \"Impacto da Desoneração da Folha no Emprego\\nTendências Paralelas\",\n     ylim = range(medias_ano$n_trabalhadores),\n     cex.lab = 1.3, cex.main = 1.4, cex.axis = 1.2)\n\n# Adicionar setores desonerados\nlines(medias_ano$ano[medias_ano$desonerado == 1], \n      medias_ano$n_trabalhadores[medias_ano$desonerado == 1],\n      type = \"b\", pch = 16, col = \"#27ae60\", lwd = 3, cex = 1.5)\n\n# Linha vertical no ano da desoneração\nabline(v = ano_desoneracao - 0.5, col = \"gray\", lty = 2, lwd = 2.5)\n\n# Legenda\nlegend(\"topleft\", \n       legend = c(\"Setores Desonerados\", \"Setores Não Desonerados\"),\n       col = c(\"#27ae60\", \"#e74c3c\"), \n       pch = c(16, 15), \n       lwd = 3, \n       cex = 1.2,\n       bty = \"n\")\n\n# Anotação\ntext(ano_desoneracao - 0.5, max(medias_ano$n_trabalhadores) * 0.95, \n     \"Lei 12.546/2011\\nDesoneração (2012)\", \n     pos = 4, cex = 1.1, font = 2)\n\n# Grid\ngrid(col = \"gray\", lty = \"dotted\")\n\n\n\n\nTendências paralelas em dados simulados da desoneração da folha. As trajetórias são similares antes de 2012 e divergem após a implementação da política.\n\n\n\n\n\n\nResultados\nO gráfico acima visualiza as tendências paralelas. Note como:\n\nAntes de 2012: As linhas dos dois grupos são aproximadamente paralelas, validando visualmente nossa hipótese identificadora\nApós 2012: A linha dos setores desonerados se afasta para cima, capturando o efeito positivo da política\nMagnitude: O gap vertical entre as linhas após 2012 representa o efeito DiD de aproximadamente +25 trabalhadores\n\nTabela Resumo dos Resultados:\n\n\n\n\n\n\n\n\n\n\nMétodo\nEstimativa\nErro Padrão\nEstatística t\np-valor\n\n\n\n\nDiD Manual\n+25.25\n-\n-\n-\n\n\nRegressão OLS (β₃)\n+25.25\n1.69\n14.96\n< 0.001\n\n\n\nConclusão: A desoneração da folha aumentou o emprego em aproximadamente 25 trabalhadores nas empresas beneficiadas, controlando por tendências temporais comuns e diferenças fixas entre setores. O efeito é altamente significativo estatisticamente."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#exemplo-numérico-três-grupos-seis-períodos",
    "href": "posts/Diferenças-em-diferenças/index.html#exemplo-numérico-três-grupos-seis-períodos",
    "title": "DID",
    "section": "Exemplo Numérico: Três Grupos, Seis Períodos",
    "text": "Exemplo Numérico: Três Grupos, Seis Períodos\nVisualizar exemplo em excel\nNota sobre a fórmula: No caso geral do artigo de Goodman-Bacon, pode haver múltiplos grupos tratados em diferentes momentos. A fórmula completa tem somatórios duplos para capturar todas as comparações possíveis entre pares de grupos. No nosso exemplo específico, temos apenas:\n\n1 grupo nunca tratado (U)\n2 grupos tratados (K em t=3, L em t=5)\n\nPortanto, a decomposição se simplifica para:\n\\[\n\\hat{\\beta}^{DD} = s_{kU} \\hat{\\beta}_{kU}^{2\\times2} + s_{\\ell U} \\hat{\\beta}_{\\ell U}^{2\\times2} + s_{k\\ell}^k \\hat{\\beta}_{k\\ell}^{2\\times2,k} + s_{k\\ell}^\\ell \\hat{\\beta}_{k\\ell}^{2\\times2,\\ell}\n\\]\nVamos ilustrar com dados concretos. Considere:\n\nGrupo U: Nunca tratado (2 unidades: U1, U2)\nGrupo K: Tratado em \\(t=3\\) (2 unidades: K1, K2)\nGrupo L: Tratado em \\(t=5\\) (2 unidades: L1, L2)\n\n\nEstrutura dos Dados\nMédias de \\(Y_{it}\\) por grupo e tempo:\n\n\n\nGrupo\nt=1\nt=2\nt=3\nt=4\nt=5\nt=6\n\n\n\n\nU (Nunca)\n12.0\n14.0\n15.0\n19.0\n20.0\n23.0\n\n\nK (Trat t=3)\n11.5\n14.0\n21.0\n23.0\n25.0\n27.0\n\n\nL (Trat t=5)\n11.5\n14.0\n16.0\n18.0\n28.0\n30.0\n\n\n\nIndicador de Tratamento \\(D_{it}\\):\n\n\n\nGrupo\nt=1\nt=2\nt=3\nt=4\nt=5\nt=6\n\n\n\n\nU\n0\n0\n0\n0\n0\n0\n\n\nK\n0\n0\n1\n1\n1\n1\n\n\nL\n0\n0\n0\n0\n1\n1"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#passo-1-calcular-os-estimadores-dd-22",
    "href": "posts/Diferenças-em-diferenças/index.html#passo-1-calcular-os-estimadores-dd-22",
    "title": "DID",
    "section": "Passo 1: Calcular os Estimadores DD 2×2",
    "text": "Passo 1: Calcular os Estimadores DD 2×2\n\n1.1. Grupo K vs. Grupo U\nPeríodos: PRE = \\(\\{1,2\\}\\), POST = \\(\\{3,4,5,6\\}\\)\nMédias:\n\\[\n\\begin{aligned}\n\\bar{Y}_{K,PRE} &= \\frac{11.5 + 14.0}{2} = 12.75 \\\\\n\\bar{Y}_{K,POST} &= \\frac{21.0 + 23.0 + 25.0 + 27.0}{4} = 24.0 \\\\\n\\bar{Y}_{U,PRE} &= \\frac{12.0 + 14.0}{2} = 13.0 \\\\\n\\bar{Y}_{U,POST} &= \\frac{15.0 + 19.0 + 20.0 + 23.0}{4} = 19.25\n\\end{aligned}\n\\]\nDiferenças temporais:\n\\[\n\\begin{aligned}\n\\Delta_K &= \\bar{Y}_{K,POST} - \\bar{Y}_{K,PRE} = 24.0 - 12.75 = 11.25 \\\\\n\\Delta_U &= \\bar{Y}_{U,POST} - \\bar{Y}_{U,PRE} = 19.25 - 13.0 = 6.25\n\\end{aligned}\n\\]\nEstimador DD 2×2:\n\\[\n\\hat{\\beta}_{kU}^{2\\times2} = \\Delta_K - \\Delta_U = 11.25 - 6.25 = 5.0\n\\]\n\n\n1.2. Grupo L vs. Grupo U\nPeríodos: PRE = \\(\\{1,2,3,4\\}\\), POST = \\(\\{5,6\\}\\)\nMédias:\n\\[\n\\begin{aligned}\n\\bar{Y}_{L,PRE} &= \\frac{11.5 + 14.0 + 16.0 + 18.0}{4} = 14.875 \\\\\n\\bar{Y}_{L,POST} &= \\frac{28.0 + 30.0}{2} = 29.0 \\\\\n\\bar{Y}_{U,PRE} &= \\frac{12.0 + 14.0 + 15.0 + 19.0}{4} = 15.0 \\\\\n\\bar{Y}_{U,POST} &= \\frac{20.0 + 23.0}{2} = 21.5\n\\end{aligned}\n\\]\nEstimador DD 2×2:\n\\[\n\\hat{\\beta}_{\\ell U}^{2\\times2} = (29.0 - 14.875) - (21.5 - 15.0) = 14.125 - 6.5 = 7.625\n\\]\n\n\n1.3. Grupo K vs. Grupo L (K como tratamento)\nPeríodos: PRE = \\(\\{1,2\\}\\), MID = \\(\\{3,4\\}\\)\nNesta comparação, usamos o Grupo L (ainda não tratado) como controle para o Grupo K.\nMédias:\n\\[\n\\begin{aligned}\n\\bar{Y}_{K,PRE} &= 12.75, \\quad \\bar{Y}_{K,MID} = \\frac{21.0 + 23.0}{2} = 22.0 \\\\\n\\bar{Y}_{L,PRE} &= 12.75, \\quad \\bar{Y}_{L,MID} = \\frac{16.0 + 18.0}{2} = 17.0\n\\end{aligned}\n\\]\nEstimador DD 2×2:\n\\[\n\\hat{\\beta}_{k\\ell}^{k} = (22.0 - 12.75) - (17.0 - 12.75) = 9.25 - 4.25 = 5.0\n\\]\n\n\n1.4. Grupo L vs. Grupo K (L como tratamento)\nPeríodos: MID = \\(\\{3,4\\}\\), POST = \\(\\{5,6\\}\\)\nATENÇÃO: Nesta comparação, usamos o Grupo K já tratado como controle para o Grupo L. Isso pode ser problemático se o efeito do tratamento em K estiver evoluindo ao longo do tempo.\nMédias:\n\\[\n\\begin{aligned}\n\\bar{Y}_{L,MID} &= 17.0, \\quad \\bar{Y}_{L,POST} = 29.0 \\\\\n\\bar{Y}_{K,MID} &= 22.0, \\quad \\bar{Y}_{K,POST} = \\frac{25.0 + 27.0}{2} = 26.0\n\\end{aligned}\n\\]\nEstimador DD 2×2:\n\\[\n\\hat{\\beta}_{k\\ell}^{\\ell} = (29.0 - 17.0) - (26.0 - 22.0) = 12.0 - 4.0 = 8.0\n\\]\n\n\nResumo dos Estimadores 2×2\n\n\n\nComparação\nEstimador\nInterpretação\n\n\n\n\n\\(\\hat{\\beta}_{kU}\\)\n5.0\nK vs. Nunca tratado\n\n\n\\(\\hat{\\beta}_{\\ell U}\\)\n7.625\nL vs. Nunca tratado\n\n\n\\(\\hat{\\beta}_{k\\ell}^k\\)\n5.0\nK vs. L (L como controle)\n\n\n\\(\\hat{\\beta}_{k\\ell}^\\ell\\)\n8.0\nL vs. K (K como controle)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#passo-2-calcular-os-pesos",
    "href": "posts/Diferenças-em-diferenças/index.html#passo-2-calcular-os-pesos",
    "title": "DID",
    "section": "Passo 2: Calcular os Pesos",
    "text": "Passo 2: Calcular os Pesos\nOs pesos na decomposição de Goodman-Bacon dependem de:\n\nTamanho relativo dos grupos na comparação\nVariância do tratamento dentro da comparação\n\n\nFórmulas dos Pesos\nPara uma comparação entre grupos \\(g\\) e \\(h\\):\n\\[\ns_{gh} = \\frac{w_{gh}}{\\sum w}\n\\]\nOnde o peso não normalizado é:\n\\[\nw_{gh} = n_{gh}^2 \\cdot V_{D,gh}\n\\]\n\n\\(n_{gh}\\): proporção da amostra na comparação\n\\(V_{D,gh}\\): variância do tratamento na comparação\n\n\n\nCálculo para Nosso Exemplo\nProporções dos grupos:\n\\[\nn_U = n_K = n_L = \\frac{2}{6} = \\frac{1}{3}\n\\]\nProporção de períodos tratados:\n\\[\n\\bar{D}_K = \\frac{4}{6} = \\frac{2}{3}, \\quad \\bar{D}_L = \\frac{2}{6} = \\frac{1}{3}\n\\]\nPara comparações com grupo nunca tratado:\n\\[\n\\begin{aligned}\n\\mu_{kU} &= \\frac{n_K}{n_K + n_U} = \\frac{1/3}{2/3} = 0.5 \\\\\nV_{kU} &= \\mu_{kU}(1 - \\mu_{kU}) \\bar{D}_K (1 - \\bar{D}_K) = 0.5 \\times 0.5 \\times \\frac{2}{3} \\times \\frac{1}{3} = \\frac{1}{18} \\\\\nw_{kU} &= \\left(\\frac{2}{3}\\right)^2 \\times \\frac{1}{18} = \\frac{4}{9} \\times \\frac{1}{18} = \\frac{1}{40.5}\n\\end{aligned}\n\\]\nSimilarmente, \\(w_{\\ell U} = \\frac{1}{40.5}\\).\nPara comparações entre grupos tratados:\n\\[\n\\begin{aligned}\nV_{k\\ell}^k &= \\mu_{k\\ell}(1 - \\mu_{k\\ell}) \\frac{\\bar{D}_K - \\bar{D}_L}{1 - \\bar{D}_L} \\frac{1 - \\bar{D}_K}{1 - \\bar{D}_L} \\\\\n&= 0.5 \\times 0.5 \\times \\frac{1/3}{2/3} \\times \\frac{1/3}{2/3} = 0.25 \\times 0.5 \\times 0.5 = \\frac{1}{16}\n\\end{aligned}\n\\]\n\\[\nw_{k\\ell}^k = \\left[\\left(\\frac{2}{3}\\right) \\times \\frac{2}{3}\\right]^2 \\times \\frac{1}{16} = \\left(\\frac{4}{9}\\right)^2 \\times \\frac{1}{16} = \\frac{1}{81}\n\\]\nSimilarmente, \\(w_{k\\ell}^\\ell = \\frac{1}{81}\\).\n\n\nPesos Normalizados\n\\[\n\\sum w = \\frac{1}{40.5} + \\frac{1}{40.5} + \\frac{1}{81} + \\frac{1}{81} \\approx 0.0741\n\\]\n\\[\n\\begin{aligned}\ns_{kU} &= \\frac{1}{3} \\approx 0.3333 \\\\\ns_{\\ell U} &= \\frac{1}{3} \\approx 0.3333 \\\\\ns_{k\\ell}^k &= \\frac{1}{6} \\approx 0.1667 \\\\\ns_{k\\ell}^\\ell &= \\frac{1}{6} \\approx 0.1667\n\\end{aligned}\n\\]\nVerificação: \\(\\frac{1}{3} + \\frac{1}{3} + \\frac{1}{6} + \\frac{1}{6} = 1\\)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#passo-3-decomposição-de-goodman-bacon",
    "href": "posts/Diferenças-em-diferenças/index.html#passo-3-decomposição-de-goodman-bacon",
    "title": "DID",
    "section": "Passo 3: Decomposição de Goodman-Bacon",
    "text": "Passo 3: Decomposição de Goodman-Bacon\nAgora calculamos a média ponderada dos estimadores DD 2×2:\n\\[\n\\begin{aligned}\n\\hat{\\beta}^{DD} &= s_{kU} \\hat{\\beta}_{kU} + s_{\\ell U} \\hat{\\beta}_{\\ell U} + s_{k\\ell}^k \\hat{\\beta}_{k\\ell}^k + s_{k\\ell}^\\ell \\hat{\\beta}_{k\\ell}^\\ell \\\\\n&= \\frac{1}{3} \\times 5.0 + \\frac{1}{3} \\times 7.625 + \\frac{1}{6} \\times 5.0 + \\frac{1}{6} \\times 8.0 \\\\\n&= 1.667 + 2.542 + 0.833 + 1.333 \\\\\n&= 6.375\n\\end{aligned}\n\\]\n\nTabela de Decomposição\n\n\n\n\n\n\n\n\n\nComparação\nEstimador\nPeso\nContribuição\n\n\n\n\n\\(\\hat{\\beta}_{kU} \\times s_{kU}\\)\n5.000\n0.3333\n1.667\n\n\n\\(\\hat{\\beta}_{\\ell U} \\times s_{\\ell U}\\)\n7.625\n0.3333\n2.542\n\n\n\\(\\hat{\\beta}_{k\\ell}^k \\times s_{k\\ell}^k\\)\n5.000\n0.1667\n0.833\n\n\n\\(\\hat{\\beta}_{k\\ell}^\\ell \\times s_{k\\ell}^\\ell\\)\n8.000\n0.1667\n1.333\n\n\nTotal\n\n1.0000\n6.375"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#passo-4-verificação-com-regressão-twfe",
    "href": "posts/Diferenças-em-diferenças/index.html#passo-4-verificação-com-regressão-twfe",
    "title": "DID",
    "section": "Passo 4: Verificação com Regressão TWFE",
    "text": "Passo 4: Verificação com Regressão TWFE\nRodando a regressão:\n\\[\nY_{it} = \\alpha_i + \\lambda_t + \\beta \\cdot D_{it} + \\varepsilon_{it}\n\\]\nObtemos: \\(\\hat{\\beta}^{TWFE} = 6.375\\)\nOs valores batem\nIsso confirma o teorema de Goodman-Bacon: o estimador TWFE é exatamente a média ponderada dos estimadores DD 2×2."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#implicações-práticas",
    "href": "posts/Diferenças-em-diferenças/index.html#implicações-práticas",
    "title": "DID",
    "section": "Implicações Práticas",
    "text": "Implicações Práticas\n\n1. Interpretação do Coeficiente TWFE\nO coeficiente \\(\\hat{\\beta}^{TWFE} = 6.375\\) não é simplesmente a média dos efeitos do tratamento. É uma média ponderada complexa que depende de:\n\nTiming do tratamento (quando cada grupo foi tratado)\nTamanho dos grupos\nVariância do tratamento\n\n\n\n2. O Problema das Comparações “Contaminadas”\nObserve que \\(\\hat{\\beta}_{k\\ell}^\\ell = 8.0\\) usa o Grupo K já tratado como controle para o Grupo L.\nPor que isso é problemático?\nSe o efeito do tratamento no Grupo K estiver evoluindo ao longo do tempo (efeitos dinâmicos), a diferença temporal de K (\\(\\Delta_K = \\bar{Y}_{K,POST} - \\bar{Y}_{K,MID}\\)) inclui:\n\nTendência temporal comum (que queremos remover)\nMudança no efeito do tratamento (que contamina a estimativa)\n\n\n\n3. Quando o TWFE Funciona Bem\nO TWFE identifica corretamente o efeito causal médio quando:\n\nEfeitos homogêneos: Todos os grupos têm o mesmo efeito (\\(\\tau_K = \\tau_L\\))\nSem efeitos dinâmicos: O efeito não muda ao longo do tempo (\\(\\tau_{it} = \\tau\\))\nTendências paralelas: Válidas para todas as comparações 2×2\n\n\n\n4. Quando o TWFE Falha\nO TWFE pode dar estimativas enviesadas quando:\n\nEfeitos heterogêneos: Diferentes grupos têm efeitos diferentes\nEfeitos dinâmicos: O efeito do tratamento evolui ao longo do tempo\nPesos negativos: Em casos extremos, alguns pesos \\(s\\) podem ser negativos!"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#soluções-alternativas",
    "href": "posts/Diferenças-em-diferenças/index.html#soluções-alternativas",
    "title": "DID",
    "section": "Soluções Alternativas",
    "text": "Soluções Alternativas\nQuando há heterogeneidade no timing e nos efeitos, considere: Callaway & Sant’Anna (2021) e Wooldrigde (2021)-ETWFE\nA decomposição de Goodman-Bacon revela que o estimador TWFE, aparentemente simples, esconde uma complexidade considerável quando há múltiplos grupos tratados em diferentes momentos.\nPrincipais lições:\n\nTWFE = média ponderada de comparações DD 2×2\nAlgumas comparações usam grupos já tratados como controles\nCom efeitos heterogêneos ou dinâmicos, TWFE pode ser enviesado"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#conclusão",
    "href": "posts/Diferenças-em-diferenças/index.html#conclusão",
    "title": "DID",
    "section": "Conclusão",
    "text": "Conclusão\nO método de Triplas Diferenças representa uma extensão poderosa do DiD clássico, permitindo-nos obter estimativas causais mesmo quando a hipótese de tendências paralelas é violada. Ao adicionar uma terceira diferença, o DDD controla por tendências divergentes entre os grupos de tratamento e controle, isolando o efeito puro da política de interesse.\nNo nosso exemplo da desoneração da folha de pagamento, o DDD nos permitiu corrigir o viés causado por choques setoriais específicos que afetavam diferencialmente os estados Tratado e Controle. O estimador final de 3.22 é uma medida mais confiável do efeito causal da política do que o DiD simples de 3.86.\nComo sempre na econometria aplicada, a escolha entre DiD e DDD (ou outros métodos) deve ser guiada pela natureza dos dados, pela plausibilidade das hipóteses identificadoras e pela disponibilidade de grupos de comparação adequados. O DDD é uma ferramenta valiosa no arsenal do pesquisador, mas deve ser aplicado com cuidado e com plena compreensão de suas hipóteses e limitações."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#etwfe-tratamento-escalonada",
    "href": "posts/Diferenças-em-diferenças/index.html#etwfe-tratamento-escalonada",
    "title": "DID",
    "section": "ETWFE: tratamento Escalonada",
    "text": "ETWFE: tratamento Escalonada\nNo exemplo que acabamos de ver, todos os setores desonerados receberam o tratamento simultaneamente em 2012. Nesse caso, o TWFE tradicional funciona perfeitamente e produz estimativas não enviesadas do ATT.\nMas e se a realidade fosse mais complexa? E se a desoneração tivesse sido implementada de forma escalonada, com diferentes setores sendo desonerados em anos diferentes?"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#simulando-desoneração-escalonada",
    "href": "posts/Diferenças-em-diferenças/index.html#simulando-desoneração-escalonada",
    "title": "DID",
    "section": "Simulando Desoneração Escalonada",
    "text": "Simulando Desoneração Escalonada\nVamos modificar nossos dados para criar um cenário mais realista de tratamento escalonado (staggered treatment):\n\n# Usar mesma estrutura de simulação, mas com tratamento escalonado\nset.seed(42)\n\n# Parâmetros (mesmos do exemplo anterior)\nn_empresas <- 100\nn_anos <- 9\nano_inicio <- 2007\n\n# Criar data frame\ndados_esc <- data.frame()\n\nfor (i in 1:n_empresas) {\n  # Dividir empresas em 3 grupos\n  if (i <= 33) {\n    # Grupo K: desonerados em 2012\n    coorte <- 2012\n    desonerado <- 1\n  } else if (i <= 66) {\n    # Grupo L: desonerados em 2014\n    coorte <- 2014\n    desonerado <- 1\n  } else {\n    # Grupo U: nunca desonerados\n    coorte <- 0\n    desonerado <- 0\n  }\n  \n  # Efeito fixo da empresa (mesmo do exemplo anterior)\n  efeito_fixo <- 100 + (30 * desonerado) + rnorm(1, mean = 0, sd = 10)\n  \n  for (t in 0:(n_anos - 1)) {\n    ano <- ano_inicio + t\n    \n    # Tendência temporal comum (mesma do exemplo anterior)\n    tendencia_temporal <- 5 * t\n    \n    # Efeito da desoneração (agora depende da coorte)\n    if (coorte == 2012 & ano >= 2012) {\n      # Grupo K: efeito de 25 trabalhadores\n      efeito_desoneracao <- 25\n    } else if (coorte == 2014 & ano >= 2014) {\n      # Grupo L: efeito de 20 trabalhadores (ligeiramente menor)\n      efeito_desoneracao <- 20\n    } else {\n      efeito_desoneracao <- 0\n    }\n    \n    # Ruído aleatório\n    erro <- rnorm(1, mean = 0, sd = 5)\n    \n    # Número de trabalhadores\n    n_trabalhadores <- efeito_fixo + tendencia_temporal + efeito_desoneracao + erro\n    \n    # Criar variável de tratamento\n    tratado <- ifelse((coorte == 2012 & ano >= 2012) | (coorte == 2014 & ano >= 2014), 1, 0)\n    \n    # Adicionar linha\n    dados_esc <- rbind(dados_esc, data.frame(\n      empresa_id = i,\n      ano = ano,\n      coorte = coorte,\n      tratado = tratado,\n      n_trabalhadores = n_trabalhadores\n    ))\n  }\n}\n\n# Visualizar trajetórias\nlibrary(dplyr)\nlibrary(ggplot2)\n\nmedias_esc <- dados_esc %>%\n  mutate(grupo = case_when(\n    coorte == 2012 ~ \"K (Deson. 2012)\",\n    coorte == 2014 ~ \"L (Deson. 2014)\",\n    coorte == 0 ~ \"U (Nunca)\"\n  )) %>%\n  group_by(ano, grupo) %>%\n  summarise(n_trab_medio = mean(n_trabalhadores), .groups = \"drop\")\n\nggplot(medias_esc, aes(x = ano, y = n_trab_medio, color = grupo, group = grupo)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 3) +\n  geom_vline(xintercept = 2011.5, linetype = \"dashed\", color = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = 2013.5, linetype = \"dashed\", color = \"orange\", alpha = 0.5) +\n  annotate(\"text\", x = 2012, y = max(medias_esc$n_trab_medio), \n           label = \"K desonerado\", vjust = -0.5, color = \"red\", size = 3.5) +\n  annotate(\"text\", x = 2014, y = max(medias_esc$n_trab_medio), \n           label = \"L desonerado\", vjust = -1.5, color = \"orange\", size = 3.5) +\n  scale_color_manual(values = c(\"K (Deson. 2012)\" = \"#27ae60\", \n                                 \"L (Deson. 2014)\" = \"#3498db\",\n                                 \"U (Nunca)\" = \"#e74c3c\")) +\n  labs(title = \"Desoneração Escalonada: Trajetórias de Emprego por Coorte\",\n       subtitle = \"Grupo K desonerado em 2012, Grupo L em 2014, Grupo U nunca desonerado\",\n       x = \"Ano\", y = \"Número Médio de Trabalhadores\", color = \"Grupo\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(face = \"bold\"))"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#o-problema-do-twfe-com-tratamento-escalonado",
    "href": "posts/Diferenças-em-diferenças/index.html#o-problema-do-twfe-com-tratamento-escalonado",
    "title": "DID",
    "section": "O Problema do TWFE com Tratamento Escalonado",
    "text": "O Problema do TWFE com Tratamento Escalonado\nVamos estimar o TWFE tradicional nesses dados:\n\nlibrary(fixest)\n\n# TWFE tradicional\nmod_twfe <- feols(n_trabalhadores ~ tratado | empresa_id + ano, \n                  data = dados_esc,\n                  vcov = ~empresa_id)\n\n# Resultado\nsummary(mod_twfe)\n\nOLS estimation, Dep. Var.: n_trabalhadores\nObservations: 900\nFixed-effects: empresa_id: 100,  ano: 9\nStandard-errors: Clustered (empresa_id) \n        Estimate Std. Error t value  Pr(>|t|)    \ntratado  23.0884   0.656958 35.1444 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 4.80258     Adj. R2: 0.969085\n                Within R2: 0.603727\n\n# Extrair ATT\natt_twfe <- coef(mod_twfe)[\"tratado\"]\ncat(sprintf(\"\\nATT estimado pelo TWFE: %.2f trabalhadores\\n\", att_twfe))\n\n\nATT estimado pelo TWFE: 23.09 trabalhadores\n\n\nProblema: O coeficiente do TWFE é uma média ponderada de várias comparações DD 2×2, incluindo:\n\nGrupo K vs. Grupo U\nGrupo L vs. Grupo U\nGrupo K vs. Grupo L (quando L ainda não tratado)\nGrupo L vs. Grupo K (quando K já tratado) (problemático!)\n\nA última comparação usa o Grupo K já desonerado como controle para o Grupo L. Se o efeito no Grupo K estiver evoluindo, essa comparação fica contaminada e o TWFE pode ser enviesado. Em outras palavras, se o ATT variar no tempo teremos problemas."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#a-solução-etwfe-extended-twfe",
    "href": "posts/Diferenças-em-diferenças/index.html#a-solução-etwfe-extended-twfe",
    "title": "DID",
    "section": "A Solução: ETWFE (Extended TWFE)",
    "text": "A Solução: ETWFE (Extended TWFE)\nWooldridge (2021, 2023) propôs saturar o modelo com todas as interações possíveis entre tratamento, coorte e tempo:\n\\[\nY_{it} = \\alpha_i + \\lambda_t + \\sum_{g \\neq U} \\sum_{t} \\beta_{gt} \\cdot \\mathbb{1}[G_i = g] \\cdot \\mathbb{1}[T = t] \\cdot D_{it} + \\varepsilon_{it}\n\\]\nOnde: - \\(G_i\\): coorte da empresa \\(i\\) (ano em que foi desonerada) - \\(\\beta_{gt}\\): efeito da desoneração para coorte \\(g\\) no ano \\(t\\) - \\(D_{it} = 1\\) se empresa \\(i\\) está desonerada no ano \\(t\\)\nIntuição: Cada coorte × ano tem seu próprio coeficiente, permitindo heterogeneidade total nos efeitos.\n\nEstimando o ETWFE\n\nlibrary(etwfe)\n\nWarning: pacote 'etwfe' foi compilado no R versão 4.4.3\n\n# Estimar ETWFE\nmod_etwfe <- etwfe(\n  fml  = n_trabalhadores ~ 1,  # sem controles\n  tvar = ano,                   # variável de tempo\n  gvar = coorte,                # variável de coorte\n  data = dados_esc,             # dataset\n  vcov = ~empresa_id            # erros clusterizados\n)\nresultados_etwfe <- broom::tidy(mod_etwfe, conf.int = TRUE)\n\n# Ver resumo\nsummary(mod_etwfe)\n\nOLS estimation, Dep. Var.: n_trabalhadores\nObservations: 900\nFixed-effects: coorte: 3,  ano: 9\nStandard-errors: Clustered (empresa_id) \n                               Estimate Std. Error t value  Pr(>|t|)    \n.Dtreat:coorte::2012:ano::2012  25.6121    1.04419 24.5281 < 2.2e-16 ***\n.Dtreat:coorte::2012:ano::2013  24.8691    1.19296 20.8465 < 2.2e-16 ***\n.Dtreat:coorte::2012:ano::2014  22.6393    1.41846 15.9605 < 2.2e-16 ***\n.Dtreat:coorte::2012:ano::2015  24.5765    1.44198 17.0436 < 2.2e-16 ***\n.Dtreat:coorte::2014:ano::2014  19.9948    1.31612 15.1922 < 2.2e-16 ***\n.Dtreat:coorte::2014:ano::2015  20.1489    1.59112 12.6634 < 2.2e-16 ***\n... 10 variables were removed because of collinearity (.Dtreat:coorte::2012:ano::2008, .Dtreat:coorte::2012:ano::2009 and 8 others [full set in $collin.var])\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 10.7     Adj. R2: 0.863225\n             Within R2: 0.238559\n\n\nO que aconteceu?\nO etwfe() criou automaticamente todas as interações: - .Dtreat × coorte::2012 × ano::2012 - .Dtreat × coorte::2012 × ano::2013 - … (e assim por diante para todas as combinações)\nOs coeficientes brutos do modelo ETWFE não são o ATT\n\n\nEfeitos Marginais (ATT Interpretável)\nPara obter o ATT, precisamos agregar os coeficientes brutos:\n\n# Calcular ATT médio\natt_etwfe <- emfx(mod_etwfe, type = \"simple\")\natt_etwfe\n\n\n .Dtreat Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %\n    TRUE       23      0.688 33.4   <0.001 810.4  21.6   24.3\n\nTerm: .Dtreat\nType:  response \nComparison: TRUE - FALSE\n\n\nO que é o ATT médio?\nÉ a média ponderada de todos os efeitos \\(\\beta_{gt}\\) para as observações tratadas:\n\\[\n\\widehat{ATT}_{\\text{simple}} = \\frac{1}{N_{\\text{tratado}}} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\mathbb{1}[D_{it} = 1] \\cdot \\hat{\\beta}_{G_i, t}\n\\] - \\(N\\): número total de unidades\n\n\\(T\\): número total de períodos\n\\(D_{it} = 1\\): indicador de que a unidade \\(i\\) está tratada no tempo \\(t\\)\n\\(G_i\\): coorte da unidade \\(i\\) (ano em que foi tratada pela primeira vez)\n\\(\\hat{\\beta}_{G_i, t}\\): coeficiente estimado para a coorte \\(G_i\\) no tempo \\(t\\)\n\\(N_{\\text{tratado}} = \\sum_{i,t} \\mathbb{1}[D_{it} = 1]\\): número total de observações tratadas"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#interpretando-os-coeficientes-do-bruto-ao-att",
    "href": "posts/Diferenças-em-diferenças/index.html#interpretando-os-coeficientes-do-bruto-ao-att",
    "title": "DID",
    "section": "Interpretando os Coeficientes: Do Bruto ao ATT",
    "text": "Interpretando os Coeficientes: Do Bruto ao ATT\n\nCoeficientes Brutos (Não Interpretáveis Diretamente)\nOs coeficientes brutos do modelo ETWFE não são o ATT. Por exemplo:\n\n# Pegar um coeficiente específico\ncoefs_brutos <- coef(mod_etwfe)\nexemplo_coef <- coefs_brutos[grepl(\".Dtreat:coorte::2012:ano::2013\", names(coefs_brutos))]\n\ncat(\"Exemplo de coeficiente bruto:\\n\")\n\nExemplo de coeficiente bruto:\n\ncat(sprintf(\"  .Dtreat:coorte::2012:ano::2013 = %.2f\\n\", exemplo_coef))\n\n  .Dtreat:coorte::2012:ano::2013 = 24.87\n\ncat(\"\\nEsse coeficiente NÃO é o ATT porque:\\n\")\n\n\nEsse coeficiente NÃO é o ATT porque:\n\ncat(\"  1. É condicional a efeitos fixos de empresa e ano\\n\")\n\n  1. É condicional a efeitos fixos de empresa e ano\n\ncat(\"  2. É condicional a todas as outras interações no modelo\\n\")\n\n  2. É condicional a todas as outras interações no modelo\n\ncat(\"  3. Não agrega múltiplas coortes/períodos\\n\")\n\n  3. Não agrega múltiplas coortes/períodos\n\n\n\n\nEfeitos Marginais (ATT Interpretável)\nPara obter o ATT, precisamos agregar os coeficientes brutos:\n\n# Calcular ATT médio\natt_etwfe <- emfx(mod_etwfe, type = \"simple\")\natt_etwfe\n\n\n .Dtreat Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %\n    TRUE       23      0.688 33.4   <0.001 810.4  21.6   24.3\n\nTerm: .Dtreat\nType:  response \nComparison: TRUE - FALSE\n\n\nO que é o ATT médio?\nÉ a média ponderada de todos os efeitos \\(\\beta_{gt}\\) para as observações tratadas:\n\\[\n\\widehat{ATT} = \\frac{1}{N_{\\text{tratado}}} \\sum_{i: D_{it}=1} \\hat{\\beta}_{G_i, t}\n\\]\nEm palavras: Aumento médio no emprego causado pela desoneração, agregando: - Todas as empresas desoneradas - Em todos os anos pós-desoneração - Ponderando adequadamente cada observação\n\n\nComparando TWFE vs. ETWFE\n\ncat(\"=== COMPARAÇÃO: TWFE vs. ETWFE ===\\n\\n\")\n\n=== COMPARAÇÃO: TWFE vs. ETWFE ===\n\ncat(sprintf(\"TWFE tradicional: %.2f trabalhadores\\n\", att_twfe))\n\nTWFE tradicional: 23.09 trabalhadores\n\ncat(sprintf(\"ETWFE:            %.2f trabalhadores\\n\", att_etwfe$estimate))\n\nETWFE:            22.97 trabalhadores\n\ncat(sprintf(\"Diferença:        %.2f trabalhadores\\n\", att_twfe - att_etwfe$estimate))\n\nDiferença:        0.11 trabalhadores\n\ncat(sprintf(\"Viés relativo:    %.1f%%\\n\", 100 * (att_twfe - att_etwfe$estimate) / att_etwfe$estimate))\n\nViés relativo:    0.5%\n\ncat(\"\\nInterpretação:\\n\")\n\n\nInterpretação:\n\nif (abs(att_twfe - att_etwfe$estimate) > 2) {\n  cat(\"  ✗ TWFE está ENVIESADO devido a comparações contaminadas\\n\")\n  cat(\"  ✓ ETWFE corrige esse viés ao saturar o modelo com interações\\n\")\n} else {\n  cat(\"  ✓ TWFE e ETWFE são similares (viés pequeno neste caso)\\n\")\n}\n\n  ✓ TWFE e ETWFE são similares (viés pequeno neste caso)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#efeitos-dinâmicos-event-study",
    "href": "posts/Diferenças-em-diferenças/index.html#efeitos-dinâmicos-event-study",
    "title": "DID",
    "section": "Efeitos Dinâmicos (Event Study)",
    "text": "Efeitos Dinâmicos (Event Study)\nO mais interessante é ver como o efeito evolui ao longo do tempo:\n\n# Event study: efeitos por tempo relativo\nemfx_event <- emfx(mod_etwfe, type = \"event\")\nplot(emfx_event ,\n      main = \"Event Study: Desoneração da Folha\",\n      xlab = \"Tempo Relativo\",\n      ylab = \"Efeito no Emprego\")\n\n\n\n\nObserve que emfx apenas relata efeitos pós-tratamento aqui. Isso ocorre porque todos os efeitos pré-tratamento foram eliminados da estimação em decorrência da configuração ETWFE. Especificamente, no padrão em que o grupo de controle é composto pelas unidades “ainda não” tratadas, todos os efeitos pré-tratamento são definidos mecanicamente como zero. Alternativamente, é possível especificar as unidades “nunca” tratadas como grupo de controle chamando etwfe(…, cgroup = “never”). Essa opção retorna efeitos pré-tratamento, embora com o possível custo de estimativas menos precisas por não utilizar todas as informações disponíveis.\n\nevent = -2: 2 anos antes da desoneração → deve ser ≈ 0 (tendências paralelas)\nevent = -1: 1 ano antes → deve ser ≈ 0\nevent = 0: Ano da desoneração → primeiro efeito\nevent = 1: 1 ano após → efeito pode ter crescido\nevent = 2: 2 anos após → efeito pode ter crescido mais\n\nComo é calculado?\nPara cada tempo relativo \\(j\\):\n\\[\n\\widehat{ATT}_j = \\frac{1}{N_j} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\mathbb{1}[D_{it} = 1] \\cdot \\mathbb{1}[t - G_i = j] \\cdot \\hat{\\beta}_{G_i, t}\n\\]\n\n\\(j\\): tempo relativo ao tratamento (ex: \\(j = -2, -1, 0, 1, 2, \\ldots\\))\n\\(t - G_i\\): anos desde que a unidade \\(i\\) foi tratada\n\\(\\mathbb{1}[t - G_i = j]\\): indicador de que estamos exatamente \\(j\\) anos após o tratamento\n\\(N_j = \\sum_{i,t} \\mathbb{1}[D_{it} = 1] \\cdot \\mathbb{1}[t - G_i = j]\\): número de observações no tempo relativo \\(j\\)"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#efeitos-por-coorte",
    "href": "posts/Diferenças-em-diferenças/index.html#efeitos-por-coorte",
    "title": "DID",
    "section": "Efeitos por Coorte",
    "text": "Efeitos por Coorte\nPodemos também ver o efeito para cada coorte:\n\n# Efeitos por coorte\nemfx_coorte <- emfx(mod_etwfe, type = \"group\")\nemfx_coorte\n\n\n coorte Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %\n   2012     24.4      0.696 35.1   <0.001 894.9  23.1   25.8\n   2014     20.1      1.057 19.0   <0.001 264.7  18.0   22.1\n\nTerm: .Dtreat\nType:  response \nComparison: TRUE - FALSE\n\n\nComo é calculado? \\[\n\\widehat{ATT}_g = \\frac{1}{N_g} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\mathbb{1}[G_i = g] \\cdot \\mathbb{1}[D_{it} = 1] \\cdot \\hat{\\beta}_{g, t}\n\\]\n\n\\(g\\): coorte específica (ex: \\(g = 2012\\) ou \\(g = 2014\\))\n\\(\\mathbb{1}[G_i = g]\\): indicador de que a unidade \\(i\\) pertence à coorte \\(g\\)\n\\(N_g = \\sum_{i,t} \\mathbb{1}[G_i = g] \\cdot \\mathbb{1}[D_{it} = 1]\\): número de observações tratadas da coorte \\(g\\)\nCoorte K (2012): ATT médio de ~25 trabalhadores\nCoorte L (2014): ATT médio de ~20 trabalhadores\n\nIsso confirma heterogeneidade entre coortes: setores desonerados em 2012 tiveram efeito ligeiramente maior (25) do que os desonerados em 2014 (20)."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#resumo-coeficientes-brutos-vs.-efeitos-marginais",
    "href": "posts/Diferenças-em-diferenças/index.html#resumo-coeficientes-brutos-vs.-efeitos-marginais",
    "title": "DID",
    "section": "Resumo: Coeficientes Brutos vs. Efeitos Marginais",
    "text": "Resumo: Coeficientes Brutos vs. Efeitos Marginais\n\n\n\n\n\n\n\n\n\nConceito\nO Que É\nInterpretação\nUso\n\n\n\n\nCoeficientes Brutos (\\(\\hat{\\beta}_{gt}\\))\nParâmetros da regressão ETWFE\nEfeito condicional para coorte \\(g\\) no tempo \\(t\\)\nNão diretamente interpretável\n\n\nATT Simples\nemfx(type = \"simple\")\nMédia de todos \\(\\hat{\\beta}_{gt}\\) tratados\nEfeito médio geral\n\n\nATT por Tempo Relativo\nemfx(type = \"event\")\nMédia de \\(\\hat{\\beta}_{gt}\\) para cada \\(j\\)\nEvent study (efeitos dinâmicos)\n\n\nATT por Coorte\nemfx(type = \"group\")\nMédia de \\(\\hat{\\beta}_{gt}\\) para cada coorte\nHeterogeneidade entre grupos"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#quando-usar-etwfe",
    "href": "posts/Diferenças-em-diferenças/index.html#quando-usar-etwfe",
    "title": "DID",
    "section": "Quando Usar ETWFE?",
    "text": "Quando Usar ETWFE?\n\n✓ Use ETWFE quando:\n\nTratamento escalonado (diferentes grupos tratados em momentos diferentes)\nSuspeita de efeitos heterogêneos entre coortes\nSuspeita de efeitos dinâmicos ao longo do tempo\nQuer evitar viés de comparações contaminadas\n\n\n\n✗ Não precisa de ETWFE quando:\n\nTodos tratados simultaneamente (como no exemplo original)\nApenas 2 períodos (antes/depois)\nEfeitos sabidamente homogêneos e constantes"
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#a-motivação-quando-o-did-falha",
    "href": "posts/Diferenças-em-diferenças/index.html#a-motivação-quando-o-did-falha",
    "title": "DID",
    "section": "A Motivação: Quando o DiD Falha",
    "text": "A Motivação: Quando o DiD Falha\nVamos revisitar nosso exemplo da desoneração da folha de pagamento. Nossa análise DiD comparou os setores desonerados (tratamento) com os setores não desonerados (controle). A validade do nosso resultado depende da suposição de que, se a desoneração não tivesse ocorrido, o emprego em ambos os grupos teria seguido a mesma tendência.\nAgora, imagine o seguinte cenário:\n\nOs setores não desonerados (nosso grupo de controle) são, em sua maioria, exportadores de commodities. Durante o período pós-tratamento (2012-2015), os preços internacionais dessas commodities caem drasticamente, afetando negativamente o emprego nesses setores. Enquanto isso, os setores desonerados (como TI e serviços) são focados no mercado interno e não sofrem esse choque.\n\nNesse caso, a nossa análise DiD estaria enviesada. A queda no emprego do grupo de controle não se deve apenas à tendência econômica geral (que afeta a todos), mas também a um choque específico que só atingiu a eles. Ao usarmos esse grupo como contrafactual, estaríamos superestimando o efeito da desoneração, pois a “base de comparação” deles caiu por um motivo não relacionado à política.\nO DDD resolve esse problema introduzindo um grupo de controle para o grupo de controle."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#a-intuição-do-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#a-intuição-do-ddd",
    "title": "DID",
    "section": "A Intuição do DDD",
    "text": "A Intuição do DDD\nA ideia é aplicar o DiD duas vezes:\n\nPrimeiro DiD: Calculamos o DiD para um critério: setores.\nSegundo DiD: Calculamos um segundo DiD para o outro critério: regime de tributação\nTerceira Diferença: Subtraímos o segundo DiD do primeiro DiD."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#decompondo-o-ddd-um-exemplo-prático",
    "href": "posts/Diferenças-em-diferenças/index.html#decompondo-o-ddd-um-exemplo-prático",
    "title": "DID",
    "section": "Decompondo o DDD: Um Exemplo Prático",
    "text": "Decompondo o DDD: Um Exemplo Prático\nPara solidificar a intuição, vamos usar os dados do arquivo ddd_exemplo.xlsx.\nO estimador de Triplas Diferenças é 3.22. Este é o nosso efeito causal final, ajustado para as tendências divergentes entre os grupos de tratamento e controle."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#o-modelo-de-regressão-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#o-modelo-de-regressão-ddd",
    "title": "DID",
    "section": "O Modelo de Regressão DDD",
    "text": "O Modelo de Regressão DDD\nAssim como no DiD, podemos estimar o DDD de forma mais robusta através de uma regressão OLS. O modelo requer a inclusão de uma interação tripla:\n\\[ Y_{ist} = \\beta_0 + \\beta_1 T_i + \\beta_2 P_t + \\beta_3 S_i + \\beta_4 (T_i \\times P_t) + \\beta_5 (T_i \\times S_i) + \\beta_6 (P_t \\times S_i) + \\beta_7 (T_i \\times P_t \\times S_i) + \\varepsilon_{it} \\] Onde:\n\n\\(Y_{it}\\) é a variável de resultado para a empresa \\(i\\) no período \\(t\\).\n\\(T_{i}\\) é uma dummy para o Não simples (alvo).\n\\(P_{t}\\) é uma dummy para o período Pós-tratamento.\n\\(S_{i}\\) é uma dummy para o grupo Tratados.\n\nInterpretação dos Coeficientes:\n\nAs dummies individuais (\\(\\beta_1, \\beta_2, \\beta_3\\)) controlam pelos níveis de base de cada dimensão.\nAs interações duplas (\\(\\beta_4, \\beta_5, \\beta_6\\)) controlam pelos efeitos DiD em subgrupos (o DiD entre período e estado, o DiD entre estado e grupo, e o DiD entre período e grupo).\nO coeficiente da interação tripla, \\(\\beta_7\\), é o estimador DDD. Ele captura a mudança diferencial na tendência temporal do grupo de tratamento que está acima e além de todas as outras tendências de nível inferior.\n\nAo estimar este modelo com os dados do exemplo, o coeficiente \\(\\beta_7\\) seria aproximadamente 3.22, confirmando nossa intuição e cálculo manual.\n\nInterpretação dos Resultados\nO estimador DDD de aproximadamente 3.22 nos diz que, após controlar pelas tendências divergentes entre os estados Tratado e Controle (capturadas pelo grupo de Comparação), o efeito causal da desoneração sobre o emprego no grupo Alvo é de cerca de 3.22 unidades.\nEste resultado é menor do que o DiD simples de 3.86 que obtivemos para o grupo Alvo. A diferença de 0.64 representa o viés que estava inflando nossa estimativa inicial, causado pela violação da hipótese de tendências paralelas."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#implementação-prática-com-os-dados-do-exemplo",
    "href": "posts/Diferenças-em-diferenças/index.html#implementação-prática-com-os-dados-do-exemplo",
    "title": "DID",
    "section": "Implementação Prática com os Dados do Exemplo",
    "text": "Implementação Prática com os Dados do Exemplo\nVamos agora implementar o DDD usando os dados do arquivo ddd_exemplo.xlsx. Primeiro, carregamos os dados e calculamos o estimador manualmente, depois confirmamos com uma regressão.\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(broom)\nlibrary(fixest)\n\n# Carregar os dados\ndados_ddd <- read_excel(\"ddd_exemplo.xlsx\", sheet = \"dados\")\n\n# Visualizar a estrutura\nglimpse(dados_ddd)\n\nRows: 48\nColumns: 5\n$ ID      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ Estado  <chr> \"Tratado\", \"Tratado\", \"Tratado\", \"Tratado\", \"Tratado\", \"Tratad…\n$ Periodo <chr> \"Antes\", \"Antes\", \"Antes\", \"Antes\", \"Antes\", \"Antes\", \"Antes\",…\n$ Grupo   <chr> \"Alvo\", \"Alvo\", \"Alvo\", \"Alvo\", \"Alvo\", \"Alvo\", \"Comparação\", …\n$ Y       <dbl> 105.497, 104.862, 105.648, 106.523, 104.766, 104.766, 102.579,…\n\n\n\nCálculo Manual do DDD\nVamos replicar o cálculo passo a passo que fizemos anteriormente.\n\n# Calcular médias por combinação de Estado, Periodo e Grupo\nmedias <- dados_ddd %>%\n  group_by(Estado, Periodo, Grupo) %>%\n  summarise(Y_medio = mean(Y), .groups = \"drop\")\n\n# Exibir as médias\nmedias %>%\n  pivot_wider(names_from = c(Estado, Periodo), values_from = Y_medio) %>%\n  knitr::kable(digits = 2, caption = \"Médias de Y por Grupo, Estado e Período\")\n\n\nMédias de Y por Grupo, Estado e Período\n\n\n\n\n\n\n\n\n\nGrupo\nControle_Antes\nControle_Depois\nTratado_Antes\nTratado_Depois\n\n\n\n\nAlvo\n103.65\n105.67\n105.34\n111.22\n\n\nComparação\n99.96\n101.66\n101.25\n103.59\n\n\n\n\n\nAgora calculamos os dois estimadores DiD:\n\n# DiD para o Grupo Alvo\ndid_alvo <- medias %>%\n  filter(Grupo == \"Alvo\") %>%\n  pivot_wider(names_from = Periodo, values_from = Y_medio) %>%\n  mutate(diff_temporal = Depois - Antes) %>%\n  select(Estado, diff_temporal) %>%\n  pivot_wider(names_from = Estado, values_from = diff_temporal) %>%\n  mutate(DiD_Alvo = Tratado - Controle) %>%\n  pull(DiD_Alvo)\n\n# DiD para o Grupo de Comparação\ndid_comparacao <- medias %>%\n  filter(Grupo == \"Comparação\") %>%\n  pivot_wider(names_from = Periodo, values_from = Y_medio) %>%\n  mutate(diff_temporal = Depois - Antes) %>%\n  select(Estado, diff_temporal) %>%\n  pivot_wider(names_from = Estado, values_from = diff_temporal) %>%\n  mutate(DiD_Comparacao = Tratado - Controle) %>%\n  pull(DiD_Comparacao)\n\n# Calcular o DDD\nddd_estimador <- did_alvo - did_comparacao\n\n# Exibir resultados\ncat(\"DiD (Grupo Alvo):\", round(did_alvo, 2), \"\\n\")\n\nDiD (Grupo Alvo): 3.86 \n\ncat(\"DiD (Grupo Comparação):\", round(did_comparacao, 2), \"\\n\")\n\nDiD (Grupo Comparação): 0.65 \n\ncat(\"DDD (Estimador Final):\", round(ddd_estimador, 2), \"\\n\")\n\nDDD (Estimador Final): 3.21 \n\n\n\n\nEstimação por Regressão OLS\nAgora vamos estimar o DDD usando uma regressão com interação tripla:\n\n# Criar variáveis dummy\ndados_ddd <- dados_ddd %>%\n  mutate(\n    Tratado = ifelse(Estado == \"Tratado\", 1, 0),\n    Post = ifelse(Periodo == \"Depois\", 1, 0),\n    Alvo = ifelse(Grupo == \"Alvo\", 1, 0)\n  )\n\n# Estimar o modelo DDD\nmodelo_ddd <- lm(Y ~ Tratado + Post + Alvo + \n                    Tratado:Post + Tratado:Alvo + Post:Alvo + \n                    Tratado:Post:Alvo, \n                 data = dados_ddd)\n\n# Exibir resultados\nsummary(modelo_ddd)\n\n\nCall:\nlm(formula = Y ~ Tratado + Post + Alvo + Tratado:Post + Tratado:Alvo + \n    Post:Alvo + Tratado:Post:Alvo, data = dados_ddd)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.63117 -0.71225  0.02958  0.52033  1.88850 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        99.9635     0.3779 264.512  < 2e-16 ***\nTratado             1.2850     0.5345   2.404  0.02092 *  \nPost                1.6998     0.5345   3.181  0.00284 ** \nAlvo                3.6863     0.5345   6.897 2.61e-08 ***\nTratado:Post        0.6455     0.7558   0.854  0.39818    \nTratado:Alvo        0.4088     0.7558   0.541  0.59157    \nPost:Alvo           0.3215     0.7558   0.425  0.67285    \nTratado:Post:Alvo   3.2133     1.0689   3.006  0.00455 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9257 on 40 degrees of freedom\nMultiple R-squared:  0.938, Adjusted R-squared:  0.9271 \nF-statistic:  86.4 on 7 and 40 DF,  p-value: < 2.2e-16\n\n\nO coeficiente da interação tripla Tratado:Post:Alvo é o nosso estimador DDD. Vamos extraí-lo de forma mais clara:\n\n# Extrair o coeficiente DDD\ncoef_ddd <- tidy(modelo_ddd, conf.int = TRUE) %>%\n  filter(term == \"Tratado:Post:Alvo\")\n\n# Exibir\ncoef_ddd %>%\n  select(term, estimate, std.error, p.value, conf.low, conf.high) %>%\n  knitr::kable(digits = 3, caption = \"Estimador DDD via Regressão OLS\")\n\n\nEstimador DDD via Regressão OLS\n\n\nterm\nestimate\nstd.error\np.value\nconf.low\nconf.high\n\n\n\n\nTratado:Post:Alvo\n3.213\n1.069\n0.005\n1.053\n5.374\n\n\n\n\n\n\n\nInterpretação dos Resultados\nO estimador DDD de aproximadamente 3.22 nos diz que, após controlar pelas tendências divergentes entre os estados Tratado e Controle (capturadas pelo grupo de Comparação), o efeito causal da desoneração sobre o emprego no grupo Alvo é de cerca de 3.22 unidades.\nEste resultado é menor do que o DiD simples de 3.86 que obtivemos para o grupo Alvo. A diferença de 0.64 representa o viés que estava inflando nossa estimativa inicial, causado pela violação da hipótese de tendências paralelas."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#visualização-do-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#visualização-do-ddd",
    "title": "DID",
    "section": "Visualização do DDD",
    "text": "Visualização do DDD\nUma forma eficaz de entender o DDD é visualizar as trajetórias de todos os quatro grupos:\n\n# Calcular médias para o gráfico\nmedias_plot <- dados_ddd %>%\n  mutate(Periodo_num = ifelse(Periodo == \"Antes\", 0, 1)) %>%\n  group_by(Estado, Grupo, Periodo_num) %>%\n  summarise(Y_medio = mean(Y), .groups = \"drop\")\n\n# Criar o gráfico\nggplot(medias_plot, aes(x = Periodo_num, y = Y_medio, \n                        color = Estado, linetype = Grupo, group = interaction(Estado, Grupo))) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"Antes\", \"Depois\")) +\n  scale_color_manual(values = c(\"Tratado\" = \"#E74C3C\", \"Controle\" = \"#3498DB\")) +\n  scale_linetype_manual(values = c(\"Alvo\" = \"solid\", \"Comparação\" = \"dashed\")) +\n  labs(\n    title = \"Visualização do Estimador de Triplas Diferenças (DDD)\",\n    subtitle = \"Trajetórias de Y para os quatro grupos\",\n    x = \"Período\",\n    y = \"Valor Médio de Y\",\n    color = \"Estado\",\n    linetype = \"Grupo\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nInterpretação do Gráfico:\n\nAs linhas sólidas representam o grupo Alvo (elegível para a desoneração no estado tratado).\nAs linhas tracejadas representam o grupo de Comparação (não elegível, mas afetado por choques setoriais).\nA linha vermelha representa o Estado Tratado (onde a política foi implementada).\nA linha azul representa o Estado de Controle (onde a política não foi implementada).\n\nObserve que:\n\nO grupo Alvo no Estado Tratado (linha vermelha sólida) tem o maior crescimento entre os períodos Antes e Depois.\nO grupo de Comparação também mostra crescimento diferencial entre os estados (linhas tracejadas), mas este crescimento não é devido à política, e sim a outros fatores (choques setoriais, tendências divergentes).\nO DDD subtrai o crescimento espúrio do grupo de Comparação do crescimento total do grupo Alvo, isolando o efeito puro da política."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#quando-usar-o-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#quando-usar-o-ddd",
    "title": "DID",
    "section": "Quando Usar o DDD?",
    "text": "Quando Usar o DDD?\nO método de Triplas Diferenças é particularmente útil nas seguintes situações:\n\nSuspeita de Violação de Tendências Paralelas: Quando há razões teóricas ou empíricas para acreditar que o grupo de controle tem uma trajetória diferente do grupo de tratamento, mesmo na ausência da política.\nDisponibilidade de um Grupo de Comparação Adequado: É necessário identificar um grupo que seja afetado pelos mesmos choques que o grupo de controle, mas que não seja afetado pela política de interesse.\nAlguns exemplos específicos\n\n\nPolíticas Implementadas em Diferentes Regiões: Quando uma política é implementada em alguns estados ou municípios, mas não em outros, e há preocupações sobre diferenças regionais em tendências econômicas.\nSetores com Dinâmicas Distintas: Quando diferentes setores econômicos têm trajetórias de crescimento naturalmente diferentes, e a política afeta apenas alguns deles."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#hipóteses-do-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#hipóteses-do-ddd",
    "title": "DID",
    "section": "Hipóteses do DDD",
    "text": "Hipóteses do DDD\nPara que o estimador DDD identifique o efeito causal, as seguintes hipóteses devem ser satisfeitas:\n\nTendências Paralelas Condicionais: Na ausência do tratamento, a diferença nas tendências entre o grupo Alvo e o grupo de Comparação seria a mesma no Estado Tratado e no Estado de Controle. Formalmente:\nAusência de Efeitos de Transbordamento (Spillovers): O tratamento no grupo Alvo do Estado Tratado não afeta os resultados dos outros grupos.\nComposição Estável: A composição dos grupos não muda de forma endógena em resposta à política.\nGrupo de Comparação Válido: O grupo de Comparação deve ser afetado pelos mesmos choques confundidores que o grupo Alvo, mas não pela política de interesse."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#limitações-e-cuidados",
    "href": "posts/Diferenças-em-diferenças/index.html#limitações-e-cuidados",
    "title": "DID",
    "section": "Limitações e Cuidados",
    "text": "Limitações e Cuidados\nApesar de sua robustez, o DDD tem limitações importantes:\n\nRequisitos de Dados Mais Exigentes: O DDD requer dados para quatro grupos (duas dimensões de tratamento), o que pode não estar disponível em todos os contextos.\nInterpretação Mais Complexa: A lógica do DDD é menos intuitiva do que o DiD simples, o que pode dificultar a comunicação dos resultados.\nHipóteses Mais Fortes: Embora o DDD relaxe a hipótese de tendências paralelas do DiD, ele impõe sua própria hipótese de tendências paralelas condicionais, que também pode ser violada.\nEscolha do Grupo de Comparação: A validade do DDD depende criticamente da escolha adequada do grupo de Comparação. Se este grupo não for afetado pelos mesmos choques que o grupo de controle, o estimador DDD será enviesado."
  },
  {
    "objectID": "posts/Controle-sintetico/index.html",
    "href": "posts/Controle-sintetico/index.html",
    "title": "Controle Sintético",
    "section": "",
    "text": "O Método de Controle Sintético é um estimador de efeito causal. Em um artigo seminal, “Synthetic Control Methods for Comparative Case Studies” [1], Alberto Abadie, Alexis Diamond e Jens Hainmueller introduzem e aplicam essa técnica para avaliar o impacto do programa de controle de tabaco da Califórnia.\n\n\nA ideia central do controle sintético é criar um contrafactual “sintético” para a unidade tratada. Em vez de escolher um único estado como controle, o método constrói uma combinação ponderada de múltiplos estados (o “pool de doadores”). Os pesos são calculados de forma que o controle sintético resultante se assemelhe o máximo possível à unidade tratada antes da implementação da política.\nO resultado é uma unidade de controle artificial, ou “sintética”, que representa o que teria acontecido com a unidade tratada se a política nunca tivesse sido implementada. A diferença entre a trajetória real da unidade tratada e a trajetória do seu controle sintético após a intervenção é a nossa estimativa do efeito da política.\n\n\n\nO artigo de Abadie, Diamond e Hainmueller (ADH) usa o método para avaliar o impacto de um abrangente programa de controle de tabaco implementado na Califórnia em 1988. Esta política incluiu:\n\nUm aumento de 25 centavos no imposto sobre maços de cigarro.\nFinanciamento de campanhas de mídia antitabaco.\nInvestimento em educação para a saúde.\nIncentivo a leis locais para ambientes livres de fumo.\n\nO objetivo era claro: reduzir o consumo de tabaco no estado. Para avaliar seu sucesso, os autores precisavam estimar qual teria sido o consumo de cigarros na Califórnia se o programa não tivesse sido implementado.\n\n\nOs autores utilizaram dados de 38 outros estados americanos (o “pool de doadores”) para construir uma “Califórnia Sintética”. O método atribuiu pesos a um pequeno número de estados cujas características, combinadas, melhor reproduziam a trajetória do consumo de cigarros e outras variáveis relevantes da Califórnia no período pré-intervenção (1970-1988).\nOs estados que mais contribuíram para a Califórnia Sintética foram:\n\n\n\nEstado\nPeso na Combinação\n\n\n\n\nNevada\n0.234\n\n\nMontana\n0.199\n\n\nColorado\n0.164\n\n\nConnecticut\n0.069\n\n\nUtah\n0.334\n\n\n\nFonte: Abadie, Diamond, e Hainmueller (2010). [1]\nÉ notável que estados vizinhos como Oregon e Arizona, ou grandes estados como Nova York e Texas, receberam peso zero, pois suas trajetórias não ajudavam a replicar a da Califórnia antes de 1988.\n\n\n\nAo comparar o consumo de cigarros per capita real da Califórnia com o da sua contraparte sintética após 1988, os resultados apontam um efeito causam.\n\n\n\nGráfico do Controle Sintético\n\n\n\n\n\nGráfico do Controle Sintético\n\n\n\n\n\nGráfico do Controle Sintético\n\n\nO autores estimaram que, no ano 2000, o consumo de cigarros per capita na Califórnia era cerca de 26 maços menor do que teria sido na ausência da Proposição 99. Isso representa uma redução de aproximadamente 25% no consumo, um efeito substancial e que se tornou mais pronunciado ao longo do tempo.\n\n\n\n\nA questão que os pesquisadores Alberto Abadie, Alexis Diamond e Jens Hainmueller se propuseram a responder em seu artigo “Comparative Politics and the Synthetic Control Method” [2] é aparentemente simples, mas metodologicamente complexa: Qual foi o custo econômico da reunificação para a Alemanha Ocidental?\n\n\n\nApós a queda do Muro de Berlim, a Alemanha Ocidental iniciou o monumental processo de integração da Alemanha Oriental. Isso envolveu transferências massivas de capital, reestruturação industrial. Intuitivamente, esse processo teve um custo econômico para os alemães ocidentais, mas como medi-lo?\nNão podemos simplesmente comparar o crescimento da Alemanha pós-1990 com o de outro país. O Reino Unido? Os EUA? O Japão? Nenhum desses países serve como um “gêmeo” perfeito para a Alemanha Ocidental. Cada um tem sua própria trajetória econômica, suas próprias políticas e seus próprios choques. Uma comparação direta seria, na melhor das hipóteses, imprecisa e, na pior, completamente enganosa. É precisamente para resolver este tipo de problema que o método de controle sintético foi projetado.\n\n\n\nOs autores do estudo usaram dados de 1960 a 2003 para a Alemanha Ocidental e um “pool de doadores” composto por 16 outros países desenvolvidos da OCDE (como EUA, Japão, Reino Unido, França, etc.). O objetivo era usar os dados do período pré-reunificação (1960-1989) para construir uma Alemanha Ocidental Sintética.\nO algoritmo de otimização buscou uma combinação ponderada desses 16 países que melhor se assemelhasse à Alemanha Ocidental real antes de 1990, com base em preditores-chave do crescimento econômico, como:\n\nPIB per capita em anos anteriores\nTaxa de inflação\nAbertura comercial\nParticipação da indústria no PIB\nNíveis de escolaridade e investimento\n\nO resultado foi uma Alemanha Sintética composta por uma mistura de cinco países, cujas características combinadas espelhavam de forma notável a trajetória econômica da Alemanha Ocidental antes da queda do muro.\n\n\n\nPaís\nPeso no Controle Sintético\n\n\n\n\nÁustria\n0.42\n\n\nEstados Unidos\n0.22\n\n\nJapão\n0.16\n\n\nSuíça\n0.11\n\n\nHolanda\n0.09\n\n\n\nFonte: Abadie, Diamond, e Hainmueller (2015). [1]\n\n\n\nCom a Alemanha Sintética construída, os autores puderam comparar sua trajetória de PIB per capita com a da Alemanha Ocidental real após 1990. O resultado é visualmente impressionante.\n\nNo período pré-reunificação, as trajetórias do PIB per capita para a Alemanha Ocidental e sua contraparte sintética são extremamente próximas. Após a reunificação, no entanto, as trajetórias divergem. O PIB per capita na Alemanha Ocidental cai acentuadamente em relação ao da Alemanha sintética. [1]\n\nOs resultados quantitativos indicam que a reunificação teve um custo econômico substancial e duradouro para a Alemanha Ocidental. Em média, o evento reduziu o PIB per capita em cerca de $1.600 dólares por ano durante o período de 1990 a 2003. Isso representa uma perda agregada de aproximadamente 8% do PIB da Alemanha Ocidental em 1990.\nA seguir o excel com a intuição do passo-a-passo para a construção da Alemanhã sintética, uma vez que os vetores de pesos foram encontrados:\nVisualizar exemplo em excel\n\n\n[1] Abadie, A., Diamond, A., & Hainmueller, J. (2010). Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program. Journal of the American Statistical Association, 105(490), 493-505.\n[2] Abadie, A., Diamond, A., & Hainmueller, J. (2015). Comparative Politics and the Synthetic Control Method. American Journal of Political Science, 59(2), 495-510."
  },
  {
    "objectID": "posts/Diferenças-em-diferenças/index.html#triplas-diferenças-ddd",
    "href": "posts/Diferenças-em-diferenças/index.html#triplas-diferenças-ddd",
    "title": "DID",
    "section": "Triplas Diferenças (DDD)",
    "text": "Triplas Diferenças (DDD)\nAté agora, exploramos como o Diferenças em Diferenças (DiD) pode isolar o efeito causal de uma política sob a hipótese crucial de tendências paralelas.\nE se o nosso grupo de controle, por alguma razão não observada, tiver uma trajetória de crescimento diferente do grupo de tratamento, mesmo na ausência da política?\nO método de Triplas Diferenças (DDD) é uma extensão do DiD que adiciona uma camada extra de controle, permitindo-nos obter estimativas causais mesmo quando a hipótese de tendências paralelas do DiD tradicional não se sustenta.\n\nA Motivação: Quando o DiD Falha\nVamos revisitar nosso exemplo da desoneração da folha de pagamento. Nossa análise DiD comparou os setores desonerados (tratamento) com os setores não desonerados (controle). A validade do nosso resultado depende da suposição de que, se a desoneração não tivesse ocorrido, o emprego em ambos os grupos teria seguido a mesma tendência.\nA verdade é que o critério para ser contemplado pela política foi: pertencer ao setor desonerado e não ser optante do simples nacional.\nAgora imagine a seguinte situação:\nDe maneira resumida: a tendência não é paralela para as empresas dos setores desonerados e não desonerados, mas é paralela para para os setores desonerados e não desonerados que não estão sob o regime de tributação do Simples Nacional."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html",
    "href": "posts/CopyOfModelos-em-Painel/index.html",
    "title": "Variávies instrumentais",
    "section": "",
    "text": "Forçar os alunos a frequentarem a escola por mais tempo realmente melhora seus resultados educacionais e, mais importante, seus salários futuros? Esse foi o problema de pesquisa em “Does Compulsory School Attendance Affect Schooling and Earnings?” de Joshua D. Angrist e Alan B. Krueger. 1"
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-problema-viés-de-variável-omitida",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-problema-viés-de-variável-omitida",
    "title": "Variávies instrumentais",
    "section": "O Problema: Viés de Variável Omitida",
    "text": "O Problema: Viés de Variável Omitida\nSe simplesmente compararmos os salários de pessoas com mais anos de estudo com os de pessoas com menos anos, enfrentamos um problema clássico: o viés de variável omitida.\nPessoas que estudam mais podem ter outras características que também influenciam seus salários: - Habilidade inata: Indivíduos mais “capazes” podem achar a escola mais fácil e, portanto, estudar por mais tempo. - Ambiente familiar: Famílias que valorizam a educação podem incentivar mais os estudos e também oferecer outras vantagens. - Paciência e perseverança: As mesmas qualidades que levam alguém a continuar na escola podem ser valorizadas no mercado de trabalho.\nEsses fatores “não observáveis” tornam difícil isolar o verdadeiro efeito causal de um ano a mais de estudo."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#a-solução-criativa-um-experimento-natural",
    "href": "posts/CopyOfModelos-em-Painel/index.html#a-solução-criativa-um-experimento-natural",
    "title": "Variávies instrumentais",
    "section": "A Solução Criativa: Um Experimento Natural",
    "text": "A Solução Criativa: Um Experimento Natural\nEles encontraram um experimento natural que afeta a quantidade de estudo de uma pessoa, mas que não tem (ou não deveria ter) nenhuma relação com sua habilidade ou ambiente familiar.\nO instrumento? A data de nascimento do indivíduo. 1\nComo isso funciona? A lógica combina duas regras institucionais:\n\nIdade de Início Escolar: A maioria dos distritos escolares exige que a criança complete 6 anos até uma data específica (por exemplo, 1º de janeiro) para poder se matricular. Isso faz com que crianças nascidas no início do ano (janeiro, fevereiro) comecem a escola mais velhas do que as nascidas no final do ano (novembro, dezembro).\nIdade de Evasão Escolar (Lei de Escolaridade Obrigatória): A lei permite que um aluno abandone a escola ao completar uma certa idade (geralmente 16 ou 17 anos).\n\nA combinação dessas duas regras cria um efeito interessante: - Um aluno nascido em janeiro começa a escola mais velho. Ele atingirá a idade legal para evasão (16 anos) com menos tempo de estudo concluído. - Um aluno nascido em dezembro começa mais novo. Ele atingirá os mesmos 16 anos com alguns meses a mais de estudo obrigatório já cursados.\nPortanto, a data de nascimento, de forma aleatória, “força” alguns alunos a estudarem um pouco mais que outros."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#análise-dos-dados-e-resultados",
    "href": "posts/CopyOfModelos-em-Painel/index.html#análise-dos-dados-e-resultados",
    "title": "Variávies instrumentais",
    "section": "Análise dos Dados e Resultados",
    "text": "Análise dos Dados e Resultados\nOs autores usaram dados de censos demográficos para testar sua hipótese.\n\nEfeito na Educação\nPrimeiro, eles mostraram que a data de nascimento realmente afeta a escolaridade. Como podemos ver nos gráficos do estudo, indivíduos nascidos no último trimestre do ano consistentemente apresentam, em média, um pouco mais de anos de estudo do que aqueles nascidos no primeiro trimestre.\nEssa diferença é estatisticamente significativa, embora pequena (cerca de 0.1 ano de estudo). É importante notar que esse efeito desaparece para níveis mais altos de educação, como graduação e mestrado, o que reforça a ideia de que o mecanismo por trás disso é a lei de escolaridade obrigatória, que afeta principalmente potenciais evasores do ensino médio.\n\n\nEfeito nos Salários\nA etapa final foi usar a data de nascimento como uma variável instrumental (VI) para estimar o retorno da educação sobre os salários. A VI permite isolar apenas a variação na escolaridade que foi causada pela data de nascimento, limpando o efeito de variáveis não observadas como a habilidade.\nO resultado foi surpreendente: a estimativa do retorno de um ano adicional de estudo usando a VI foi muito próxima da estimativa mais simples (feita por Mínimos Quadrados Ordinários - MQO).\nIsso sugere que, para a população afetada pela lei (aqueles no limiar de abandonar a escola), o viés de variável omitida não é tão grande quanto se pensava. Em outras palavras, o retorno financeiro por serem “forçados” a estudar um pouco mais é real e comparável ao retorno médio observado na população em geral."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#conclusão-da-aula",
    "href": "posts/CopyOfModelos-em-Painel/index.html#conclusão-da-aula",
    "title": "Variávies instrumentais",
    "section": "Conclusão da Aula",
    "text": "Conclusão da Aula\nO conceito de LATE é uma das contribuições mais importantes da econometria moderna. Ele nos força a ser muito precisos sobre o que estamos medindo.\n\nO ITT nos dá o efeito de uma política de incentivo na população como um todo.\nO LATE nos dá o efeito do tratamento em si, mas apenas para o subgrupo que responde a esse incentivo.\n\nCompreender essa distinção é fundamental para interpretar corretamente os resultados de estudos que usam variáveis instrumentais e para desenhar políticas públicas mais eficazes.\n\nReferências"
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#aprofundando-a-análise",
    "href": "posts/CopyOfModelos-em-Painel/index.html#aprofundando-a-análise",
    "title": "Variávies instrumentais",
    "section": "Aprofundando a Análise",
    "text": "Aprofundando a Análise\nvamos nos aprofundar na teoria por trás dessa técnica com o artigo seminal de Guido Imbens e Joshua Angrist: “Identification and Estimation of Local Average Treatment Effects”. 1\nEste artigo nos dá um framework mais robusto para entender exatamente o que a abordagem de VI está medindo."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-problema-quem-é-afetado-pelo-instrumento",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-problema-quem-é-afetado-pelo-instrumento",
    "title": "Variávies instrumentais",
    "section": "O Problema: Quem é Afetado pelo Instrumento?",
    "text": "O Problema: Quem é Afetado pelo Instrumento?\nLembre-se que, no exemplo da escolaridade obrigatória, o instrumento (data de nascimento) só “forçava” um subgrupo de alunos a estudar mais: aqueles que teriam abandonado a escola assim que a lei permitisse. O instrumento não teve efeito algum sobre os alunos que já planejavam se formar no ensino médio ou ir para a faculdade.\nIsso nos leva a uma questão crucial: se o instrumento só afeta uma parte da população, o efeito que medimos é válido para todos? A resposta é não. E para entender para quem ele é válido, precisamos classificar a população em relação ao instrumento.\nVamos definir:\n\nZ: Nossa variável instrumental. Pode ser Z=1 (incentivado a receber o tratamento) ou Z=0 (não incentivado). No nosso exemplo anterior, Z=1 poderia ser nascer no final do ano.\nD: O tratamento em si. D=1 (recebeu o tratamento) ou D=0 (não recebeu). No exemplo, D=1 seria ter um ano a mais de estudo.\n\nPodemos dividir a população em quatro grupos:\n\nCompliers (Cumpridores): São os indivíduos que recebem o tratamento se forem incentivados, e não recebem se não forem. Eles “seguem” o instrumento.\nAlways-Takers (Sempre Tratados): Recebem o tratamento independentemente do incentivo. (Ex: Alunos que sempre terminariam a escola).\nNever-Takers (Nunca Tratados): Nunca recebem o tratamento, mesmo que incentivados. (Ex: Alunos que abandonariam a escola mesmo que a lei os obrigasse a ficar mais um pouco).\nDefiers (Desafiadores): Fazem o oposto do incentivo. Recebem o tratamento se não são incentivados e vice-versa. (Ex: Alunos que estudariam mais se nascessem em janeiro e menos se nascessem em dezembro).\n\nPara que a análise de VI funcione, Imbens e Angrist estabelecem uma condição chave chamada Monotonicidade: não existem Defiers. Essa é uma suposição bastante razoável na maioria dos cenários. É difícil imaginar por que alguém decidiria estudar mais justamente porque a lei o libera mais cedo."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-que-a-vi-realmente-estima-o-late",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-que-a-vi-realmente-estima-o-late",
    "title": "Variávies instrumentais",
    "section": "O que a VI Realmente Estima? O LATE",
    "text": "O que a VI Realmente Estima? O LATE\nSob a condição de monotonicidade, a mágica acontece. A estimativa de Variáveis Instrumentais não mede o efeito do tratamento para toda a população. Em vez disso, ela mede o Local Average Treatment Effect (LATE), que é o efeito médio do tratamento apenas para os Compliers. [5]\nO LATE é o efeito do tratamento sobre o grupo de indivíduos que foram induzidos a receber o tratamento pela mudança no instrumento. No nosso exemplo, é o retorno de um ano a mais de estudo especificamente para os alunos que só permaneceram na escola por causa da combinação de sua data de nascimento e da lei.\n\nA Fórmula do LATE\nA estimativa de VI pode ser formalizada como a razão entre dois outros efeitos.\n\n1. Intention-to-Treat (ITT)\nPrimeiro, medimos o efeito do incentivo (Z) no resultado (Y). Isso é chamado de Intention-to-Treat (ITT). Ele ignora se o tratamento foi de fato recebido. A fórmula é:\n\\[\nITT = E[Y | Z=1] - E[Y | Z=0]\n\\]\nEm português: “Qual a diferença média nos salários (Y) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?”\n\n\n2. O Efeito do Instrumento no Tratamento\nSegundo, medimos o quão eficaz o incentivo é em de fato mudar o status do tratamento (D).\n\\[\nEfeito_{Z \\to D} = E[D | Z=1] - E[D | Z=0]\n\\]\nEm português: “Qual a diferença na proporção de pessoas que receberam o tratamento (D) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?” Este denominador representa, na verdade, a proporção de Compliers na população.\n\n\nA Razão Mágica: Wald Estimator\nO estimador de VI, também conhecido como Wald Estimator, é simplesmente a razão entre o ITT e o efeito do instrumento no tratamento:\n\\[\n\\hat{\\beta}_{IV} = \\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]} = \\frac{ITT}{\\text{Proporção de Compliers}}\n\\]\nEssa fórmula nos diz que o LATE é o efeito “Intention-to-Treat” reescalonado pela proporção de pessoas que de fato cumpriram com o incentivo (os Compliers). Estamos, essencialmente, atribuindo todo o efeito observado no resultado (o ITT) ao grupo que de fato foi influenciado pelo instrumento."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-que-a-vi-realmente-estima",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-que-a-vi-realmente-estima",
    "title": "Variávies instrumentais",
    "section": "O que a VI Realmente Estima?",
    "text": "O que a VI Realmente Estima?\nA estimativa de Variáveis Instrumentais não mede o efeito do tratamento para toda a população. Em vez disso, ela mede o Local Average Treatment Effect (LATE), que é o efeito médio do tratamento apenas para os Compliers. [5]\nO LATE é o efeito do tratamento sobre o grupo de indivíduos que foram induzidos a receber o tratamento pela mudança no instrumento. No nosso exemplo, é o retorno de um ano a mais de estudo especificamente para os alunos que só permaneceram na escola por causa da combinação de sua data de nascimento e da lei.\n\nA Fórmula do LATE\nA estimativa de VI pode ser formalizada como a razão entre dois outros efeitos.\n\n1. Intention-to-Treat (ITT)\nPrimeiro, medimos o efeito do incentivo (Z) no resultado (Y). Isso é chamado de Intention-to-Treat (ITT). Ele ignora se o tratamento foi de fato recebido. A fórmula é:\n\\[\nITT = E[Y | Z=1] - E[Y | Z=0]\n\\]\nEm português: “Qual a diferença média nos salários (Y) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?”\n\n\n2. O Efeito do Instrumento no Tratamento\nSegundo, medimos o quão eficaz o incentivo é em de fato mudar o status do tratamento (D).\n\\[\nEfeito_{Z \\to D} = E[D | Z=1] - E[D | Z=0]\n\\]\nEm português: “Qual a diferença na proporção de pessoas que receberam o tratamento (D) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?” Este denominador representa, na verdade, a proporção de Compliers na população.\n\n\nEstimator IV\nO estimador de VI, também conhecido como Wald Estimator, é simplesmente a razão entre o ITT e o efeito do instrumento no tratamento:\n\\[\n\\hat{\\beta}_{IV} = \\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]} = \\frac{ITT}{\\text{Proporção de Compliers}}\n\\]\nEssa fórmula nos diz que o LATE é o efeito “Intention-to-Treat” reescalonado pela proporção de pessoas que de fato cumpriram com o incentivo (os Compliers). Estamos, essencialmente, atribuindo todo o efeito observado no resultado (o ITT) ao grupo que de fato foi influenciado pelo instrumento."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#resumindo",
    "href": "posts/CopyOfModelos-em-Painel/index.html#resumindo",
    "title": "Variávies instrumentais",
    "section": "Resumindo",
    "text": "Resumindo\nO conceito de LATE é uma das contribuições mais importantes da econometria moderna. Ele nos força a ser muito precisos sobre o que estamos medindo.\n\nO ITT nos dá o efeito de uma política de incentivo na população como um todo.\nO LATE nos dá o efeito do tratamento em si, mas apenas para o subgrupo que responde a esse incentivo.\n\nCompreender essa distinção é fundamental para interpretar corretamente os resultados de estudos que usam variáveis instrumentais e para desenhar políticas públicas mais eficazes."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#outro-exemplo",
    "href": "posts/CopyOfModelos-em-Painel/index.html#outro-exemplo",
    "title": "Variávies instrumentais",
    "section": "Outro exemplo",
    "text": "Outro exemplo\nVamos analisar um dos exemplos mais famosos de um experimento natural: o sorteio militar da Guerra do Vietnã, detalhado no artigo de Joshua Angrist de 1990, “Lifetime Earnings and the Vietnam Era Draft Lottery”. 3\nA pergunta de pesquisa é: servir no exército durante a Guerra do Vietnã afetou os rendimentos futuros dos veteranos?"
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-desafio-da-seleção",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-desafio-da-seleção",
    "title": "Variávies instrumentais",
    "section": "O Desafio da Seleção",
    "text": "O Desafio da Seleção\nAssim como no problema da educação, uma comparação simples entre os salários de veteranos e não veteranos é problemática. Os homens que servem no exército (especialmente os voluntários) podem ser diferentes dos que não servem em muitos aspectos: nível de educação, origem socioeconômica, oportunidades de trabalho, etc. Isso cria um viés de seleção que contamina a análise."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#o-instrumento-perfeito-a-loteria-do-alistamento",
    "href": "posts/CopyOfModelos-em-Painel/index.html#o-instrumento-perfeito-a-loteria-do-alistamento",
    "title": "Variávies instrumentais",
    "section": "O Instrumento Perfeito: A Loteria do Alistamento",
    "text": "O Instrumento Perfeito: A Loteria do Alistamento\nPara contornar esse problema, Angrist utiliza um instrumento brilhante: o sorteio do alistamento militar (draft lottery). 3\nDurante a era do Vietnã, o governo dos EUA realizou um sorteio para determinar a ordem de convocação. Cada data de nascimento do ano recebia um número aleatório de 1 a 365 (o “Random Sequence Number” ou RSN). O governo então definia um teto (por exemplo, 125). Homens cujos aniversários correspondiam a números abaixo do teto eram elegíveis para convocação, enquanto aqueles com números acima estavam essencialmente isentos.\nA aleatoriedade do sorteio é a chave: ter um número baixo ou alto não tem nenhuma relação com a habilidade, educação ou potencial de ganho de um indivíduo. A única coisa que o número da loteria afeta é a probabilidade de ser convocado para o serviço militar.\nTemos aqui a configuração perfeita para uma análise de VI:\n\nInstrumento (Z): Ser elegível para o alistamento (ter um número de sorteio abaixo do teto). Z=1 se elegível, Z=0 se não.\nTratamento (D): Servir no exército (ter status de veterano). D=1 se veterano, D=0 se não.\nResultado (Y): Rendimentos (salários) anos após o período de serviço."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#aplicando-os-conceitos-de-itt-e-late",
    "href": "posts/CopyOfModelos-em-Painel/index.html#aplicando-os-conceitos-de-itt-e-late",
    "title": "Variávies instrumentais",
    "section": "Aplicando os Conceitos de ITT e LATE",
    "text": "Aplicando os Conceitos de ITT e LATE\nVamos agora aplicar o framework do LATE\n\nOs Grupos de População\nNo contexto do sorteio, os quatro grupos são fáceis de identificar:\n\nCompliers: Homens que serviram no exército porque foram sorteados com um número baixo, mas não teriam servido de outra forma. São os “convocados relutantes”.\nAlways-Takers: Homens que se alistaram voluntariamente, independentemente do seu número no sorteio. Eles serviriam de qualquer maneira.\nNever-Takers: Homens que, mesmo sendo elegíveis para a convocação, não serviram (por isenções médicas, causas estudantis, ou simplesmente sorte).\nDefiers: Homens que serviriam apenas se tivessem um número alto no sorteio. Este grupo é considerado inexistente (a condição de monotonicidade se aplica).\n\n\n\nIntention-to-Treat (ITT)\nO primeiro passo de Angrist é calcular o ITT. Ele compara os rendimentos médios de todos os homens elegíveis para o alistamento com os rendimentos de todos os não elegíveis.\n\\[\nITT = E[\\text{Salário} | \\text{Elegível}] - E[\\text{Salário} | \\text{Não Elegível}]\n\\]\nOs resultados, como vistos na Tabela 1 do artigo, mostram que os homens brancos que foram elegíveis para o alistamento (o grupo “incentivado”) ganhavam consistentemente menos, anos depois, do que aqueles que não eram elegíveis. [7] Este é o efeito da intenção de tratar: a simples elegibilidade para a convocação já teve um impacto negativo nos rendimentos futuros.\n\n\nCalculando o LATE\nO ITT, no entanto, não é o efeito de servir no exército, mas sim o efeito de ser elegível. Para encontrar o efeito do serviço militar em si, precisamos usar o estimador de Wald:\n\\[\nLATE = \\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]}\n\\]\n\nO numerador é o ITT que acabamos de discutir (a diferença nos salários).\nO denominador é a diferença na probabilidade de servir no exército entre os elegíveis e os não elegíveis. Esse número é a proporção de Compliers. A Tabela 2 do artigo mostra que ser elegível aumentava a probabilidade de servir em cerca de 10 a 16 pontos percentuais.\n\nAo dividir a diferença de salários pela diferença na probabilidade de servir, Angrist isola o efeito do serviço militar apenas para os Compliers — os homens que foram efetivamente induzidos ao serviço pelo sorteio.\nO resultado principal do estudo é que, para este grupo, o serviço militar durante a era do Vietnã causou uma perda substancial de rendimentos, de aproximadamente 15% ao ano, mesmo uma década após o serviço."
  },
  {
    "objectID": "posts/CopyOfModelos-em-Painel/index.html#conclusão",
    "href": "posts/CopyOfModelos-em-Painel/index.html#conclusão",
    "title": "Variávies instrumentais",
    "section": "Conclusão",
    "text": "Conclusão\nO estudo do sorteio do Vietnã é um exemplo poderoso e claro de como os conceitos de ITT e LATE funcionam na prática.\n\nEle demonstra como um evento aleatório (a loteria) pode ser usado para responder a uma pergunta causal complexa.\nEle mostra que o efeito de uma política (o alistamento) não é homogêneo e que a VI nos permite identificar o efeito para um grupo específico e relevante: aqueles cuja decisão foi alterada pelo instrumento.\nO resultado (um grande impacto negativo nos rendimentos) teve implicações políticas significativas para o debate sobre a compensação a veteranos.\n\nEste artigo solidificou a importância da busca por experimentos naturais e da interpretação cuidadosa do que as estimativas de VI realmente significam.\n\nReferências"
  },
  {
    "objectID": "posts/Variavel-instrumental/index.html",
    "href": "posts/Variavel-instrumental/index.html",
    "title": "Variávies instrumentais",
    "section": "",
    "text": "Forçar os alunos a frequentarem a escola por mais tempo realmente melhora seus resultados educacionais e, mais importante, seus salários futuros? Esse foi o problema de pesquisa em “Does Compulsory School Attendance Affect Schooling and Earnings?” de Joshua D. Angrist e Alan B. Krueger. 1\n\n\nSe simplesmente compararmos os salários de pessoas com mais anos de estudo com os de pessoas com menos anos, enfrentamos um problema clássico: o viés de variável omitida.\nPessoas que estudam mais podem ter outras características que também influenciam seus salários: - Habilidade inata: Indivíduos mais “capazes” podem achar a escola mais fácil e, portanto, estudar por mais tempo. - Ambiente familiar: Famílias que valorizam a educação podem incentivar mais os estudos e também oferecer outras vantagens. - Paciência e perseverança: As mesmas qualidades que levam alguém a continuar na escola podem ser valorizadas no mercado de trabalho.\nEsses fatores “não observáveis” tornam difícil isolar o verdadeiro efeito causal de um ano a mais de estudo.\n\n\n\nEles encontraram um experimento natural que afeta a quantidade de estudo de uma pessoa, mas que não tem (ou não deveria ter) nenhuma relação com sua habilidade ou ambiente familiar.\nO instrumento? A data de nascimento do indivíduo. 1\nComo isso funciona? A lógica combina duas regras institucionais:\n\nIdade de Início Escolar: A maioria dos distritos escolares exige que a criança complete 6 anos até uma data específica (por exemplo, 1º de janeiro) para poder se matricular. Isso faz com que crianças nascidas no início do ano (janeiro, fevereiro) comecem a escola mais velhas do que as nascidas no final do ano (novembro, dezembro).\nIdade de Evasão Escolar (Lei de Escolaridade Obrigatória): A lei permite que um aluno abandone a escola ao completar uma certa idade (geralmente 16 ou 17 anos).\n\nA combinação dessas duas regras cria um efeito interessante: - Um aluno nascido em janeiro começa a escola mais velho. Ele atingirá a idade legal para evasão (16 anos) com menos tempo de estudo concluído. - Um aluno nascido em dezembro começa mais novo. Ele atingirá os mesmos 16 anos com alguns meses a mais de estudo obrigatório já cursados.\nPortanto, a data de nascimento, de forma aleatória, “força” alguns alunos a estudarem um pouco mais que outros.\n\n\n\nOs autores usaram dados de censos demográficos para testar sua hipótese.\n\n\nPrimeiro, eles mostraram que a data de nascimento realmente afeta a escolaridade. Como podemos ver nos gráficos do estudo, indivíduos nascidos no último trimestre do ano consistentemente apresentam, em média, um pouco mais de anos de estudo do que aqueles nascidos no primeiro trimestre.\nEssa diferença é estatisticamente significativa, embora pequena (cerca de 0.1 ano de estudo). É importante notar que esse efeito desaparece para níveis mais altos de educação, como graduação e mestrado, o que reforça a ideia de que o mecanismo por trás disso é a lei de escolaridade obrigatória, que afeta principalmente potenciais evasores do ensino médio.\n\n\n\nA etapa final foi usar a data de nascimento como uma variável instrumental (VI) para estimar o retorno da educação sobre os salários. A VI permite isolar apenas a variação na escolaridade que foi causada pela data de nascimento, limpando o efeito de variáveis não observadas como a habilidade.\nO resultado foi surpreendente: a estimativa do retorno de um ano adicional de estudo usando a VI foi muito próxima da estimativa mais simples (feita por Mínimos Quadrados Ordinários - MQO).\nIsso sugere que, para a população afetada pela lei (aqueles no limiar de abandonar a escola), o viés de variável omitida não é tão grande quanto se pensava. Em outras palavras, o retorno financeiro por serem “forçados” a estudar um pouco mais é real e comparável ao retorno médio observado na população em geral.\n\n\n\n\nvamos nos aprofundar na teoria por trás dessa técnica com o artigo seminal de Guido Imbens e Joshua Angrist: “Identification and Estimation of Local Average Treatment Effects”. 1\nEste artigo nos dá um framework mais robusto para entender exatamente o que a abordagem de VI está medindo.\n\n\n\nLembre-se que, no exemplo da escolaridade obrigatória, o instrumento (data de nascimento) só “forçava” um subgrupo de alunos a estudar mais: aqueles que teriam abandonado a escola assim que a lei permitisse. O instrumento não teve efeito algum sobre os alunos que já planejavam se formar no ensino médio ou ir para a faculdade.\nIsso nos leva a uma questão crucial: se o instrumento só afeta uma parte da população, o efeito que medimos é válido para todos? A resposta é não. E para entender para quem ele é válido, precisamos classificar a população em relação ao instrumento.\nVamos definir:\n\nZ: Nossa variável instrumental. Pode ser Z=1 (incentivado a receber o tratamento) ou Z=0 (não incentivado). No nosso exemplo anterior, Z=1 poderia ser nascer no final do ano.\nD: O tratamento em si. D=1 (recebeu o tratamento) ou D=0 (não recebeu). No exemplo, D=1 seria ter um ano a mais de estudo.\n\nPodemos dividir a população em quatro grupos:\n\nCompliers (Cumpridores): São os indivíduos que recebem o tratamento se forem incentivados, e não recebem se não forem. Eles “seguem” o instrumento.\nAlways-Takers (Sempre Tratados): Recebem o tratamento independentemente do incentivo. (Ex: Alunos que sempre terminariam a escola).\nNever-Takers (Nunca Tratados): Nunca recebem o tratamento, mesmo que incentivados. (Ex: Alunos que abandonariam a escola mesmo que a lei os obrigasse a ficar mais um pouco).\nDefiers (Desafiadores): Fazem o oposto do incentivo. Recebem o tratamento se não são incentivados e vice-versa. (Ex: Alunos que estudariam mais se nascessem em janeiro e menos se nascessem em dezembro).\n\nPara que a análise de VI funcione, Imbens e Angrist estabelecem uma condição chave chamada Monotonicidade: não existem Defiers. Essa é uma suposição bastante razoável na maioria dos cenários. É difícil imaginar por que alguém decidiria estudar mais justamente porque a lei o libera mais cedo.\n\n\n\nA estimativa de Variáveis Instrumentais não mede o efeito do tratamento para toda a população. Em vez disso, ela mede o Local Average Treatment Effect (LATE), que é o efeito médio do tratamento apenas para os Compliers. [5]\nO LATE é o efeito do tratamento sobre o grupo de indivíduos que foram induzidos a receber o tratamento pela mudança no instrumento. No nosso exemplo, é o retorno de um ano a mais de estudo especificamente para os alunos que só permaneceram na escola por causa da combinação de sua data de nascimento e da lei.\n\n\nA estimativa de VI pode ser formalizada como a razão entre dois outros efeitos.\n\n\nPrimeiro, medimos o efeito do incentivo (Z) no resultado (Y). Isso é chamado de Intention-to-Treat (ITT). Ele ignora se o tratamento foi de fato recebido. A fórmula é:\n\\[\nITT = E[Y | Z=1] - E[Y | Z=0]\n\\]\nEm português: “Qual a diferença média nos salários (Y) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?”\n\n\n\nSegundo, medimos o quão eficaz o incentivo é em de fato mudar o status do tratamento (D).\n\\[\nEfeito_{Z \\to D} = E[D | Z=1] - E[D | Z=0]\n\\]\nEm português: “Qual a diferença na proporção de pessoas que receberam o tratamento (D) entre o grupo incentivado (Z=1) e o não incentivado (Z=0)?” Este denominador representa, na verdade, a proporção de Compliers na população.\n\n\n\nO estimador de VI, também conhecido como Wald Estimator, é simplesmente a razão entre o ITT e o efeito do instrumento no tratamento:\n\\[\n\\hat{\\beta}_{IV} = \\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]} = \\frac{ITT}{\\text{Proporção de Compliers}}\n\\]\nEssa fórmula nos diz que o LATE é o efeito “Intention-to-Treat” reescalonado pela proporção de pessoas que de fato cumpriram com o incentivo (os Compliers). Estamos, essencialmente, atribuindo todo o efeito observado no resultado (o ITT) ao grupo que de fato foi influenciado pelo instrumento.\n\n\n\n\n\nO conceito de LATE é uma das contribuições mais importantes da econometria moderna. Ele nos força a ser muito precisos sobre o que estamos medindo.\n\nO ITT nos dá o efeito de uma política de incentivo na população como um todo.\nO LATE nos dá o efeito do tratamento em si, mas apenas para o subgrupo que responde a esse incentivo.\n\nCompreender essa distinção é fundamental para interpretar corretamente os resultados de estudos que usam variáveis instrumentais e para desenhar políticas públicas mais eficazes.\n\n\n\nVamos analisar um dos exemplos mais famosos de um experimento natural: o sorteio militar da Guerra do Vietnã, detalhado no artigo de Joshua Angrist de 1990, “Lifetime Earnings and the Vietnam Era Draft Lottery”. 3\nA pergunta de pesquisa é: servir no exército durante a Guerra do Vietnã afetou os rendimentos futuros dos veteranos?\n\n\n\nAssim como no problema da educação, uma comparação simples entre os salários de veteranos e não veteranos é problemática. Os homens que servem no exército (especialmente os voluntários) podem ser diferentes dos que não servem em muitos aspectos: nível de educação, origem socioeconômica, oportunidades de trabalho, etc. Isso cria um viés de seleção que contamina a análise.\n\n\n\nPara contornar esse problema, Angrist utiliza um instrumento brilhante: o sorteio do alistamento militar (draft lottery). 3\nDurante a era do Vietnã, o governo dos EUA realizou um sorteio para determinar a ordem de convocação. Cada data de nascimento do ano recebia um número aleatório de 1 a 365 (o “Random Sequence Number” ou RSN). O governo então definia um teto (por exemplo, 125). Homens cujos aniversários correspondiam a números abaixo do teto eram elegíveis para convocação, enquanto aqueles com números acima estavam essencialmente isentos.\nA aleatoriedade do sorteio é a chave: ter um número baixo ou alto não tem nenhuma relação com a habilidade, educação ou potencial de ganho de um indivíduo. A única coisa que o número da loteria afeta é a probabilidade de ser convocado para o serviço militar.\nTemos aqui a configuração perfeita para uma análise de VI:\n\nInstrumento (Z): Ser elegível para o alistamento (ter um número de sorteio abaixo do teto). Z=1 se elegível, Z=0 se não.\nTratamento (D): Servir no exército (ter status de veterano). D=1 se veterano, D=0 se não.\nResultado (Y): Rendimentos (salários) anos após o período de serviço.\n\n\n\n\nVamos agora aplicar o framework do LATE\n\n\nNo contexto do sorteio, os quatro grupos são fáceis de identificar:\n\nCompliers: Homens que serviram no exército porque foram sorteados com um número baixo, mas não teriam servido de outra forma. São os “convocados relutantes”.\nAlways-Takers: Homens que se alistaram voluntariamente, independentemente do seu número no sorteio. Eles serviriam de qualquer maneira.\nNever-Takers: Homens que, mesmo sendo elegíveis para a convocação, não serviram (por isenções médicas, causas estudantis, ou simplesmente sorte).\nDefiers: Homens que serviriam apenas se tivessem um número alto no sorteio. Este grupo é considerado inexistente (a condição de monotonicidade se aplica).\n\n\n\n\nO primeiro passo de Angrist é calcular o ITT. Ele compara os rendimentos médios de todos os homens elegíveis para o alistamento com os rendimentos de todos os não elegíveis.\n\\[\nITT = E[\\text{Salário} | \\text{Elegível}] - E[\\text{Salário} | \\text{Não Elegível}]\n\\]\nOs resultados, como vistos na Tabela 1 do artigo, mostram que os homens brancos que foram elegíveis para o alistamento (o grupo “incentivado”) ganhavam consistentemente menos, anos depois, do que aqueles que não eram elegíveis. [7] Este é o efeito da intenção de tratar: a simples elegibilidade para a convocação já teve um impacto negativo nos rendimentos futuros.\n\n\n\nO ITT, no entanto, não é o efeito de servir no exército, mas sim o efeito de ser elegível. Para encontrar o efeito do serviço militar em si, precisamos usar o estimador de Wald:\n\\[\nLATE = \\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]}\n\\]\n\nO numerador é o ITT que acabamos de discutir (a diferença nos salários).\nO denominador é a diferença na probabilidade de servir no exército entre os elegíveis e os não elegíveis. Esse número é a proporção de Compliers. A Tabela 2 do artigo mostra que ser elegível aumentava a probabilidade de servir em cerca de 10 a 16 pontos percentuais.\n\nAo dividir a diferença de salários pela diferença na probabilidade de servir, Angrist isola o efeito do serviço militar apenas para os Compliers — os homens que foram efetivamente induzidos ao serviço pelo sorteio.\nO resultado principal do estudo é que, para este grupo, o serviço militar durante a era do Vietnã causou uma perda substancial de rendimentos, de aproximadamente 15% ao ano, mesmo uma década após o serviço.\n\n\n\n\nO estudo do sorteio do Vietnã é um exemplo poderoso e claro de como os conceitos de ITT e LATE funcionam na prática.\n\nEle demonstra como um evento aleatório (a loteria) pode ser usado para responder a uma pergunta causal complexa.\nEle mostra que o efeito de uma política (o alistamento) não é homogêneo e que a VI nos permite identificar o efeito para um grupo específico e relevante: aqueles cuja decisão foi alterada pelo instrumento.\nO resultado (um grande impacto negativo nos rendimentos) teve implicações políticas significativas para o debate sobre a compensação a veteranos.\n\nEste artigo solidificou a importância da busca por experimentos naturais e da interpretação cuidadosa do que as estimativas de VI realmente significam."
  },
  {
    "objectID": "posts/RDD/index.html",
    "href": "posts/RDD/index.html",
    "title": "RDD",
    "section": "",
    "text": "O Regression Discontinuity Design (RDD), ou Regressão com Descontinuidade, é mais um método para estimação do efeito causais (treatment effect).\nSua a fundamentação teórica, encontra-se no trabalho seminal de Hahn, Todd e Van der Klaauw (2001) [1], que formalizou as condições sob as quais o RDD identifica um efeito de tratamento causal. Em seguida, faremos um paralelo entre duas aplicações empíricas clássicas:\n\nLee (2008) [2]: O estudo sobre a vantagem eleitoral de incumbentes nos EUA, um exemplo de como uma regra (vencer por uma margem mínima) cria um quase-experimento.\nCarpenter & Dobkin (2009) [3]: A análise do efeito da idade mínima para consumo de álcool sobre a mortalidade, um caso onde a variável de tratamento é perfeitamente determinada por uma lei."
  },
  {
    "objectID": "posts/RDD/index.html#o-setup-básico-do-rdd",
    "href": "posts/RDD/index.html#o-setup-básico-do-rdd",
    "title": "RDD",
    "section": "O Setup Básico do RDD",
    "text": "O Setup Básico do RDD\nImagine uma situação onde uma intervenção (tratamento) é atribuída com base em uma variável de continuidade (running variable), que chamaremos de Z. Existe um ponto de corte (cutoff), c, que determina quem recebe o tratamento. Por exemplo, Z pode ser a nota de um aluno em um exame, e todos com nota Z >= c recebem uma bolsa de estudos.\nO RDD explora a ideia de que indivíduos com valores de Z muito próximos ao cutoff c, mas de lados opostos, são, em média, muito semelhantes em todas as outras características (observáveis e não observáveis). A única diferença sistemática entre eles é o recebimento do tratamento. Portanto, qualquer “salto” ou descontinuidade na variável de resultado nesse ponto pode ser atribuído ao efeito causal do tratamento."
  },
  {
    "objectID": "posts/RDD/index.html#sharp-vs.-fuzzy-rdd",
    "href": "posts/RDD/index.html#sharp-vs.-fuzzy-rdd",
    "title": "RDD",
    "section": "Sharp vs. Fuzzy RDD",
    "text": "Sharp vs. Fuzzy RDD\nHTV formalizam a distinção entre dois tipos de RDD:\n\nSharp RDD (RDD Nítido): O tratamento é uma função determinística do cutoff. Todos os indivíduos com Z >= c recebem o tratamento, e ninguém com Z < c o recebe. A probabilidade de tratamento salta de 0 para 1 exatamente no cutoff.\nFuzzy RDD (RDD Difuso): O cutoff influencia a probabilidade de receber o tratamento, mas não a determina perfeitamente. Por exemplo, uma bolsa de estudos pode ser oferecida a todos com Z >= c, mas nem todos a aceitam. Nesse caso, a probabilidade de tratamento salta de um valor p_abaixo para um valor p_acima no cutoff, mas não necessariamente de 0 para 1."
  },
  {
    "objectID": "posts/RDD/index.html#a-condição-de-identificação-fundamental",
    "href": "posts/RDD/index.html#a-condição-de-identificação-fundamental",
    "title": "RDD",
    "section": "A Condição de Identificação Fundamental",
    "text": "A Condição de Identificação Fundamental\nA grande contribuição de HTV foi esclarecer o pressuposto central que permite a identificação do efeito causal. Este pressuposto é a continuidade das funções de regressão dos resultados potenciais no cutoff.\nVamos definir os resultados potenciais:\n\nY(1): O resultado que um indivíduo teria se recebesse o tratamento.\nY(0): O resultado que o mesmo indivíduo teria se não recebesse o tratamento.\n\nO pressuposto fundamental do RDD é que as médias condicionais de Y(1) e Y(0) são contínuas em relação à variável de continuidade Z no ponto c.\n\nPressuposto de Continuidade (HTV, 2001): As funções E[Y(1) | Z=z] e E[Y(0) | Z=z] são contínuas em z=c.\n\nEm palavras simples, isso significa que, na ausência do tratamento, a relação entre a variável de continuidade e o resultado seria suave e não teria um salto no cutoff. Se essa condição for válida, qualquer salto observado no resultado real no cutoff deve ser atribuído ao tratamento."
  },
  {
    "objectID": "posts/RDD/index.html#o-que-o-rdd-estima-o-late",
    "href": "posts/RDD/index.html#o-que-o-rdd-estima-o-late",
    "title": "RDD",
    "section": "O que o RDD Estima: O LATE",
    "text": "O que o RDD Estima: O LATE\nSob este pressuposto, HTV mostram que o RDD identifica o Efeito Médio do Tratamento Local (Local Average Treatment Effect - LATE) no cutoff. O estimador é a razão entre o salto no resultado e o salto na probabilidade de tratamento:\n\\[ \\text{LATE} = \\frac{\\lim_{z \\to c^+} E[Y|Z=z] - \\lim_{z \\to c^-} E[Y|Z=z]}{\\lim_{z \\to c^+} E[D|Z=z] - \\lim_{z \\to c^-} E[D|Z=z]} \\]\nOnde: - Y é o resultado observado. - D é o indicador de tratamento (0 ou 1). - O numerador é o “salto” no resultado no cutoff. - O denominador é o “salto” na probabilidade de tratamento no cutoff.\nNo caso de um Sharp RDD, o denominador é 1 (o salto na probabilidade é de 0 para 1), então o LATE é simplesmente o tamanho do salto no resultado."
  },
  {
    "objectID": "posts/RDD/index.html#a-lógica-da-identificação-em-cada-contexto",
    "href": "posts/RDD/index.html#a-lógica-da-identificação-em-cada-contexto",
    "title": "RDD",
    "section": "A Lógica da Identificação em Cada Contexto",
    "text": "A Lógica da Identificação em Cada Contexto\n\nLee (2008): Eleições como Experimentos Aleatórios\nA genialidade do estudo de Lee é argumentar que, em eleições muito disputadas (com margem de vitória próxima de zero), o vencedor é tão bom quanto aleatório. Um candidato que vence por 0.1% dos votos é, em média, extremamente semelhante a um que perde por 0.1%. Eles têm financiamento, qualidade e apelo eleitoral virtualmente idênticos.\n\nValidade do Pressuposto de Continuidade: É plausível que a porcentagem de votos na próxima eleição (Y) variaria suavemente com a margem de vitória anterior (Z) se não houvesse o “prêmio” da incumbência. Não há razão para acreditar que um candidato que vence por 0.1% teria uma trajetória de votos futura drasticamente diferente de um que perde por 0.1%, a não ser pelo fato de ter vencido.\nImpossibilidade de Manipulação: É extremamente difícil para um candidato controlar o resultado de uma eleição com precisão suficiente para garantir uma vitória por uma margem mínima.\n\nO estudo encontra um salto de cerca de 7-8 pontos percentuais na porcentagem de votos na eleição seguinte, que é o LATE da incumbência.\n\n\nCarpenter & Dobkin (2009): Leis como Descontinuidades Perfeitas\nEste estudo explora uma regra institucional ainda mais rígida: a idade mínima para o consumo de álcool (MLDA - Minimum Legal Drinking Age).\n\nValidade do Pressuposto de Continuidade: A variável de continuidade é a idade. É altamente plausível que a taxa de mortalidade (Y) mude suavemente com a idade (Z). Não há razão biológica ou social para que a mortalidade de uma pessoa salte abruptamente no dia do seu 21º aniversário, a não ser por uma mudança de comportamento induzida por uma nova permissão legal.\nImpossibilidade de Manipulação: A idade de uma pessoa é uma variável que não pode ser manipulada. Ninguém pode escolher fazer 21 anos mais cedo para beber legalmente. Isso torna o design RDD extremamente crível neste contexto.\n\nO estudo encontra um salto discreto de cerca de 9% na taxa de mortalidade geral logo após os 21 anos, atribuído ao aumento do consumo de álcool e comportamentos de risco associados."
  }
]