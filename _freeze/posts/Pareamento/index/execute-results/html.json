{
  "hash": "dcb930aef2f3be948c3e977d1e2bc628",
  "result": {
    "markdown": "---\ntitle: \"Pareamento\"\nauthor: \"Caio Lopes\"\ndate: \"2025-04-19\"\ncategories: [Ensino]\n#image: \"image.jpg\"\n---\n\n\n# 1. O Problema dos Confounders\n\n## Motivação: Avaliação de Treinamento Corporativo\n\n**Pergunta de pesquisa**: Programas de treinamento corporativo aumentam a produtividade dos funcionários?\n\n**Variáveis**:\n- **Y**: Produtividade mensal (R\\$ mil) \n- **D**: Participação em treinamento (0/1) \n- **X**: Experiência no cargo (anos)\n\n## Por que Experiência é um Confounder?\n\n**Definição**: Um confounder é uma variável que afeta tanto o tratamento quanto o resultado.\n\nNo nosso exemplo: \n\n1. **Experiência → Treinamento**: Funcionários inexperientes são mais enviados para treinamento \n\n2. **Experiência → Produtividade**: Funcionários experientes são naturalmente mais produtivos\n\n**Conclusão**: não levar em conta o confounder (experiência) causa endogeneidade (viés de variável obtida). \n\n\n## Simulação do Problema\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(MatchIt)\nlibrary(Matching)\nlibrary(knitr)\nlibrary(kableExtra)\n\nset.seed(123)\nn <- 800\n\n# Gerar dados com confounding negativo\ndados <- tibble(\n  # Experiência (confounder)\n  experiencia = pmax(0, rgamma(n, shape = 2, rate = 0.4)),\n  \n  # Probabilidade de treinamento (maior para inexperientes)\n  prob_treinamento = plogis(1.5 - 0.3 * experiencia),\n  treinamento = rbinom(n, 1, prob_treinamento),\n  \n  # Produtividade (depende de experiência E treinamento)\n  # Efeito verdadeiro do treinamento: +15 mil\n  produtividade = 25 + 8 * experiencia + 15 * treinamento + rnorm(n, 0, 10)\n) %>%\n  mutate(produtividade = pmax(5, produtividade))\n\n# Estatísticas por grupo\ndados %>%\n  group_by(treinamento) %>%\n  summarise(\n    n = n(),\n    experiencia_media = round(mean(experiencia), 1),\n    produtividade_media = round(mean(produtividade), 1),\n    .groups = \"drop\"\n  ) %>%\n  mutate(grupo = c(\"Sem Treinamento\", \"Com Treinamento\")) %>%\n  dplyr::select(grupo, everything(), -treinamento) %>%\n  kable()\n```\n\n::: {.cell-output-display}\n|grupo           |   n| experiencia_media| produtividade_media|\n|:---------------|---:|-----------------:|-------------------:|\n|Sem Treinamento | 383|               5.9|                71.6|\n|Com Treinamento | 417|               3.5|                68.1|\n:::\n:::\n\n\n## O Problema Revelado\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Análise ingênua (INCORRETA)\ndiferenca_ingenua <- dados %>%\n  group_by(treinamento) %>%\n  summarise(prod_media = mean(produtividade)) %>%\n  summarise(diferenca = diff(prod_media)) %>%\n  pull(diferenca)\n\ncat(\"Efeito aparente (sem controles):\", round(diferenca_ingenua, 1), \"mil reais \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEfeito aparente (sem controles): -3.5 mil reais \n```\n:::\n\n```{.r .cell-code}\ncat(\"Efeito verdadeiro (por construção): +15.0 mil reais \\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEfeito verdadeiro (por construção): +15.0 mil reais \n```\n:::\n\n```{.r .cell-code}\ncat(\"Conclusão errônea: 'Treinamento não funciona!'\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConclusão errônea: 'Treinamento não funciona!'\n```\n:::\n:::\n\n\n**Visualização do problema**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- dados %>%\n  ggplot(aes(x = factor(treinamento), y = experiencia)) +\n  geom_boxplot() +\n  labs(title = \"Funcionários treinados têm menos experiência\",\n       x = \"Treinamento\", y = \"Experiência (anos)\")\n\np2 <- dados %>%\n  ggplot(aes(x = experiencia, y = produtividade, color = factor(treinamento))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Experiência confunde a relação\",\n       x = \"Experiência (anos)\", y = \"Produtividade (R$ mil)\",\n       color = \"Treinamento\")\n\nlibrary(gridExtra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: pacote 'gridExtra' foi compilado no R versão 4.4.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAnexando pacote: 'gridExtra'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nO seguinte objeto é mascarado por 'package:dplyr':\n\n    combine\n```\n:::\n\n```{.r .cell-code}\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/viz-problema-1.png){width=960}\n:::\n:::\n\n\n# 2. Como o Pareamento Corrige o Problema\n\n## Intuição Básica\n\n**Ideia central**: Comparar funcionários similares que diferem apenas no tratamento.\n\n**Estratégia**: \n\n* Encontrar funcionários com mesma experiência\n\n* Alguns receberam treinamento, outros não \n\n* Calcular diferença na produtividade\n\n## Framework de Resultados Potenciais\n\nPara cada funcionário $i$:\n\n* $Y_i^1$: produtividade se recebe treinamento \n\n* $Y_i^0$: produtividade se não recebe treinamento\n\n* $D_i$: indicador de treinamento \n- $X_i$: experiência\n\n**Suposição de Independência Condicional (CIA)**: $$(Y_i^1, Y_i^0) \\perp D_i | X_i$$\n\n**Interpretação**: Condicionalmente à experiência, a seleção para treinamento é \"como se fosse\" aleatória.\n\n## Demonstração: Subclassificação Manual\n\nA subclassificação consiste em estimar o efeito do tratamento pela soma da diferença ponderada entre tratados e controles. A ponderação permite lidar com o problema de \"covariates imbalance\" (diferença na distribuição dos X's entre os grupos).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criar 4 estratos de experiência (simplificado)\ndados <- dados %>%\n  mutate(estrato_exp = case_when(\n    experiencia < 2 ~ \"Muito Inexperiente\",\n    experiencia < 4 ~ \"Inexperiente\", \n    experiencia < 7 ~ \"Intermediário\",\n    TRUE ~ \"Experiente\"\n  ))\n\n# Verificar distribuição dos estratos\ndados %>%\n  count(estrato_exp, treinamento) %>%\n  pivot_wider(names_from = treinamento, values_from = n, names_prefix = \"treinamento_\") %>%\n  kable(col.names = c(\"Estrato\", \"Sem Treinamento\", \"Com Treinamento\"))\n```\n\n::: {.cell-output-display}\n|Estrato            | Sem Treinamento| Com Treinamento|\n|:------------------|---------------:|---------------:|\n|Experiente         |             126|              28|\n|Inexperiente       |              98|             140|\n|Intermediário      |             117|             127|\n|Muito Inexperiente |              42|             122|\n:::\n\n```{.r .cell-code}\n# Calcular efeito dentro de cada estrato\nefeitos_por_estrato <- dados %>%\n  group_by(estrato_exp) %>%\n  summarise(\n    n = n(),\n    n_tratados = sum(treinamento),\n    n_controles = sum(1 - treinamento),\n    efeito = mean(produtividade[treinamento == 1]) - \n             mean(produtividade[treinamento == 0]),\n    .groups = \"drop\"\n  )\n\nefeitos_por_estrato %>%\n  kable(digits = 2, col.names = c(\"Estrato\", \"N Total\", \"N Tratados\", \"N Controles\", \"Efeito (R$ mil)\"))\n```\n\n::: {.cell-output-display}\n|Estrato            | N Total| N Tratados| N Controles| Efeito (R$ mil)|\n|:------------------|-------:|----------:|-----------:|---------------:|\n|Experiente         |     154|         28|         126|            3.98|\n|Inexperiente       |     238|        140|          98|           15.04|\n|Intermediário      |     244|        127|         117|           14.47|\n|Muito Inexperiente |     164|        122|          42|           14.11|\n:::\n\n```{.r .cell-code}\n# Efeito médio ponderado\nate_corrigido <- efeitos_por_estrato %>%\n  mutate(peso = n / sum(n)) %>%\n  summarise(ate = sum(efeito * peso)) %>%\n  pull(ate)\n\ncat(\"Efeito corrigido:\", round(ate_corrigido, 2), \"mil reais\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEfeito corrigido: 12.55 mil reais\n```\n:::\n\n```{.r .cell-code}\ncat(\"Agora recuperamos algo próximo do efeito verdadeiro\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAgora recuperamos algo próximo do efeito verdadeiro\n```\n:::\n:::\n\n\n\n\nNesse caso estamos calculando o ATE a partir de 4 estratos da nossa amostra: \n\n - A: Inexperiente\n - B: Experiente\n - C: Intermediário \n - D: Muito Inexperiente\n \nO calculo do ATE foi baseado na soma ponderada de cada estrato da amostra:\n\n$$\nATE = \n\\left ( \\bar{Y}^{1,A} - \\bar{Y}^{0,A} \\right ) \\frac{N^{A}}{N} +\n\\left ( \\bar{Y}^{1,B} - \\bar{Y}^{0,B} \\right ) \\frac{N^{B}}{N} +\n\\left ( \\bar{Y}^{1,C} - \\bar{Y}^{0,C} \\right ) \\frac{N^{C}}{N} +\n\\left ( \\bar{Y}^{1,D} - \\bar{Y}^{0,D} \\right ) \\frac{N^{D}}{N}\n$$\nImagine que exista outro confundidor: o regime de trabalho. Os trabalhadores CLT são mais engajados em participar do treinamento, mas tendem a ser menos produtivos. Já os trabalhadores PJ são menos engajados em participar do treinamento, mas tendem a ser mais produtivos.Nesse casos, considerando as classificações de experiencia e de regime de trabalho, temos 8 estratos: \n\n - A1: Inexperiente e CLT\n - A2: Inexperiente e PJ\n - B1: Experiente e CLT\n - B2: Experiente e PJ\n - C1: Intermediário e CLT\n - C2: Intermediário e PJ\n - D1: Muito Inexperiente e CLT\n - D2: Muito Inexperiente e PJ\n\nA medida que as variáveis de controle aumentam, começamos a ter dificuldade em colocar cada unidade (tratada ou não) em uma \"caixinha\" do X's. Se a variável confundidora não for discreta (e.g. experiência em anos) a dificuldade aumenta.\n\nNesses casos, estimar o ATT  pode ser mais fácil. Por exemplo, digamos que você não consegue colocar todas as unidades tratadas em um estrato, mas consegue colocar todas do grupo de controle. Logo, para cada estrato de unidade tratada você poderá construir um contrafactual (mas você não conseguirá um contrafactual par a grupo controle).\n\n$$\nATT = \\sum^{K}_{k=1}\n\\left ( \\bar{Y}^{1,k} - \\bar{Y}^{0,k} \\right ) \\frac{N^{k}_{T}}{N_{T}}\n$$\nEste problema causado pela dimensionalidade é um problema de suporte comum. Alternativamente, se preenchêssemos o resultado potencial ausente para cada unidade de tratamento usando uma unidade do grupo de controle que fosse \"mais próxima\" da unidade do grupo de tratamento para algum\nfator de confusão, poderíamos simplesmente calcular a média das diferenças. Esse método é conhecido como pareamento.\n\n\n# 3. Principais Tipos de Pareamento\n\n## 3.1 Pareamento Exato\n\n**Definição**: Parear unidades com valores idênticos das covariáveis.\n\n**Vantagens**: - Transparente e fácil de entender - Balance perfeito por construção - Não requer suposições funcionais\n\n**Desvantagens**: - Maldição da dimensionalidade - Perda de observações - Só funciona com covariáveis categóricas\n\n## 3.2 Pareamento Aproximado\n\n**Motivação**: Quando pareamento exato não é viável, pois tenho covariadas contínuas ou um conjunto de covariadas. \n\n**Estratégias**: - Nearest neighbor matching - Caliper matching\n\nO estimador do paraemento \"1 para 1\" é definido por:\n$$\nATT = \\frac{1}{N_{T}}\\sum_{d_{i}=1}\\left (Y_{i} - Y_{j(i)} \\right ) \n$$\nEm que a unidade $j$ é a unidade do grupo controle \"mais próxima em termos de X\" da unidade $i$ do grupo tratado. Este estimador computa o ATT, pois a média é condicional a $d_{i}=1$. \n\nSe no grupo controle encontrarmos mais de uma unidade parecida com a unidade tratada em termos dos Xs, podemos usar a média.\n\n$$\nATT = \\frac{1}{N_{T}}\\sum_{d_{i}=1}\\left (Y_{i} - \\left [\\frac{1}{M} \\sum^{M}_{m=1} Y_{j_{m}(i) } \\right ] \\right ) \n$$\n\n::: {.cell}\n\n```{.r .cell-code}\ndados$numeric_estrato_exp <- as.numeric(as.factor(dados$estrato_exp))\n\nM1_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 1,\n                estimand='ATT')\nsummary(M1_att) # The default estimate is ATT here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimate...  15.406 \nAI SE......  0.94063 \nT-stat.....  16.379 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  600 \n```\n:::\n\n```{.r .cell-code}\npares_detalhado <- data.frame(\n  tratado_id    = M1_att$index.treated,\n  controle_id   = M1_att$index.control,\n  produtividade_tratado = dados$produtividade[M1_att$index.treated],\n  produtividade_controle = dados$produtividade[M1_att$index.control],\n  X_tratado = dados$experiencia[M1_att$index.treated],\n  X_controle = dados$experiencia[M1_att$index.control]\n)\nhead(pares_detalhado)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  tratado_id controle_id produtividade_tratado produtividade_controle X_tratado\n1          3           8              56.66426               19.52045 0.3609374\n2          4         388              76.77873               60.26301 4.1563083\n3          7         433              59.62470               35.35006 0.8767943\n4         10         326              71.28918               59.01813 4.9326166\n5         10         402              71.28918               59.50021 4.9326166\n6         13           1              59.29248               37.74784 2.2411907\n  X_controle\n1  0.3260003\n2  4.1818486\n3  0.8471077\n4  4.9292527\n5  4.9417003\n6  2.2302339\n```\n:::\n:::\n\nPerceba que: o tratado 3 pareou com o controle 8, o tratado 4 com o controle 388, etc. Vamos definir um M=3.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM3_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 3,\n                estimand='ATT')\nsummary(M3_att) # The default estimate is ATT here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimate...  15.244 \nAI SE......  0.84785 \nT-stat.....  17.98 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  1303 \n```\n:::\n\n```{.r .cell-code}\npares_detalhado_M3 <- data.frame(\n  tratado_id    = M3_att$index.treated,\n  controle_id   = M3_att$index.control,\n  produtividade_tratado = dados$produtividade[M3_att$index.treated],\n  produtividade_controle = dados$produtividade[M3_att$index.control],\n  X_tratado = dados$experiencia[M3_att$index.treated],\n  X_controle = dados$experiencia[M3_att$index.control]\n)\nhead(pares_detalhado_M3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  tratado_id controle_id produtividade_tratado produtividade_controle X_tratado\n1          3           8              56.66426               19.52045 0.3609374\n2          3         594              56.66426               26.65428 0.3609374\n3          3         690              56.66426               58.48778 0.3609374\n4          4         365              76.77873               65.01573 4.1563083\n5          4         388              76.77873               60.26301 4.1563083\n6          4         425              76.77873               61.86003 4.1563083\n  X_controle\n1  0.3260003\n2  0.4281087\n3  0.4083420\n4  4.1860628\n5  4.1818486\n6  4.1227288\n```\n:::\n:::\n\n\nPerceba que: o tratado 3 pareou com o controle 8, 594 e 690; o tratado 4 com o controle 365, 388 e 425, etc. Vamos definir um M=3.\n\nÉ possível calcular o ATE usando o pareamento. O estimador é dado por: \n$$\nATE = \\frac{1}{N}\\sum_{i=1}^{N} (2D_{i}-1) \\left (Y_{i} - \\left [\\frac{1}{M} \\sum^{M}_{m=1} Y_{j_{m}(i) } \\right ] \\right ) \n$$\nQuando $D_{i}=1$, então esse termo principal se torna  1. E quando $D_{i}=0$, então esse termo principal se torna -1, e os resultados invertem a ordem para que a observação do tratamento possa ser imputada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM3_ate <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                M = 3,\n                estimand='ATE')\nsummary(M3_ate) # The default estimate is ATT here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimate...  14.814 \nAI SE......  0.84969 \nT-stat.....  17.434 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  800 \nMatched number of observations  (unweighted).  2536 \n```\n:::\n:::\n\n\nQuando temos muitas covariadas, podemos usar um criterio para medir a distancia entre elas e definir um caliper\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMaha_att <- Match(Y = dados$produtividade, \n                Tr = dados$treinamento, \n                X = dados$experiencia,\n                caliper  = .25,\n                Weight = 2, #mahalanobis\n                estimand='ATT')\nsummary(Maha_att) # The default estimate is ATT here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimate...  15.406 \nAI SE......  0.94063 \nT-stat.....  16.379 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  600 \n\nCaliper (SDs)........................................   0.25 \nNumber of obs dropped by 'exact' or 'caliper'  0 \n```\n:::\n:::\n\n- Distância Euclidiana \n\n**Conceito**: Distância \"em linha reta\" no espaço multidimensional.\n\n**Fórmula**: $d = \\sqrt{\\sum_{k=1}^p (x_{1k} - x_{2k})^2}$\n\nonde $k$ é o número de covariadas\n\n**Quando usar**: Poucas variáveis com escalas similares.\n\n- Distância Mahalanobis \n\n**Conceito**: Distância que considera a estrutura de correlação dos dados.\n\n**Fórmula**: $d = \\sqrt{(x_1 - x_2)^T S^{-1} (x_1 - x_2)}$\n\nonde $S$ é a matriz de covariância.\n\n**Quando usar**: Múltiplas covariáveis correlacionadas.\n\nO `caliper` define o **limite máximo de distância** para aceitar um pareamento. É como um \"raio de busca\" - só forma pares dentro desse raio.\n\n## 3.3 Propensity Score Matching\n\n\n**Ideia revolucionária** (Rosenbaum & Rubin, 1983): Reduzir dimensionalidade usando probabilidade de tratamento.\n\n**Propensity Score**: $e(X) = P(D = 1 | X)$\n\n**Teorema**: Se $(Y^1, Y^0) \\perp D | X$, então $(Y^1, Y^0) \\perp D | e(X)$\n\n### Passos do Propensity Score Matching:\n\n1.  **Estimar propensity score**\n2.  **Verificar overlap**\n3.  **Fazer pareamento**\n4.  **Verificar balance**\n5.  **Estimar efeito**\n\n- O que é Balance?\n*Balance significa que os grupos tratado e controle têm distribuições similares das covariáveis após o pareamento.\n\n* Objetivo: Se conseguimos balance perfeito, as únicas diferenças entre os grupos serão devido ao tratamento, não aos confounders.\n\n*|Diff.Adj| < 0.1: Excelente balance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Passo 1: Estimar propensity score\nps_model <- glm(treinamento ~ experiencia + I(experiencia^2), \n                data = dados, family = binomial)\n\nX  <- ps_model$fitted\nY  <- dados$produtividade\nTr  <- dados$treinamento\n\n# Passo 2: Verificar overlap\ndados$pscore <- predict(ps_model, type = \"response\")\n\ndados %>%\n  ggplot(aes(x = pscore, fill = factor(treinamento))) +\n  geom_histogram(alpha = 0.7, position = \"identity\", bins = 25) +\n  labs(title = \"Distribuição dos Propensity Scores\",\n       x = \"Propensity Score\", y = \"Frequência\",\n       fill = \"Treinamento\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/propensity-score-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Passo 3: Fazer pareamento\nrr  <- Match(Y=Y, Tr=Tr, X=X, M=1);\nsummary(rr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nEstimate...  15.281 \nAI SE......  0.9384 \nT-stat.....  16.284 \np.val......  < 2.22e-16 \n\nOriginal number of observations..............  800 \nOriginal number of treated obs...............  417 \nMatched number of observations...............  417 \nMatched number of observations  (unweighted).  571 \n```\n:::\n\n```{.r .cell-code}\nmb  <- MatchBalance(treinamento ~ experiencia + I(experiencia^2),  data=dados, match.out=rr, nboots=10)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ks.test.default(...): O valor-p será aproximado na presença de\nempates\nWarning in ks.test.default(...): O valor-p será aproximado na presença de\nempates\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n***** (V1) experiencia *****\n                       Before Matching \t \t After Matching\nmean treatment........     3.5041 \t \t     3.5041 \nmean control..........     5.9115 \t \t     3.5064 \nstd mean diff.........    -106.34 \t \t   -0.10125 \n\nmean raw eQQ diff.....     2.4243 \t \t    0.01421 \nmed  raw eQQ diff.....     1.9071 \t \t  0.0079278 \nmax  raw eQQ diff.....     7.3303 \t \t    0.29034 \n\nmean eCDF diff........    0.20697 \t \t  0.0025845 \nmed  eCDF diff........    0.23461 \t \t  0.0017513 \nmax  eCDF diff........     0.3012 \t \t   0.015762 \n\nvar ratio (Tr/Co).....    0.37858 \t \t     1.0009 \nT-test p-value........ < 2.22e-16 \t \t    0.14818 \nKS Bootstrap p-value.. < 2.22e-16 \t \t          1 \nKS Naive p-value...... 3.7114e-16 \t \t          1 \nKS Statistic..........     0.3012 \t \t   0.015762 \n\n\n***** (V2) I(experiencia^2) *****\n                       Before Matching \t \t After Matching\nmean treatment........     17.391 \t \t     17.391 \nmean control..........     48.447 \t \t     17.403 \nstd mean diff.........    -134.36 \t \t  -0.050585 \n\nmean raw eQQ diff.....     31.299 \t \t   0.099713 \nmed  raw eQQ diff.....     15.674 \t \t    0.04658 \nmax  raw eQQ diff.....     234.91 \t \t     5.9291 \n\nmean eCDF diff........    0.20697 \t \t  0.0025845 \nmed  eCDF diff........    0.23461 \t \t  0.0017513 \nmax  eCDF diff........     0.3012 \t \t   0.015762 \n\nvar ratio (Tr/Co).....    0.14395 \t \t    0.99165 \nT-test p-value........ < 2.22e-16 \t \t    0.56036 \nKS Bootstrap p-value.. < 2.22e-16 \t \t          1 \nKS Naive p-value...... 3.7114e-16 \t \t          1 \nKS Statistic..........     0.3012 \t \t   0.015762 \n\n\nBefore Matching Minimum p.value: < 2.22e-16 \nVariable Name(s): experiencia I(experiencia^2)  Number(s): 1 2 \n\nAfter Matching Minimum p.value: 0.14818 \nVariable Name(s): experiencia  Number(s): 1 \n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}